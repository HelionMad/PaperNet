{
    "nodes": [
        {
            "group": 0,
            "name": "10.1.1.1.3782",
            "keyword": "",
            "author": "Boon Thau Loo, Ryan Huebsch, Ion Stoica, Joseph M. Hellerstein",
            "abstract": "Popular P2P file-sharing systems like Gnutella and Kazaa use unstructured  network designs. These networks typically adopt flooding-based search  techniques to locate files. While flooding-based techniques are effective for locating  highly replicated items, they are poorly suited for locating rare items. As  an alternative, a wide variety of structured P2P networks such as distributed hash  tables (DHTs) have been recently proposed. Structured networks can efficiently  locate rare items, but they incur significantly higher overheads than unstructured  P2P networks for popular files. Through extensive measurements of the Gnutella  network from multiple vantage points, we argue for a hybrid search solution,  where structured search techniques are used to index and locate rare items, and  flooding techniques are used for locating highly replicated content. To illustrate,  we present experimental results of a prototype implementation that runs at multiple  sites on PlanetLab and participates live on the Gnutella network.",
            "title": "The Case for a Hybrid P2P Search Infrastructure"
        },
        {
            "group": 1,
            "name": "10.1.1.1.3873",
            "keyword": "",
            "author": "Jukka Perki\u00f6,  Wray Buntine,  Sami Perttu",
            "abstract": "Topic-based search engines are an alternative to simple keyword search engines that are common in today's intranets. The temporal behaviour of the topics in a topic model based search engine can be used for trend analysis, which is an important research goal on its own. We apply topic modelling to an online financial newspaper data and show that some of the trends in the topics are consistent with common understanding.",
            "title": "Exploring Independent Trends in a Topic-Based Search Engine"
        },
        {
            "group": 2,
            "name": "10.1.1.1.4235",
            "keyword": "gene regulatory network, visualization",
            "author": "Naoki Hosoyama,  Noman Nasimul, Hitoshi Iba",
            "abstract": "In recent years, base sequences have been increasingly unscrambled through attempts represented  by the human genome project. Accordingly, the estimation of the genetic network has been  accelerated. However, no definitive method has become available for drawing a large e#ective graph.",
            "title": "Layout Search of a Gene Regulatory Network for 3-D Visualization"
        },
        {
            "group": 3,
            "name": "10.1.1.1.6320",
            "keyword": "",
            "author": "Steffen Staab, Auere Brucker Str",
            "abstract": "The process of understanding spoken language requires the efficient processing of ambiguities that arise by the nature of speech. This paper presents an approach that allows the efficient incremental integration of speech recognition and language understanding using Tomita's generalized LR-parsing algorithm. For this purpose the GLRlattice -parsing-algorithm [11] is revised so that an agenda mechanism can be used to control the flow of computation of the parsing process. Subsequently the HMMevaluations of the word models are combined with a stochastical language model to do a beam search similar to [2, 1, 12], where chartparsers are used to do the job. 1. INTRODUCTION  In [10] M. Tomita proposes a parsing algorithm (Generalized LR-Parsing, GLRP) and extends it in [11] to an algorithm that can parse whole word lattices. This algorithm often works more efficiently with grammars for natural languages than others (see [10, 7]). Nevertheless the lattice-GLRP is not very flexible and require...",
            "title": "Glr-Parsing Of Word Lattices Using A Beam Search Method"
        },
        {
            "group": 4,
            "name": "10.1.1.1.6470",
            "keyword": "",
            "author": "Alexis Kaporis, Christos Makris,  Spyros Sioutas, Athanasios Tsakalidis, Kostas Tsichlas, Christos Zaroliagis",
            "abstract": "We present a new finger search tree with O(1) worst-case  update time and O(log log d) expected search time with high probability  in the Random Access Machine (RAM) model of computation for a large  class of input distributions. The parameter d represents the number of  elements (distance) between the search element and an element pointed  to by a finger, in a finger search tree that stores n elements. For the need  of the analysis we model the updates by a \"balls and bins\" combinatorial  game that is interesting in its own right as it involves insertions and  deletions of balls according to an unknown distribution.",
            "title": "Improved Bounds for Finger Search on a RAM"
        },
        {
            "group": 5,
            "name": "10.1.1.1.7993",
            "keyword": "",
            "author": "S. Orlando, R. Perego,  F. Silvestri",
            "abstract": "This paper describes the architecture of MOSE (My Own Search Engine), a scalable parallel and distributed engine for searching the web. MOSE was specifically designed to efficiently exploit affordable parallel architectures, such as clusters of  workstations. Its modular and scalable architecture can be easily adjusted to fulfill the bandwidth requirements of the application at hand. Both task-parallel  and data-parallel approaches are exploited within MOSE in order to increase  the throughput and efficiently use communication, storing and computational resources. We used",
            "title": "Design of a Parallel and Distributed Web Search Engine"
        },
        {
            "group": 6,
            "name": "10.1.1.1.8476",
            "keyword": "",
            "author": "Jian He,  Layne T. Watson, Naren Ramakrishnan, Clifford A. Shaffer, Alex Verstak, Jing Jiang, Kyung Bae, William, H. Tranter",
            "abstract": "The DIRECT (DIviding RECTangles) algorithm of Jones, Perttunen, and Stuckman (Journal of Optimization Theory and Applications, vol. 79, no. 1, pp. 157--181, 1993), a variant of Lipschitzian methods for bound constrained global optimization, has proved effective even in higher dimensions. However, the performance of a DIRECT implementation in real applications depends on the characteristics of the objective function, the problem dimension, and the desired solution accuracy. Implementations with static data structures often fail in practice, since it is difficult to predict memory resource requirements in advance. This is especially critical in multidisciplinary engineering design applications, where the DIRECT optimization is just one small component of a much larger computation, and any component failure aborts the entire design process. To make the DIRECT global optimization algorithm efficient and robust on large-scale, multidisciplinary engineering problems, a set of dynamic data structures is proposed here to balance the memory requirements with execution time, while simultaneously adapting to arbitrary problem size. The focus of this paper is on design issues of the dynamic data structures, and related memory management strategies. Numerical computing techniques and modifications of Jones' original DIRECT algorithm in terms of stopping rules and box selection rules are also explored. Performance studies are done for synthetic test problems with multiple local optima. Results for application to a site-specific system simulator for wireless communications systems (S    W ) are also presented to demonstrate the effectiveness of the proposed dynamic data structures for an implementation of DIRECT.",
            "title": "Dynamic Data Structures for a Direct Search Algorithm"
        },
        {
            "group": 7,
            "name": "10.1.1.1.8593",
            "keyword": "",
            "author": "Timothy Horiuchi, Ernst Niebur, The Zanvyl Krieger Mind/brain",
            "abstract": "The ability of animals to select a limited region of sensory space for scrutinyisanimportant  factor in dealing with cluttered or complex sensory environments. Such an #attentional\" system  in the visual domain is believed to be involved in both the perception of objects and the control of  eyemovements in primates. While wecanintentionally guide our attention to perform a speci#c  task, it is also re#exively drawn to #salient\" features in our sensory input space. Understanding  how high-level task information and low-level stimulus information can combine to control our  sensory processing is of great interest to both neuroscience and engineering. Towards this end,  wehave designed and fabricated a one-dimensional, analog VLSI vision chip that models covert  attentional search and tracking. We extend previous analog VLSI work #Morris and DeWeerth,  1997# on delayed inhibition in a winner-take-all network to use extracted image edges as input  to the attentional saliency map and to perform serial search on a particular feature conjunction  #spatial derivative and direction-of-motion#. We further demonstrate the abilitytomodifythe  circuit's parameters #on-the-#y\" to switchbetween a search mode and a tracking mode.",
            "title": "Conjunction Search Using a 1-D, Analog VLSI-based, Attentional Search/Tracking Chip"
        },
        {
            "group": 8,
            "name": "10.1.1.1.9000",
            "keyword": "",
            "author": "Jens Graupmann,  Michael Biwer, Christian Zimmer, Patrick Zimmer, Matthias Bender,  Martin Theobald, Gerhard Weikum",
            "abstract": "this document in other search conditions. For example, once again consider the query about a book store in our home town that o#ers the book 'War and Peace' by Tolstoy. In our query language, this query could be expressed as follows:   SELECT A,B FROM INDEX  WHERE A.~address=Saarbrucken  AND A[keyword]=\"book store\"  AND B.title=\"War and Peace\"  AND B.~author=Tolstoy  AND A.B  In this case, matches for the conditions address = Saarbrucken and bookstore are bound to the variable A, which can be used to express the path condition A.B that additionally requires all matches for A to directly link to a match B for title=\"War an Peace\" and  #author=Tolstoy",
            "title": "COMPASS: A Concept-based Web Search Engine for HTML, XML, and Deep Web Data"
        },
        {
            "group": 9,
            "name": "10.1.1.1.9427",
            "keyword": "CSM-371 Page 2",
            "author": "Edward Tsang, Patrick Mills, John Ford",
            "abstract": "Guided Local Search is a general penalty-based optimisation method that sits on  top of local search methods to help them escape local optimum. It has been applied to a  variety of problems and demonstrated effective. The aim of this paper is not to produce  further evidence that Guided Local Search is an effective algorithm, but to present an  extension of Guided Local Search that potentially has no parameter to tune. Compared to  other algorithms, Guided Local Search is relatively easy to apply, as there is only one major  parameter (#) to set. In some applications, performance of Guided Local Search is insensitive   to the value of this parameter. Nevertheless, the value of this parameter can affect the   performance of Guided Local Search in some problems. In this paper, we show how (a) an   aspiration criterion and (b) random moves may be added to Guided Local Search to reduce   the sensitivity of its performance to the parameter value. The extended Guided Local Search   is tested on the SAT, weighted MAX-SAT and Quadratic Assignment Problems with positive   results.   ",
            "title": "Extending Guided Local Search - Towards a . . ."
        },
        {
            "group": 10,
            "name": "10.1.1.10.4357",
            "keyword": "",
            "author": "Ryan Porter, Eugene Nudelman, Yoav Shoham",
            "abstract": "We present two simple search methods for computing a sample  Nash equilibrium in a normal-form game: one for 2player  games and one for n-player games. We test these algorithms  on many classes of games, and show that they perform  well against the state of the art-- the Lemke-Howson algorithm  for 2-player games, and Simplicial Subdivision and  Govindan-Wilson for n-player games.",
            "title": "Simple Search Methods for Finding a Nash Equilibrium"
        },
        {
            "group": 11,
            "name": "10.1.1.10.6259",
            "keyword": "",
            "author": "Nick Koudas, Beng Chin Ooi, Heng Tao Shen, Anthony K. H. Tung",
            "abstract": "Recent advances in research fields like multimedia and bioinformatics have brought about a new generation of hyper-dimensional databases which can contain hundreds or even thousands of dimensions. Such hyperdimensional databases pose significant problems to existing high-dimensional indexing techniques which have been developed for indexing databases with (commonly) less than a hundred dimensions. To support e#cient querying and retrieval on hyper-dimensional databases, we propose a methodology called Local Digital Coding (LDC) which can support k-nearest neighbors (KNN) queries on hyper-dimensional databases and yet co-exist with ubiquitous indices, such as B    -trees. LDC extracts a simple bitmap representation called Digital Code(DC) for each point in the database. Pruning during KNN search is performed by dynamically selecting only a subset of the bits from the DC based on which subsequent comparisons are performed. In doing so, expensive operations involved in computing L-norm distance functions between hyper-dimensional data can be avoided. Extensive experiments are conducted to show that our methodology o#ers significant performance advantages over other existing indexing methods on both real life and synthetic hyper-dimensional datasets.",
            "title": "LDC: Enabling Search by Partial Distance in a Hyper-Dimensional Space"
        },
        {
            "group": 12,
            "name": "10.1.1.100.3526",
            "keyword": "",
            "author": "",
            "abstract": "This paper describes an organization method of page information agents for adaptive interface between a user and a Web search engine. Though a Web search engine indicates a hit list of relevant Web pages, it includes many useless ones. Thus a user often needs to select useful Web pages from them with page information like the title, the URL on the hit list, and actually fetch the Web pages for checking relevance. Since the page information is neither sufficient nor necessary for a user, adequate information is necessary for valid selection. Hence we propose adaptive interface AOAI in which different page information agents are organized through human evaluation.",
            "title": "Intelligent User Interface for a Web Search Engine by Organizing Page Information Agents"
        },
        {
            "group": 13,
            "name": "10.1.1.100.4764",
            "keyword": "presentation, User Interfaces.- Graphical user interfaces. General terms, Design, Human Factors Keywords, OPAC, Human-Computer Interaction, GUI, AJAX",
            "author": "Jesse Prabawa Gozali",
            "abstract": "We redesign the user interface of an online library catalog, leveraging current web technologies that allow dynamic and fine-grained user interaction. Over the course of our iterative design and test cycle, we identified four key areas where such dynamic web technologies can be used to improve the support for typical information seeking strategies: namely, 1) the use of overview + details, 2) a tabular data display, 3) using tabs as a history mechanism and 4) embedding a suggestion bar. We believe that the revised affordances created by our changes in these four areas will inform the design of future search interfaces. ACM Classification: H5.2 [Information interfaces and",
            "title": "Rich and Dynamic Library Catalogs: A Case Study of Online Search Interfaces"
        },
        {
            "group": 14,
            "name": "10.1.1.100.5019",
            "keyword": "VQ, Euclidean metric, Manhattan metric, Chebyshev metric, codeword search",
            "author": "J. S. Pan",
            "abstract": "In this paper, an efficient approximate VQ codeword search algorithm is proposed. This algorithm is based on a modification of the Chebyshev metric (or Manhattan metric). Applying this new algorithm to VQ codeword search and comparing it with the minimax method, it is found that more than 36 % and 5 % multiplications can be saved for 8 and 1024 codewords, respectively. In terms of the total number of mathematical operations, a few mathematical operations can be saved without inducing any extra distortion. Experimental results confirm this new algorithm.",
            "title": "Short Paper A Training Approach for Efficient VQ Codeword Search *"
        },
        {
            "group": 15,
            "name": "10.1.1.100.5228",
            "keyword": "Finite Domains, Search, Applications, Timetabling",
            "author": "R. Gonz\u00e1lez-del-Campo, F. S\u00e1enz-P\u00e9rez",
            "abstract": "Labeling is crucial in the performance of solving timetabling problems with constraint programming. Traditionally, labeling strategies are based on static and dynamic information about variables and their domains, and selecting variables and values to assign. However, the size of combinatorial problems tractable by these techniques is limited. In this paper, we present a real problem solved with constraint programming using programmed search based on the knowledge about the solution structure as a starting point for classical propagation and labeling techniques to find a feasible solution. For those problems in which solutions are close to the seed because of its structure, propagation and labeling can reach a first solution within a small response time. We apply our approach to a real timetabling problem, and we tackle its implementation with two different languages, OPL and T OY, using the constraint programming paradigm over finite domains. While OPL is a commercial, algebraic, and specific-purpose constraint programming language, T OY is a prototype of a general-purpose constraint functional logic programming language. We present the specification of the problem, its implementation with both languages, and a comparative performance analysis.",
            "title": "Programmed Search in a Timetabling Problem over Finite Domains "
        },
        {
            "group": 16,
            "name": "10.1.1.100.5790",
            "keyword": "using computer graphics, computer vision, CAD medical",
            "author": "Yingliang Lu, Kunihiko Kaneko, Akifumi Makinouchi",
            "abstract": "Searching a database of 3D objects for objects that are similar to a given 3D search object is an important task that arises in a number of database applications for example, in Medicine and CAD fields. Most of the existing similarity models are based on global features of 3D objects. Developing a feature set or a feature vector of 3D object using their partial features is challenging. In the present paper, we introduce a novel segment weight vector to matching 3D objects rapidly. We also describe a partial and geometrical similarity based solution to the problem of searching for similar 3D objects. As the first step, we split a 3D object into parts according to its topology. Next, we introduce a new method to extract the thickness feature of each part and generate the feature as a feature vector of the 3D object. We also propose a novel searching algorithm using the newly introduced feature vector. Furthermore, we present a new solution for improving the accuracy of the similarity queries. Finally, we present a performance evaluation of our stratagem. The result indicates that the proposed approach offers a significant performance improvement over the existing approach. Since the proposed method is based on partial features, it is particularly suited to searching objects having distinct part structures and is invariant to part architecture.",
            "title": "Using a Partial Geometric Feature for Similarity Search of 3D Objects"
        },
        {
            "group": 17,
            "name": "10.1.1.100.5841",
            "keyword": "Distributed Data Structures, Scalability, Network Computing, Binary Search Trees",
            "author": "Panayiotis Bozanis, Yannis Manolopoulos",
            "abstract": "We propose LDT, a new Scalable Distributed Search Tree for the dictionary problem, as an alternative to both random trees and deterministic height balanced trees. Our scheme exhibits logarithmic update time, either constant or logarithmic search time for single key queries and output sensitive query time for range search query, depending whether one affords linear or O(n log n) space overhead.",
            "title": "LDT: A Logarithmic Distributed Search Tree"
        },
        {
            "group": 18,
            "name": "10.1.1.100.6645",
            "keyword": "Sequences for Content-Based Search and Retrieval",
            "author": "S\u00e9bastien Lef\u00e8vre, J\u00e9r\u00f4me Holler, Nicole Vincent",
            "abstract": "We present in this paper a review of methods for segmentation of uncompressed video sequences. Video segmentation is usually performed in the temporal domain by shot change detection. In case of real-time segmentation, computational complexity is one of the criteria which has to be taken into account when comparing different methods. When dealing with uncompressed video sequences, this criterion is even more significant. However previous published reviews did not involve complexity criterion when comparing shot change detection methods. Only recognition rate and ability to classify detected shot changes were considered. So contrary to previous reviews we give here complexity of most of the described methods. We review in this paper an extensive set of methods presented in the literature and classify them in several parts, depending on the information used to detect shot changes. The earliest methods were comparing successive frames by relying on most simple elements, that is to say pixels. Comparison could be performed on a global level, so methods based on histograms were also proposed. Block-based methods have been considered to process data at an intermediate level, between local (using pixels) and global (using histograms) levels. More complex features can be involved, resulting in featurebased",
            "title": "S. Lef\u00e8vre, J. Holler, N. Vincent: A Review of Real-time Segmentation of Uncompressed Video Sequences for Content-Based Search and Retrieval RFAI publication: Real Time Imaging, to appear A Review of Real-time Segmentation of Uncompressed Video Sequences "
        },
        {
            "group": 19,
            "name": "10.1.1.100.6746",
            "keyword": "",
            "author": "Stefano Burigat, Luca Chittaro, Luca De Marco",
            "abstract": "Abstract. This paper discusses the design and development of a preference-based search tool (PBST) for tourists, operating on PDA devices. PBSTs are decision support systems that help users in finding the outcomes (e.g., multi-attribute products or services) that best satisfy their needs and preferences. Our tool is specifically aimed at filtering the amount of information about points of interest (POIs) in a geographic area, thus supporting users in the search of the most suitable solution to their needs (e.g., a hotel, a restaurant, a combination of POIs satisfying a set of constraints specified by the user). We focus on the design of an effective interface for the tool, by exploring the combination of dynamic queries to filter POIs on a map with a visualization of the degree of satisfaction of constraints set by the user. We also report the results of a usability test we carried out on the first prototype of the system. 1",
            "title": "Bringing dynamic queries to mobile devices: a visual preference-based search tool for tourist decision support"
        },
        {
            "group": 20,
            "name": "10.1.1.100.7727",
            "keyword": "2",
            "author": "Eng Pwey Lau, Dion Hoe-lian Goh",
            "abstract": "A transaction log analysis of the Nanyang Technological University (NTU) OPAC was conducted to identify query and search failure patterns with the goal of identifying areas of improvement for the system. One semester\u2019s worth of OPAC transaction logs were obtained and from these, 641 991 queries were extracted and used for this work. Issues investigated included query length, frequency and type of search options and Boolean operators used as well as their relationships with search failure. Among other findings, results indicate that a majority of the queries were simple, with short query lengths and a low usage of Boolean operators. Failure analysis revealed that on average, users had an almost equal chance of obtaining no records or at least one record to a submitted query. We propose enhancements and suggest future areas of work to improve the users \u2019 search experience with the NTU OPAC.",
            "title": "In Search of Query Patterns: A Case Study of a University"
        },
        {
            "group": 21,
            "name": "10.1.1.100.880",
            "keyword": "",
            "author": "Lada A. Adamic, Eytan Adar",
            "abstract": "We address the question of how participants in a small world experiment are able to find short paths in a social network using only local information about their immediate contacts. We simulate such experiments on a network of actual email contacts within an organization as well as on a student social networking website. On the e-mail network we find that small world search strategies using a contact\u2019s position in physical space or in an organizational hierarchy relative to the target can effectively be used to locate most individuals. However, we find that in the online student network, where the data is incomplete and hierarchical structures are not well defined, local search strategies are less effective. We compare our findings to recent theoretical hypotheses about underlying social structure that would enable these simple search strategies to succeed and discuss the implications to social software design. 1",
            "title": "How To Search a Social Network"
        },
        {
            "group": 22,
            "name": "10.1.1.101.3422",
            "keyword": "",
            "author": "",
            "abstract": "structured peer-to-peer (P2P) networks only support singlekeyword exact-match lookups. In practice, however, users often have fuzzy information for identifying these items and tend to submit broad queries. The support of searching based on multiple",
            "title": "Supporting Multiple-Keyword Search in A Hybrid Structured Peer-to-Peer Network"
        },
        {
            "group": 23,
            "name": "10.1.1.101.3496",
            "keyword": "",
            "author": "Kerim G\u00fcney",
            "abstract": "A new simple formula for the radiation efficiency of a resonant rectangular microstrip patch antenna is presented. The formula is obtained by using a tabu search algorithm, which is a quite new optimization technique based on the principles of intelligent problem solving. The formula is valid for substrates with relative permittivities between 1 and 12.8 and for the complete range of thicknesses normally used. The results obtained by using this new simple formula are in conformity with those reported elsewhere. The formula can also be used in the calculation of the radiation efficiency of dipoles. Key words: Microstrip antenna, rectangular, radiation efficiency, tabu search 1.",
            "title": "A simple formula obtained using tabu search algorithm for the radiation efficiency of a resonant rectangular microstrip antenna"
        },
        {
            "group": 24,
            "name": "10.1.1.101.360",
            "keyword": "",
            "author": "Quang Minh Vu, Tomonari Masada",
            "abstract": "Abstract \u2014 Results of queries by personal names often contain documents related to several people because of the namesake problem. In order to differentiate documents related to different people, an effective method is needed to measure document similarities and to find documents related to the same person. Some previous researchers have used the vector space model or have tried to extract common named entities for measuring similarities. We propose a new method that uses Web directories as a knowledge base to find shared contexts in document pairs and uses the measurement of shared contexts to determine similarities between document pairs. Experimental results show that our proposed method outperforms the vector space model method and the named entity recognition method. I.",
            "title": "Disambiguation of People in Web Search Using a Knowledge Base"
        },
        {
            "group": 25,
            "name": "10.1.1.101.3781",
            "keyword": "",
            "author": "Irene Celino, Emanuele Della Valle, Dario Cerizza, Andrea Turati",
            "abstract": "Abstract. Search engines are becoming such an easy way to find textual resources that we wish to use them also for multimedia content; however, syntactic techniques, even if promising, are not up to the task: future search engines must consider new approaches. Experimental prototypes of this search engine of the future are appearing. Most of them employs \u201csmart machines \u201d able to directly elaborate multimedia resources, but we believe that the solution should embrace also \u201csmart data\u201d, able to capture lexical and conceptual characteristics of a domain in an ontology. In order to prove that Semantic Web technologies provide real benefits to end users in terms of an easier and more effective access to information, we developed\u00cb\u00d5\u00d9\ufffd\ufffd\ufffd\u00d0\ufffd, a Semantic Web framework that eases the deployment of semantic search engines. Following a model-driven approach to application development,\u00cb\u00d5\u00d9\ufffd\ufffd\ufffd\u00d0\ufffdmakes ontologies (both the SKOS model and the domain knowledge) part of the running code. We evaluate the advantages of\u00cb\u00d5\u00d9\ufffd\ufffd\ufffd\u00d0\ufffdagainst traditional approaches in two real world deployments: one to search images of skiers for Torino 2006 Winter Olympic Games and one to search music files. 1",
            "title": "Squiggle: a semantic search engine for indexing and retrieval of multimedia content"
        },
        {
            "group": 26,
            "name": "10.1.1.101.3820",
            "keyword": "",
            "author": "Lengning Liu, Miros\u0142aw Truszczy\u0144ski",
            "abstract": "",
            "title": "Wildcat: a Local Search PB Optimizer"
        },
        {
            "group": 27,
            "name": "10.1.1.101.4574",
            "keyword": "",
            "author": "Pierre Peterlongo, Laurent No\u00e9, Dominique Lavenier, Gilles Georges, Julien Jacques, Gregory Kucherov, Mathieu Giraud",
            "abstract": "With a sharp increase of available DNA and protein sequence data, new precise and fast similarity search methods are needed for large- scale genome and proteome comparisons. Modern seed-based techniques of similarity search (spaced seeds, multiple seeds, subset seeds) provide a better sensitivity/specificity ratio. We present an implementation of such a seed-based technique on a parallel specialized hardware embed- ding reconfigurable architecture (FPGA), where the FPGA is tightly connected to large capacity Flash memories. This parallel system allows large databases to be fully indexed and rapidly accessed. Compared to traditional approaches presented by the Blastp software, we obtain both a significant speed-up and better results. To the best of our knowledge, this is the first attempt to exploit efficient seed-based algorithms for parallelizing the sequence similarity search",
            "title": "Protein similarity search with subset seeds on a dedicated reconfigurable hardware"
        },
        {
            "group": 28,
            "name": "10.1.1.101.4726",
            "keyword": "",
            "author": "Sunil Movva, Rahul Ramach, Xiang Li, Phani Cherukuri, Sara Graves",
            "abstract": "Abstract- The goal for search engines is to return results that are both accurate and complete. The search engines should find only what you really want and find everything you really want. General search engines (even meta-search engines) lack semantics. In this paper Noesis, which is a meta-search engine and a resource aggregator that uses domain ontologies to provide scoped search capabilities will be described. Noesis uses these ontologies to help the user scope the search query to ensure that the search results are both accurate and complete. The users can refine their search query using these domain ontologies and thereby achieve better precision in their results. I.",
            "title": "Noesis: A Semantic Search Engine and Resource Aggregator for Atmospheric Science"
        },
        {
            "group": 29,
            "name": "10.1.1.101.4811",
            "keyword": "DIRECT, dynamic data structures, global optimization, load balancing, mas- sively parallel schemes, performance evaluation",
            "author": "Jian He, Joel A. Nachlas, Calvin J. Ribbens, Adrian Sandu, Clifford A. Shaffer, Jian He",
            "abstract": "The present work aims at an efficient, portable, and robust design of a data-distributed massively parallel DIRECT, the deterministic global optimization algorithm widely used in multidisciplinary engineering design, biological science, and physical science applications. The original algorithm is modified to adapt to different problem scales and optimization (exploration vs. exploitation) goals. Enhanced with a memory reduction technique, dy-namic data structures are used to organize local data, handle unpredictable memory re-quirements, reduce the memory usage, and share the data across multiple processors. The parallel scheme employs a multilevel functional and data parallelism to boost concurrency and mitigate the data dependency, thus improving the load balancing and scalability. In addition, checkpointing features are integrated to provide fault tolerance and hot restarts. Important algorithm modifications and design considerations are discussed regarding data structures, parallel schemes, error handling, and portability. Using several benchmark functions and real-world applications, the present work is evaluated in terms of optimization effectiveness, data structure efficiency, memory usage, parallel performance, and checkpointing overhead. Modeling and analysis techniques are",
            "title": "Design and Evaluation of a Data-distributed Massively Parallel Implementation of a Global Search Algorithm\u2014DIRECT"
        },
        {
            "group": 30,
            "name": "10.1.1.101.7275",
            "keyword": "The Pmperty Rent Accounting and Waiting List",
            "author": "Sarabjot S. Anand, David A. Bell, John G. Hughes",
            "abstract": "The property management database system under development at the Northern Ireland Housing Executive (NIHE) is a large relational database system. The application system has a high expected transaction processing rate-approximately 37000 transactions per day (most of them accessing mutliple tables) from about 250 on-line users. Performance is of critical importance in its success. In this paper we consider the effect of the Ingres Search Accelerator on the transaction processing efficiency of the system. The performance enhancement brought about by SCAFS (XL\u2019s current version of the well-known Content Addressable File Store, CAFS pABB79, BABB85,COUL72]- the heart of the Ingres Search Accelerator) for different fde organisations is assessed. Recommendations on how the performance of SCAFS can be improved by tuning certain parameters is provided. We also provide a rough guideline as to when the Ingres Query Optimizer \u201cdecides \u201d to use SCAFS for different file organ&lions and point out deficiencies in this decision making",
            "title": "An empirical performance study of the Ingres Search Accelerator for a large property management database system"
        },
        {
            "group": 31,
            "name": "10.1.1.101.7546",
            "keyword": "",
            "author": "Chien-chung Huang",
            "abstract": "An advanced information extraction system requires an effective text categorization technique to categorize extracted facts (text patterns) into a hierarchy of domain-specific topic categories. Text patterns are often short and their categorization is quite different from conventional document categorization. This paper proposes a Web mining approach that exploits Web resources to categorize unknown text patterns with limited manual intervention. The feasibility and wide adaptability of the proposed approach has been shown with extensive experiments on categorizing different kinds of text patterns including domain-specific terms, named entities, and even paper titles into Yahoo!\u2019s taxonomy trees. 1",
            "title": "Categorizing Unknown Text Patterns for Information Extraction Using a Search Result Mining Approach"
        },
        {
            "group": 32,
            "name": "10.1.1.102.1289",
            "keyword": "",
            "author": "Matei Ripeanu, Ian Foster, Adriana Iamnitchi, Anne Rogers",
            "abstract": "Abstract--Multicast communication primitives have broad utility as building blocks for distributed applications. The challenge is to create and maintain the distributed structures that support these primitives while accounting for volatile end-nodes and variable network characteristics. Most solutions proposed to date rely on complex algorithms or global information, thus limiting the scale of deployments and acceptance outside the academic realm. This article introduces a low-complexity, self-organizing solution for maintaining multicast trees, that we refer to as UMM (Unstructured Multi-source Multicast). UMM uses traditional distributed systems techniques: layering, soft-state, and passive data collection to adapt to the dynamics of the physical network and maintain data dissemination trees. The result is a simple, adaptive system with lower overheads than more complex alternatives. We have implemented UMM and evaluated it on a 100-node PlanetLab testbed and on up to 1024-node emulated ModelNet networks Extensive experimental evaluations demonstrate UMM\u2019s low overhead, efficient network usage compared to alternative solutions, and ability to quickly adapt to network changes and to recover from failures. Index Terms--distributes systems, self-organization, multi-source multicast overlay, I",
            "title": "In Search of Simplicity: A Self-Organizing Multi-Source Multicast Overlay"
        },
        {
            "group": 33,
            "name": "10.1.1.102.1473",
            "keyword": "",
            "author": "",
            "abstract": "Abstract. The search algorithm presented allows the CDF of a dependent variable to be bounded with 100 % confidence, and allows for a guaranteed evaluation of the error involved. These reliability bounds are often enough to make decisions, and often require a minimal number of function evaluations. The procedure is not intrusive, i.e. it can be equally applied when the function is a complex computer model (black box). The proposed procedure can handle input information consisting of probabilistic, interval-valued, set-valued, or random-set-valued information, as well as any combination thereof. The function as well as the joint pdf of the input variables can be of any type. 1.",
            "title": "DOI: 10.1007/s11155-006-9025-2 A Search Algorithm for Calculating Validated Reliability Bounds"
        },
        {
            "group": 34,
            "name": "10.1.1.102.5346",
            "keyword": "Global search, genetic algorithms, optimisation",
            "author": "B. Raphael, I. F. C. Smith",
            "abstract": "ABSTRACT: A new global search technique called &quot;Probabilistic Global Search-Lausanne &quot; (PGSL), is presented in this paper. The technique is based on selective sampling of the search space according to a probability distribution function. The performance of the technique is compared with genetic algorithms using non-linear benchmark problems involving a large number of variables. For most of these problems, PGSL performs better than GAs. PGSL shows promise for improving the performance of advanced software for the construction industry.",
            "title": "paper w78-2000-708.content A PROBABILISTIC SEARCH ALGORITHM FOR FINDING OPTIMALLY DIRECTED SOLUTIONS"
        },
        {
            "group": 35,
            "name": "10.1.1.102.604",
            "keyword": "K-Clique, Pattern Matching, Swarm Algorithms, Swarm Intelligence, Distributed Knowledge Sharing",
            "author": "Yaniv Altshuler, Arie Matsliah, Ariel Felner",
            "abstract": "Abstract. As the complexity of systems increases, so does the need of examining the nature of complexity itself. This work discusses the domain of physical swarm problems, in which a swarm of mobile agents is employed for solving physical graph problems (where a certain amount of travel effort in required for every movement along the graph\u2019s edges). A new kind of complexity scheme, suitable for this domain, is discussed by examining a central problem of this domain \u2014 the physical k-clique problem. In this problem, a swarm comprising of mobile agents travels along the vertices of a physical graph G, searching for a clique of size k. Thus, the complexity of the problem is measured in travel efforts (instead of in computation resources). In order to share information between the agents, two communication models are discussed \u2014 a complete knowledge sharing (referred to as centralized shared memory) and a distributed shared memory model, where the mobile agents can store and extract information using the graph\u2019s vertices. The work presents a search algorithm for the agents, and discusses its performance under each communication model. The major contribution of this work is demonstrating the strength of the distributed shared memory model. Although this model is much easier to implement and maintain, is highly fault tolerant and has high scalability, the quality of the results it produces is very high, compared to the strongest model of complete knowledge sharing.",
            "title": "On the Complexity of Physical Problems and a Swarm Algorithm for k-Clique Search in Physical Graphs"
        },
        {
            "group": 36,
            "name": "10.1.1.102.6248",
            "keyword": "",
            "author": "Internet Journal, First Monday",
            "abstract": "This study examines metadata as a means to enhance information retrieval in a suite of seven search engines, AltaVista,",
            "title": "Metadata as a Catalyst: Experiments with Metadata and Search Engines in the"
        },
        {
            "group": 37,
            "name": "10.1.1.102.6528",
            "keyword": "Interfaces and Presentation, User InterfacesEvaluation/methodology, H.5.2 [Information Interfaces and Presentation, User InterfacesScreen Design, I.7.5 [Document and Text Processing, Document",
            "author": "Alan Chalmers",
            "abstract": "",
            "title": "How People use Presentation to Search for a Link: Expanding the Understanding of Accessibility on the Web"
        },
        {
            "group": 38,
            "name": "10.1.1.102.691",
            "keyword": "",
            "author": "Lin Fu, Dion Hoe-lian Goh, Schubert Shou-boon Foo, Yohan Supangat",
            "abstract": "Abstract. Information overload has led to a situation where users are swamped with too much information, resulting in difficulty sifting through the material in search of relevant content. In this paper, we address this issue from the perspective of collaboration in query formulation. We describe a search assistant that helps users with query formulation by finding related previously submitted queries through mining query logs. The search assistant runs as a reusable software component and can be incorporated into various search engines. We report our approach to designing and implementing the software and evaluation results. 1",
            "title": "Query Formulation with a Search Assistant"
        },
        {
            "group": 39,
            "name": "10.1.1.102.9359",
            "keyword": "",
            "author": "Marios D. Dikaiakos, Rizos Sakellariou, Yannis Ioannidis, Marios D. Dikaiakos, Rizos Sakellariou, Yannis Ioannidis",
            "abstract": "In this work we present a preliminary study of the issues surrounding the development of Seach Engines for Grid environments. We discuss the need for Grid Search Engines, that would enable the provision of a variety of Grid information services, such as locating useful resources, learning about their capabilities, and expected conditions of use. The Chapter highlights the main requirements for the design of Grid search engines and the research issues that need to be addressed. 1",
            "title": "Information Services for Large-Scale Grids A Case for a Grid Search Engine"
        },
        {
            "group": 40,
            "name": "10.1.1.103.2797",
            "keyword": "",
            "author": "Max L. Wilson",
            "abstract": "This is a nine month progress report detailing my research into supporting users in their search for information, where the questions, results or even their",
            "title": "A Nine Month Report on Progress Towards a Framework for Evaluating Advanced Search Interfaces considering Information Retrieval and Human Computer Interaction"
        },
        {
            "group": 41,
            "name": "10.1.1.103.4542",
            "keyword": "Search results, displaying list, information retrieval, interface for search results",
            "author": "Offer Drori",
            "abstract": "Search results retrieved from textual databases may be presented in several ways. In commercial search engines, the most common method is the presentation of a list that includes the titles of the retrieved documents, and, sometimes, the first few lines of each document and additional information. A series of studies at the Hebrew University examined the impact of different textual elements presented to the user on the effectiveness of the search. In the current experiment, presentation of search results in the Google-based Yahoo! interface was compared to presentation of search results in the LCC&K (Line in Context, Categories,  & Keywords) interface that was developed consequent to the findings of a previous series of studies. The findings indicate a distinct advantage to the LCC&K interface in terms of objective components (such as duration of search time), and subjective components (such as the user\u2019s increasing sense of co nfidence as the search progressed that it would yield the correct answer, the user\u2019s sense of comfort, the extent to which the interface can mislead the user, etc.). This paper will address the experiment process and its findings.",
            "title": "Informing Science InSITE- \u201cWhere Parallels Intersect \u201d June 2003 Display of Search Results in Google-based Yahoo! vs. LCC&K Interfaces: A Comparison Study"
        },
        {
            "group": 42,
            "name": "10.1.1.103.5610",
            "keyword": "",
            "author": "Claire Vishik, David Hoffman, Karim Lesina",
            "abstract": "RFID technology can present privacy and security issues. These issues must be understood and the risks must be mitigated. Press coverage of some of these issues has often used hyperbole, instead of reasoned analysis to assess the risks. In this paper, we attempt to address one of these risk areas of today\u2019s technology that is",
            "title": "In Search of a Perfect Identifier: Identifiers and Privacy"
        },
        {
            "group": 43,
            "name": "10.1.1.103.828",
            "keyword": "",
            "author": "",
            "abstract": "Most studies concerning constraint satisfaction problems (CSPs) involve variables that take values from small domains. This paper deals with an alternative form of temporal CSPs; the number of variables is relatively small and the domains are large collections of intervals. Such situations may arise in temporal databases where several types of queries can be modeled and processed as CSPs. For these problems, systematic CSP algorithms can take advantage of temporal indexing to accelerate search. Directed search versions of chronological backtracking and forward checking are presented and tested. Our results show that indexing can drastically improve search performance. 1",
            "title": "Improving search using indexing: a study with temporal CSPs"
        },
        {
            "group": 44,
            "name": "10.1.1.103.8823",
            "keyword": "Grover search algorithm, superconducting quantum interference devices PACC, 0365, 4250",
            "author": "Lu Yan, Dong Ping, Xue Zheng-yuan, Cao Zhuo-liang",
            "abstract": "We propose a scheme for implementing the Grover search algorithm with two superconducting quantum interference devices (SQUIDs) in a cavity. Our scheme only requires single resonant interaction of the SQUID-cavity system and the required interaction time is very short. The simplicity of the process and the reduction of the interaction time are important for restraining decoherence.",
            "title": "1009-1963/2007/16(12)/3601-04 Chinese Physics and IOP Publishing Ltd Quantum search via superconducting quantum interference devices in a cavity \u2217"
        },
        {
            "group": 45,
            "name": "10.1.1.104.1004",
            "keyword": "",
            "author": "Anders Albrechtslund",
            "abstract": "NB! This is a draft version. Please do not quote. Comments are appreciated. This paper offers an ethically, philosophically and sociologically founded study of privacy in a digital environment of transformed humanness. The focus is on emergent trends in search technology, in particular Google\u2019s powerful search engine, which contributes to the distribution and \u201cstretching \u201d of human life by making unsorted information available through keyword and-phrase searches. The prominence of searching in human everyday life is brought about by a mutually strengthening combination of several developments, including technological advancements and constantly growing amounts of information. In recent years, we have witnessed a \u201csearch war \u201d similar to the renowned \u201cbrowser wars \u201d of the 1990\u2019s, and this battle between giants like Google, Yahoo! and Microsoft has spun off a number of specialized search opportunities. One of the most thought-provoking developments is the possibility to search and browse satellite images using e.g. Google Earth or MSN Virtual Earth. By combining already available satellite imagery, these tools facilitate visual surveillance, and the potential of this technology \u2013 in a future when (more or less) live feeds from satellites might become an option for private individuals \u2013 is to allow searching and zooming in very detailed, up-to-date maps thus exposing everything that can be seen from above. In this paper I will map and study ethical problems and dilemmas that appear in the wake of emergent search technologies, and a number of questions will be raised: What are the ethical issues and consequences of both \u201ctraditional \u201d and specialized searching? How does searching become surveillance, and what are the relations between the two? How will the new \u201cflows \u201d of (personal) information alter the conception of private and public space? The paper is divided into two main parts: Firstly, the rise of searching as an integral part of human life will be discussed with particular reference to Google\u2019s search engine. Secondly, the expanding of searching to zooming will be studied, i.e. searching in satellite images using recent search technology; here I will focus on Google Earth. 1.",
            "title": "Surveillance in searching A study into ethical aspects of an emergent search culture"
        },
        {
            "group": 46,
            "name": "10.1.1.104.1248",
            "keyword": "",
            "author": "",
            "abstract": "Traditional library catalog systems have been effective in providing access to collections of books, films, and other material. However, they have many limitations when it comes to finding musical information, which has significantly different, and in many ways more complex, structure. The Variations2 search system is an alternative designed specifically to aid users in searching for music. It leverages a rich set of bibliographic data records, expressing relationships between creators of music and their creations. These records enable musicians to search for music using familiar terms and relationships, rather than trying to decipher the methods libraries typically use to organize musical items. This paper describes the design and implementation of the system that makes these searches possible. 1.",
            "title": "THE ANATOMY OF A BIBLIOGRAPHIC SEARCH SYSTEM FOR MUSIC"
        },
        {
            "group": 47,
            "name": "10.1.1.104.3072",
            "keyword": "",
            "author": "Martin Weller, C. Bouras, A. Gkamas, T. Tsiatsos, Jon Mason Graham Adcock, Karl L. Smart, Judy Rice, Larry Wood, Chalk Dust, Virtual Classroom, Al D. Carlson, Judi Repman",
            "abstract": "The use of the Web in education has seen a dramatic increase in the past two to three years. This has corresponded to its continued growth in society in general. Its flexibility and pervasiveness mean it offers a number of benefits for educators. For instance, it can be used as a delivery mechanism both in distance and",
            "title": "Design Guidelines for the Web: In Search of Building Codes for Constructing a Habitable Cyberspace"
        },
        {
            "group": 48,
            "name": "10.1.1.104.3724",
            "keyword": "",
            "author": "Joan C. Nordbotten",
            "abstract": "The number of Web-databases has exploded during the last years. In order to justify the development of new information resources, it is essential to know if the use of existing resources has followed a similar trend. This paper presents an analysis of the use of a national statistical webdatabase made to support Web site improvement efforts. The study is based on log data taken during 2 time periods in 1999 and 2000. In this period, the number of registered users increased 5-fold and the number of sessions more than double. During September 2000, active users spent 4,320 hours on the Web-DB and initiated 14,998 topic-sessions giving an average of 7 hours and 25 sessions per user. Definition of a session has proved difficult since the log data available is based on registered organizations, rather than on tasks or individual persons. Ideally, a session should be defined as a search and retrieval for the information required for a task. We have used a topic-session, defined as the sequence of requests from topic initiation to retrieval of data from this topic, as a task approximation.",
            "title": "Evaluation of User Search in a Web-Database"
        },
        {
            "group": 49,
            "name": "10.1.1.104.6447",
            "keyword": "",
            "author": "Joso L Marques Silva",
            "abstract": "This paper introduces GRASP (Generic seaRch Algorithm for the Satisjiability Problem), an integrated algorithmic framework for SAT that un.$es several previously proposed searchpruning techniques and facilitates ident$cation of additional ones. GRASP is premised on the inevitability of confzicts during search and its most distinguishing feature is the augmentation of basic backtracking search with a powerfil confzict analysis procedure. Analyzing confzicts to determine their cawes enables GRASP to backtrack non-chronologically to earlier levels in the search tree, potentially pruning large portions of the search space. In addition, by \u201crecording \u201d the causes of conflicts, GRASP can recognize andpreempt the occurrence of similar conficts later on in the search. Finally, straightjwward bookkeeping of the causality chains leading up to conflicts allows GRASP to identifi assignments that are necessary for a solution to be found. fiperimental results obtained from a large number of benchmarks, including many from the $eld of test pattern generation, indicate that application of the proposed confzict analysis techniques to SATalgorithm can be extremely effectivefor a large number of representative classes of SAT instances. 1",
            "title": "GRASP - A New Search Algorithm for Satisfiability"
        },
        {
            "group": 50,
            "name": "10.1.1.104.7612",
            "keyword": "",
            "author": "Niloy Ganguly, Geoff Canright Andreas Deutsch",
            "abstract": "Abstract. In this paper, we report a decentralized algorithm, termed ImmuneSearch, for searching p2p networks. ImmuneSearch avoids query message flooding; instead it uses an immune-systems-inspired concept of proliferation and mutation for message movement. In addition, a protocol is formulated to change the neighborhoods of the peers based upon their proximity with the queried item. This results in topology evolution of the network whereby similar contents cluster together. The topology evolution help the p2p network to develop \u2018memory\u2019, as a result of which the search efficiency of the network improves as more and more individual peers perform searches. Moreover, the algorithm is extremely robust and its performance is stable even when peers are transient. 1",
            "title": "Design of a robust search algorithm for p2p networks"
        },
        {
            "group": 51,
            "name": "10.1.1.104.7658",
            "keyword": "",
            "author": "Jacques Laye, Charis Lina, Herve Tanguy, Jel L",
            "abstract": "We have developed an agent-based computational model, extension of an analytical model 5 that studies the structure of coalitions of B-to-C web sites, when Internet buyers incur search costs for finding the good that matches their preferences, and coalitions of sites reduce this cost through specialized search engines. This multiagent model consists of heterogeneous, bounded rational agents: sites and web users, which have states and rules of behavior. Our goal is to run simulations by instantiating two agent populations (a population of sites/sellers and a population of web users/consumers), let the agents interact through the consumer search process and the coalition formation process, and monitor the evolution of the simulations in order to study the emerging dynamics, in particular the emerging coalition structure. The agent-based model extends the analytical results for less restricting assumptions. Moreover, beyond the coalition formation process, the analytical model is enriched by additional behaviors for the sites (entry and death), which give insights on the dynamics of competition when building coalition matters for increasing demand at the expense of non or less coalesced sites. Key Words: B-to-C, coalition formation, multi-agent.",
            "title": "Consumers \u2019 Search Cost and Emerging Structure of Web Sites Coalitions: a Multi-agent Based Simulation of an Electronic Market 1"
        },
        {
            "group": 52,
            "name": "10.1.1.104.7915",
            "keyword": "",
            "author": "Wanxia Wei, Chu Min Li, Harry Zhang",
            "abstract": "The local search algorithm adaptG 2 W SATP [3, 4] flips the promising decreasing variable with the largest computed promising score if there are promising decreasing variables. It selects a variable to flip from a randomly chosen unsatisfied clause using heuristic Novelty++P [3, 4] otherwise. This heuristic Novelty++P is described as follows. Novelty++P (p, dp): With probability dp (diversification probability), flip a variable in c whose flip can falsify the least recently satisfied clause. With probability 1 \u2212 dp, do as Novelty, but flip second if best is more recently flipped than second and if pscore(second)  \u2265 pscore(best). The local search algorithm V W [6] introduces variable weighting. This algorithm initializes the weight of a variable x, variable weight[x], to 0 and updates and smoothes variable weight[x] each time x is flipped, using the following equation: variable weight[x]  = (1 \u2212 s)(variable weight[x] + 1) + s \u00d7 t (1) where s is a parameter and 0 \u2264 s \u2264 1, and t denotes the time when x is flipped. This algorithm uses a unique variable selection rule. We call this rule the low variable weight favoring rule. If a randomly selected unsatisfied clause c contains freebie variables, 3 V W randomly flips one of them. Otherwise, with probability p, it flips a variable chosen randomly from c, and with probability 1 \u2212 p, it flips a variable in c",
            "title": "Hybrid1: A Local Search Algorithm That Switches Between Two Heuristics"
        },
        {
            "group": 53,
            "name": "10.1.1.104.8635",
            "keyword": "",
            "author": "Jingzhi Guo",
            "abstract": "Abstract. The title of this paper was chosen to introduce what EM2I really means and how it could be treated as a research area for the research specialists of business information systems and electronic commerce. It functions as offering a few commonplace remarks by way of introduction so that the area researchers may come up with valuable opinions. 1. What is EM2I? In the preparation of this symposium, the term \u201cElectronic Marketplace Integration and Interoperability \u201d was coined as a shorthand way in EM2I to refer to some concerns about supporting the technical integration of multiple business systems so that the expected integration results could further enable a wider scope of both technical and business interoperability across involved business systems. The meaning of the individual words in the term needs clarification and special treatment. What is electronic marketplace? What is integration? What is interoperability? 1.1. Confusion between Electronic Marketplace and Electronic Market Current use of the terms between \u201celectronic marketplace \u201d (EMp) and",
            "title": "EM2I: A Term in Search of the Infrastructure of Electronic Markets"
        },
        {
            "group": 54,
            "name": "10.1.1.104.9338",
            "keyword": "",
            "author": "Robert W. Lindeman, Yasuyuki Yanagida, John L. Sibert, Robert Lavine",
            "abstract": "Abstract: This paper presents results from work we have done into the combination of visual and vibrotactile cues for improving user interaction in virtual environments. Using a custom-designed control system, the intensity of a large number of low-cost vibrational devices can be independently controlled. Our current task is to determine the parameters and design-space for providing this type of cueing to support effective HCI. In a visual search task, user performance was compared over three levels of visual cues and four levels of vibrotactile cue types, in an attempt to narrow the visual search field for locating a letter from a random display of letters. Our results confirm the work of others, showing that users perform significantly faster when given visual cues, and that in the absence of visual cues, vibrotactile cues significantly improve performance. We also found that the waveform of the vibrotactile cue does not seem to make a difference in performance. Keywords: Multi-modal, vibrotactile, empirical study, HCI. 1",
            "title": "Effective Vibrotactile Cueing in a Visual Search Task"
        },
        {
            "group": 55,
            "name": "10.1.1.104.9464",
            "keyword": "decentralized",
            "author": "Jie Wu",
            "abstract": "Search engines are among the most important applications or services on the web. Most existing successful search engines use a centralized architecture and global ranking algorithms to generate the ranking of documents crawled in their databases, for example, Google's PageRank. However, global ranking of documents has two potential problems: high computation cost, and potentially poor rankings. Both of the problems are related to the centralized computation paradigm. We propose a decentralized architecture to solve the problem in a P2P fashion. We identify three sub-problems in the big picture: a logical framework for ranking computation, an efficient way of computing dynamic local ranking, and a cooperative approach that bridges distributed local rankings and collective global ranking. In the paper we summarize the current knowledge and existing solutions for distributed IR systems, and present our new ideas. We also provide initial results, demonstrating that the use of such an architecture can ameliorate the above-mentioned problems for Web and P2P search engines. 1 Keywords: search engines, information retrieval, P2P systems, link analysis, swarm intelligence,",
            "title": "Towards a decentralized search architecture for the web and p2p systems"
        },
        {
            "group": 56,
            "name": "10.1.1.104.9655",
            "keyword": "",
            "author": "",
            "abstract": "Ranking data is a fundamental organizational activity. Given advice, we may wish to rank a set of items to satisfy as much of that advice as possible. In the Feedback Arc Set (FAS) problem, advice takes the form of pairwise ordering statements, \u2018a should be ranked before b\u2019. Instances in which there is advice about every pair of items is known as a tournament. This task is equivalent to ordering the nodes of a given directed graph to minimize the number of arcs pointing in one direction. In the past, much work focused on finding good, effective heuristics for solving the problem. Recently, a proof of the NP-completeness of the problem (even when restricted to tournaments) has accompanied new algorithms with approximation guarantees, culminating in the development of a PTAS (polynomial time approximation scheme) for solving FAS on tournaments. In this paper we re-examine many of these existing algorithms and develop some new techniques for solving FAS. The algorithms are tested on both synthetic and Rank Aggregation-based datasets. We find that, in practice, local-search algorithms are very powerful, even though we prove that they do not have approximation guarantees. Our new algorithm is based on reversing arcs whose nodes have large indegree differences, eventually leading to a total ordering. Combining this with a powerful local-search technique yields an algorithm that beats existing techniques on a variety of data sets.",
            "title": "Ranking Tournaments: Local Search and a New Algorithm \u2217"
        },
        {
            "group": 57,
            "name": "10.1.1.105.4690",
            "keyword": "",
            "author": "",
            "abstract": "Abstract \u2014 Broadcasting data with an index is an effective way to disseminate public information to a large clients. For a server, using multiple channels to provide services (e.g., location-based services) makes the broadcast cycle shorter than using one channel. Among location-based services, the k nearest neighbors (kNN) search is an important one and finds the k closest objects to a query point in a multi-dimensional space. This paper considers k nearest neighbors search on a broadcast R-tree in a multi-channel environment. We assume that a mobile client can only tune into a specified channel at one time instance. We study how a server generates the broadcast schedules on multiple channels and explore how a client executes the kNN search on the broadcast. Different broadcast schedules with the client kNN search processing makes different kNN search protocols. The objectives of the protocols is to minimize the latency (i.e., the time elapsed between issuing and termination of the query), tuning time (i.e., the amount of time spent on listening to the channel), and the memory usage for kNN search processing. Last, we present our experiments and the experiment results validate that our mechanisms achieve the objectives. I.",
            "title": "Broadcast Schedules and Query Processing for k Nearest Neighbors Search on Multi-dimensional Index Trees in a Multi-Channel Environment"
        },
        {
            "group": 58,
            "name": "10.1.1.105.5106",
            "keyword": "",
            "author": "Alon Wolf A, Howie H. Choset B, Howard B. Brown A, Y Casciola C",
            "abstract": "user-Interface",
            "title": "Design and Control of a Mobile Hyper-Redundant Urban Search and Rescue Robot"
        },
        {
            "group": 59,
            "name": "10.1.1.105.5978",
            "keyword": "Design, Documentation, Experimentation Keywords Open Source Software, Web Search, Software Architecture",
            "author": "Rohit Khare, Doug Cutting",
            "abstract": "Nutch is an open-source Web search engine that can be used at global, local, and even personal scale. Its initial design goal was to enable a transparent alternative for global Web search in the public interest \u2014 one of its signature features is the ability to \u201cexplain \u201d its result rankings. Recent work has emphasized how it can also be used for intranets; by local communities with richer data models, such as the Creative Commons metadata-enabled search for licensed content; on a personal scale to index a user's files, email, and web-surfing history; and we also report on several other research projects built on Nutch. In this paper, we present how the architecture of the Nutch system enables it to be more flexible and scalable than other comparable systems today.",
            "title": "Nutch: A flexible and scalable open-source web search engine"
        },
        {
            "group": 60,
            "name": "10.1.1.105.6990",
            "keyword": "data integration, database, search platform",
            "author": "Seok Jong, Yu Dan, Bi Kim, Inae Hur, Sang Joo Lee",
            "abstract": "Searching biological data is an important process to find biological information [1, 2]. For fast and easy data searching, the demands for integrated biological database are booming. The problems occur when integrating biological data are due to several factors such as the amount and variety of data available, the representational heterogeneity of the data in different sources, and autonomy and different capabilities of the",
            "title": "Framework Approach for a Search Platform on Biological Data"
        },
        {
            "group": 61,
            "name": "10.1.1.105.729",
            "keyword": "global optimization, molecular conformation, nonlinear programming",
            "author": "J. C. Meza, R. S. Judson, T. R. Faulkner, Allelix Biopharmaceuticals, Goreway Dr",
            "abstract": "We present results from the application of two conformational searching methods: genetic algorithms (GA) and direct search methods for nding low energy conformations of organic molecules. GAs are in a class of biologically motivated optimization methods that evolve a population of individuals where individuals who are more \\ t &quot; have a higher probability of surviving into subsequent generations. The parallel direct search method (PDS) is a type of pattern search method that uses an adaptive grid to search for minima. Both methods found energies equal to or lower than the energy of the relaxed crystal structure in all cases, at a relatively small cost in CPU time. We suggest that either method would be a good candidate to nd 3-D conformations in a large scale screening application.",
            "title": "A comparison of a direct search method and a genetic algorithm for conformational searching"
        },
        {
            "group": 62,
            "name": "10.1.1.105.8027",
            "keyword": "",
            "author": "Ziv Bar-yossef, Maxim Gurevich",
            "abstract": "We revisit a problem introduced by Bharat and Broder almost a decade ago: how to sample random pages from the corpus of documents indexed by a search engine, using only the search engine\u2019s public interface? Such a primitive is particularly useful in creating objective benchmarks for search engines. The technique of Bharat and Broder suffers from a well-recorded bias: it favors long documents. In this paper we introduce two novel sampling algorithms: a lexicon-based algorithm and a random walk algorithm. Our algorithms produce biased samples, but each sample is accompanied by a weight, which represents its bias. The samples, in conjunction with the weights, are then used to simulate near-uniform samples. To this end, we resort to four well-known Monte Carlo simulation methods: rejection sampling, importance sampling, the Metropolis-Hastings algorithm, and the Maximum Degree method. The limited access to search engines force our algorithms to use bias weights that are only \u201capproximate\u201d. We characterize analytically the effect of approximate bias weights on Monte Carlo methods and conclude that our algorithms are guaranteed to produce near-uniform samples from the search engine\u2019s corpus. Our study of approximate Monte Carlo methods could be of independent interest. Experiments on a corpus of 2.4 million documents substantiate our analytical findings and show that our algorithms do not have significant bias towards long documents. We use our algorithms to collect fresh comparative statistics about the corpora of the Google, MSN Search, and Yahoo! search engines. 1",
            "title": "Random Sampling from a Search Engine\u2019s Corpus \u2217"
        },
        {
            "group": 63,
            "name": "10.1.1.105.8198",
            "keyword": "",
            "author": "Christos Voudouris, Raphael Dorne, David Lesaint, Anne Liret",
            "abstract": "Abstract. Heuristic Search techniques are known for their efficiency and effectiveness in solving NP-Hard problems. However, there has been limited success so far in constructing a software toolkit which is dedicated to these methods and can fully support all the stages and aspects of researching and developing a system based on these techniques. Some of the reasons for that include the lack of problem modelling facilities and domain specific frameworks which specifically suit the operations of heuristic search, tedious code optimisations which are often required to achieve efficient implementations of these methods, and the large number of available algorithms- both local search and population-based- which make it difficult to implement and evaluate a range of techniques to find the most efficient one for the problem at hand. The iOpt Toolkit, presented in this article, attempts to address these issues by providing problem modelling facilities well-matched to heuristic search operations, a generic framework for developing scheduling applications, and a logically structured heuristic search framework allowing the synthesis and evaluation of a variety of algorithms. In addition to these, the toolkit incorporates interactive graphical components for the visualisation of problem and scheduling models, and also for monitoring the run-time behaviour and configuring the parameters of heuristic search algorithms. 1",
            "title": "iOpt: A Software Toolkit for Heuristic Search Methods"
        },
        {
            "group": 64,
            "name": "10.1.1.105.9349",
            "keyword": "Hybrid systems, abstractions, timed languages, scheduling",
            "author": "Paulo Tabuada, Pedro Lima",
            "abstract": "Large-scale, multi-agent systems are becoming extremely complex due to the rapid advances in computation and communication. A natural approach to deal with the increased complexity of such systems is the use of abstractions: given a complicated model and some properties of interest, extract simpler models of the original system that propagate the desired properties to the abstracted model, while hiding details that are of no interest. In this paper, we review our methodology for extracting hybrid systems out of continuous control systems while preserving timed languages. This allows us to extract high level models that can be used for real time scheduling while ensuring that high level plans have feasible implementations at the lower level model. Our methodology, is then fully illustrated by a search and rescue case study. 1",
            "title": "Hybrid abstractions: A search and rescue case study"
        },
        {
            "group": 65,
            "name": "10.1.1.105.9517",
            "keyword": "",
            "author": "",
            "abstract": "desktop search systems maintain per-user indices to keep track of file contents. In a multi-user environment, this is not a viable solution, because the same file has to be indexed many times, once for every user that may access the file, causing both space and performance problems. Having a single system-wide index for all users, on the other hand, allows for efficient indexing but requires special security mechanisms to guarantee that the search results do not violate any file permissions. We present a security model for full-text file system search, based on the UNIX security model, and discuss two possible implementations of the model. We show that the first implementation, based on a postprocessing approach, allows an arbitrary user to obtain information about the content of files for which he does not have read permission. The second implementation does not share this problem. We give an experimental performance evaluation for both implementations and point out query optimization opportunities for the second one. 1",
            "title": "Abstract A Security Model for Full-Text File System Search in Multi-User Environments"
        },
        {
            "group": 66,
            "name": "10.1.1.106.1771",
            "keyword": "",
            "author": "Student Lucian Leahu, Advisor Carla Gomes",
            "abstract": "Abstract. We study the behavior of heuristics based on the LP relaxation with respect to the underlying constraindness of the problem. Our study focuses on the Latin square (or quasigroup) completion problem [1]) 1 as a prototype for highly combinatorial problems. We find that simple techniques based on the LP relaxation of the problem provide satisfactory guidance for under- and over-constrained instances. In the critically constrained region, the performance of such simple techniques degrades, due to the inherit hardness of the problem. In this setting, we examine a technique that recomputes the LP relaxation every time a variable is set. This leads to a significant increase in performance, suggesting that carefully designed \u201cone step at a time \u201d LP-based heuristics could provide suitable guidance even for the hardest instances. Recent years have witnessed the emergence of a new area involving hybrid solvers integrating CP- and OR-based methods. OR has a long and rich history of using Linear Programming (LP) based relaxations for (Mixed) Integer",
            "title": "LP as a Global Search Heuristic Across Different Constrainedness Regions \u22c6 Extended Abstract"
        },
        {
            "group": 67,
            "name": "10.1.1.106.3016",
            "keyword": "",
            "author": "Samir Loudni",
            "abstract": "This paper presents a new hybrid method for solving constraint optimization problems in anytime contexts. Discrete optimization problems are modelled as Valued CSP. Our method (VNS/LDS+CP)",
            "title": "combines a Variable Neighborhood Search and"
        },
        {
            "group": 68,
            "name": "10.1.1.106.4525",
            "keyword": "Inductive Logic Programming, similarity index, \u03b8-subsumption, partial subsumption, CSP",
            "author": "Samuel Wieczorek, Gilles Bisson, Mirta B. Gordon",
            "abstract": "Abstract: We introduce a new test, named \u03c0-subsumption, which computes partial subsumptions between a hypothesis h and an example e, as well as a new measure, the subsumption index, which quantifies the covering degree between h and e. The behaviour of this measure is studied in the region of the phase transition and compared with \u03b8-subsumption. We then consider the use of this measure for the covering test in Inductive Logic Programming to improve the learning phase.",
            "title": "Guiding ILP Search in the Sparse Solutions Region with a Partial Subsumption Test"
        },
        {
            "group": 69,
            "name": "10.1.1.106.4715",
            "keyword": "",
            "author": "Zenon W. Pylyshyn",
            "abstract": "Below is the unedited, uncorrected final draft of a BBS target article that has been accepted for publication. This preprint has been prepared for potential commentators who wish to nominate themselves for formal commentary invitation. Please DO NOT write a commentary until you receive a formal invitation. If you are invited to submit a commentary, a copyedited, corrected version of this paper will be posted.",
            "title": "Mental Imagery: In search of a theory"
        },
        {
            "group": 70,
            "name": "10.1.1.106.4960",
            "keyword": "",
            "author": "Kathy-anne Brickman",
            "abstract": "For my mom and dad ii ACKNOWLEDGEMENTS My graduate school experience here at Michigan has been amazing and that is due, in large part, to the people that I have met and the friends that I have made along the way. First and foremost I need to thank Chris for letting me work in his lab, Chris, thank you so much. In my six years here I have learned more than I could have possibly imagined. When I look back to when I first joined the lab, compared to where I am now the difference, in my mind at least, is unreal. In your lab I had the opportunity to learn about so many different aspects of experimental physics, from microwave sources, to optics and lasers, to atomic physics. Thank you for all of the opportunities you have given me and for supporting me along the way. I feel well prepared for whatever my physics future holds and I am truly grateful. Next I need to thank all my collegues especially Louis, Patty, and Paul with whom I worked and from whom I learned the most. Louis and Patty, thank you for showing",
            "title": "Implementation of Grover\u2019s quantum search algorithm in a scalable system"
        },
        {
            "group": 71,
            "name": "10.1.1.106.5334",
            "keyword": "Web Archive, Community Webs",
            "author": "M\u00e1rio J. Silva",
            "abstract": "This paper discusses the importance of search engines specialised in providing services to community Webs and presents the case for a search engine for the Portuguese Web community. In addition to a search service optimised for these users, there are other services that can be addressed by such system, including the preservation of publications of historical interest for future access to the community and obtaining knowledge about the preferences and interests of this society in the information age. The paper also introduces the architecture and design of tumba!, a new Internet search engine for the Portuguese Web. Tumba! uses a new repository architecture and implements innovative ranking and presentation algorithms. It is designed to take profit of our unique knowledge of this Web, making it a platform that could work as a testbed for research and evaluation of new ideas in Web information retrieval and computational processing of the Portuguese language.",
            "title": "The case for a portuguese web search engine"
        },
        {
            "group": 72,
            "name": "10.1.1.106.6610",
            "keyword": "Contents",
            "author": "Acronym Alvis",
            "abstract": "Contract number IST-1-002068-STP Start date of the project 1.1.2004",
            "title": "ALVIS \u2013 Superpeer Semantic Search Engine Open Source Search: A Data Mining Platform"
        },
        {
            "group": 73,
            "name": "10.1.1.106.7121",
            "keyword": "Motion estimation, half-pixel, half-pel, sub-pixel, linear model",
            "author": "Yun-gu Lee, Jae Hun Lee, Jong Beom Ra",
            "abstract": "a linear model",
            "title": "Fast half-pixel motion estimation based on directional search and a linear model"
        },
        {
            "group": 74,
            "name": "10.1.1.106.7808",
            "keyword": "cutting and packing, nesting, irregular shape, heuristics, beam search 3",
            "author": "Julia A. Bennell, Xiang Song, Julia A. Bennell, Xiang Song",
            "abstract": "The paper investigates the irregular shape packing problem, also frequently referred to as the nesting problem. A review of the literature highlights two distinct approaches for representing the problem; as an order list of pieces to be packed that is decoded by a placement rule (construction heuristic), or as a layout where pieces have allocated co-ordinate positions on the stock sheet. The former strategy is explored in this paper. Success of such an approach is dependant on two critical characteristics; the construction heuristic and the packing order. A construction heuristic based taken from the literature is presented and modified through a more powerful nofit polygon generator and new evaluation criteria that encourage certain desirable behaviours. A beam search algorithm is implemented to search over the packing order. Beam search is analogous to branch and bound where the tree is searched breadth first and aggressively pruned at each level. Using this approach many parallel partial solutions can be generated and compared using the new constructive heuristic. Computational results for benchmark problems show that the algorithm generates highly competitive solutions in significantly less time than the best results currently in the literature.",
            "title": "1 A Beam Search Implementation for the Irregular Shape Packing Problem"
        },
        {
            "group": 75,
            "name": "10.1.1.106.8172",
            "keyword": "called keyword spices",
            "author": "Satoshi Oyama, Takashi Kokubo, Toru Ishida, Teruhiro Yamada",
            "abstract": "This paper presents a new method for building domain-specific web search engines. Previous methods eliminate irrelevant documents from the pages accessed using heuristics based on human knowledge about the domain in question. Accordingly, they are hard to build and can not be applied to other domains. The keyword spice method, in contrast, improves search performance by adding",
            "title": "Keyword spices: A new method for building domain-specific web search engines"
        },
        {
            "group": 76,
            "name": "10.1.1.106.8358",
            "keyword": "",
            "author": "David L. Parnas, Paul C. Clements",
            "abstract": "A perfectly rational person is one who always has a good reason for what he does. Each step taken can be shown to be the best way to get to a well defined goal. Most of us like to think of ourselves as rational professionals. However, to many observers, the usual process of designing software appears quite irrational. Programmers start without a clear statement of desired behavior and implementation constraints. They make a long sequence of design decisions with no clear statement of why they do things the way they do. Their rationale is rarely explained. Many of us are not satisfied with such a design process. That is why there is research in software design, programming methods, structured programming and related topics. Ideally, we would like to derive our programs from a statement of requirements in the same sense that theorems are derived from axioms in a published proof. All of the methodologies that can be considered \u201ctop down \u201d are the result of our desire to have a rational, systematic way of designing software. This paper brings a message with both bad news and good news. The bad news is that, in our opinion, we will never find the philosopher's stone. We will never find a process that allows us to design software in a perfectly rational way. The good news is that we can fake it. We can present our system to others as if we had been rational designers and it pays to pretend do so during development and maintenance.",
            "title": "I. THE SEARCH FOR THE PHILOSOPHER'S STONE: WHY DO WE WANT A RATIONAL DESIGN PROCESS?"
        },
        {
            "group": 77,
            "name": "10.1.1.106.9004",
            "keyword": "",
            "author": "Pavel \u017dikovsk\u00fd, Pavel Slav\u00edk",
            "abstract": "Abstract. Making the content of web pages more accessible for visually impaired people involves displaying web pages sonically- mostly by speech. The other aspect of web browsing- entering information into web forms remains nearly untouched. This aspect is one of the biggest advantages of the internet itself- the possibility to use search engines- Google, etc. Before searching the Internet, the user must enter a",
            "title": "A Method to Define a Search Query by Speech"
        },
        {
            "group": 78,
            "name": "10.1.1.106.9081",
            "keyword": "",
            "author": "Alexei Yavlinsky",
            "abstract": "Abstract. This short report outlines the indexing techniques and the user interface of a prototype image search engine called Behold. It complements traditional image metadata with automatically generated image annotations and an image similarity network to make images more accessible. The user supplies the initial query in the form of one or more keywords and is then able to locate the desired images more precisely in the image network through a browsing interface. 1",
            "title": "Behold: a content based image search engine for the World Wide Web"
        },
        {
            "group": 79,
            "name": "10.1.1.107.144",
            "keyword": "",
            "author": "G\u00e1bor Gosztolya, Andr\u00e1s Kocsor, L\u00e1szl\u00f3 T\u00f3th, L\u00e1szl\u00f3 Felf\u00f6ldi",
            "abstract": "In any speech recognition application we have to identify spoken words, based on the information provided by various features. In this process a large number of word-combinations must be tried out, and the best fitting ones must be chosen. A reduction of this search space (ie. word-sequences) is quite important for both speed and memory reasons, because most of these hypotheses will, for one reason or another, turn out to be quite unsuitable. To tackle this problem, a number of standard algorithms are available like Viterbi beam search, stack decoding, forward-backward search and A * [1][2]. We have implemented some of them and focused mainly on an extension of the general purpose stack decoding method. Our OASIS Speech Laboratory package incorporates most of these methods, which we then tested on a set of (Hungarian) speech databases. In order to find the best fitting word-sequences, language information is obviously quite important. Incorporating this kind of knowledge into a speech",
            "title": "Various Robust Search Methods in a Hungarian Speech Recognition System"
        },
        {
            "group": 80,
            "name": "10.1.1.107.176",
            "keyword": "digital image library, information retrieval, thesaurus, subject hierarchy, normalisation process, translation, automatic",
            "author": "Jos\u00e9 C. Gonz\u00e1lez, Julio Villena, Cristina Moreno, Jos\u00e9 L. Mart\u00ednez-fern\u00e1ndez",
            "abstract": "The topics addressed in this paper are threefold: First, techniques for the semi-automatic normalization of image descriptors in a digital image collection fromfree-text titles and keywords. Second, the efficient construction of thesauri for specific image collections. And third, the optimisation of search mechanisms to deal with the special characteristics of image collections and with the use through web-based search interfaces. The solutions presented here have been developed in the framework of a commercial project intended to improve image search in a website for selling photographs through the web. The ultimate goal of this project is to improve customer accessibility to a collection of more than two million photographs. This project has been developed by the company DAEDALUS, S.A. for the Internet website www.stockphotos.es, of the company Stock Photos S.L.",
            "title": "Abstract Semi-Automatic Extraction of Thesauri and Semantic Search in a Digital Image Archive"
        },
        {
            "group": 81,
            "name": "10.1.1.107.2631",
            "keyword": "",
            "author": "Nikita Schmidt, Ahmed Patel",
            "abstract": "This paper reports on the authors \u2019 experience in developing and running a distributed system for Web search and search-based document placement (advertising). Distributed architecture was chosen to address scalability issues and to provide seamless search service for the \u2018invisible Web\u2019. The system consists of topical document collections and request routing infrastructure. Request routing to the appropriate document collection is performed for both search and placement requests. Other features of the system include support for structured attribute-based search, topic-specific (focused) Web crawling, and payment transactions. Security issues arising from the distributed nature of the system as well as from revenue generation are discussed. Important architectural and design decisions are presented and analysed in the light of implementation and pilot operation of the system. 1.",
            "title": "DESIGN AND IMPLEMENTATION OF A DISTRIBUTED SEARCH AND ADVERTISING SYSTEM"
        },
        {
            "group": 82,
            "name": "10.1.1.107.3867",
            "keyword": "",
            "author": "Justin Klekota, Frederick P. Roth, Stuart L. Schreiber, Alfonso Valencia",
            "abstract": "Query Chem (www.QueryChem.com) is a Web program that integrates chemical structure and text-based searching using publicly available chemical databases and Google\u2019s Web Application Program Interface (API). Query Chem makes it possible to search the Web for information about chemical structures without knowing their common names or identifiers. Furthermore, a structure can be combined with textual query terms to further restrict searches. Query Chem\u2019s search results can retrieve many interesting structure-property relationships of biomolecules on the Web. The recent proliferation of Web-based chemical databases has made information about millions of compound structures and their biological properties publicly available. Chembank 1, ZINC 2, Pubchem 3, ChemDB 4, and ChemMine 5 are among the increasing number of chemical databases. Web-based tools, including Chmoogle 6 and",
            "title": "Query Chem: A Google-Powered Web Search Combining Text and Chemical Structures"
        },
        {
            "group": 83,
            "name": "10.1.1.107.391",
            "keyword": "",
            "author": "Ziyang Liu",
            "abstract": "users to easily access XML data without the need of learning XPath or XQuery and studying possibly complex data schemas. XSeek addresses a challenge in XML keyword search that has been neglected in the literature: how to determine the desired return information, analogous to inferring a \u201creturn \u201d clause in XQuery. To infer the search semantics, XSeek recognizes possible entities and attributes in the data, differentiates search predicates and return specifications in the keywords, and generates meaningful search results based on the analysis. 1.",
            "title": "XSeek: A Semantic XML Search Engine Using Keywords"
        },
        {
            "group": 84,
            "name": "10.1.1.107.5260",
            "keyword": "",
            "author": "Rune Devik",
            "abstract": "transmitted, in any form, or by any means, electronic, mechanical, photocopying, recording, or otherwise, without the prior consent of the publisher. p-SARS",
            "title": "Peer-to-Peer Search for A Recommender System"
        },
        {
            "group": 85,
            "name": "10.1.1.107.5956",
            "keyword": "similarity search, multidimensional access method, bounding sphere",
            "author": "Tran Khanh  Dang ",
            "abstract": "Approaches to indexing and searching feature vectors are an indispensable factor to support similarity search effectively and efficiently. Such feature vectors extracted from real world objects are usually presented in the form of multidimensional data. As a result, many multidimensional data index techniques have been widely introduced to the research community. These index techniques are categorized into two main classes: SP (space partitioning)/KD-tree-based and DP (data partitioning)/R-tree-based. Although there are a variety of \u201cmixed \u201d index techniques, which try to inherit positive aspects from more than one index technique, the number of techniques that are derived from these two main classes is just a few. In this paper, we introduce such a \u201cmixed\u201d index, the SH-tree: a novel and flexible super hybrid index structure for multidimensional data. Theoretical analyses indicate that the SH-tree is a good combination of the two index technique families with respect to both the presentation and search algorithms. It overcomes shortcomings and makes use of their positive aspects to facilitate efficient similarity searches in multidimensional data spaces. Empirical experiment results with both uniformly distributed and real data sets will confirm our theoretical analyses.",
            "title": "The SH-Tree: A Novel and Flexible Super Hybrid Index Structure for Similarity Search on Multidimensional Data "
        },
        {
            "group": 86,
            "name": "10.1.1.107.7596",
            "keyword": "Genetic Algorithm",
            "author": "M. Koorangi, K. Zamanifar",
            "abstract": "In this paper, the problems of current web search engines are analyzed, and the need for a new design is justified. Some ideas on how to improve current web search engines are presented, and then an adaptive method for web meta-search engines with a multi-agent specially the mobile agents is presented to make search engines work more efficiently. In the method, the cooperation between stationary and mobile agents is used to make more efficiency. The meta-search engine gives the user needed documents based on the multi-stage mechanism. The merge of the results obtained from the search engines in the network is done in parallel. Using a reduction parallel algorithm, the efficiency of this method is increased. Furthermore, a feedback mechanism gives the meta-search engine the user\u2019s suggestions about the found documents, which leads to a new query using a genetic algorithm. In the new search stage, more relevant documents are given to the user. The practical experiments were performed in Aglets programming environment. The results achieved from these experiments confirm the efficiency and adaptability of the method. Key words:",
            "title": "A Distributed Agent Based Web Search using a Genetic Algorithm"
        },
        {
            "group": 87,
            "name": "10.1.1.107.7866",
            "keyword": "digital libraries, XML, XML search system, XML database",
            "author": "Pedro Manuel, Almeida Joaquim, Arnaldo Martins, Joaquim Sousa",
            "abstract": "Abstract- This article presents a framework for a XML based search system composed of three layers: data layer, logic layer and presentation layer. In all three layers XML related technologies are used to store, search, transport and present information like Native XML Databases, Web Services and XSLT. Two examples of an implementation of a XML based search system are presented and compared, one based in open-source tools and another in a commercial suite. The open-source system uses XIndice to store the XML information and JAVA technologies to create the Web Services and the presentation while the commercial system uses Microsoft IndexServer with a XML Filter to analyze the XML Information and the.NET framework to create the Web Services and presentation of the information. Both systems have strengths and weaknesses that are presented in this article.",
            "title": "FRAMEWORK FOR A XML BASED SEARCH SYSTEM: A COMPONENT OF THE PORTUGUESE PARLIAMENT DIGITAL LIBRARY"
        },
        {
            "group": 88,
            "name": "10.1.1.107.9476",
            "keyword": "",
            "author": "Carlos Castillo",
            "abstract": "Search engines provide search results based on a large repository of pages downloaded by a web crawler from several servers. To provide best results, this repository must be kept as fresh as possible, but this can be difficult due to the large volume of pages involved and to the fact that polling is the only method for detecting changes. In this paper, we explore and compare several alternatives for keeping fresh repositories that involve some degree of cooperation from servers. 1.",
            "title": "Cooperation schemes between a web server and a web search engine"
        },
        {
            "group": 89,
            "name": "10.1.1.108.2269",
            "keyword": "",
            "author": "Madhukar R. Korupolu, C. Greg Plaxton , Rajmohan Rajaraman",
            "abstract": "In this paper, we study approximation algorithms for several NP-hard facility location problems. We prove that a simple local search heuristic yields polynomial-time constant-factor approximation bounds for the metric versions of the uncapacitated k-median problem and the uncapacitated facility location problem. (For the k-median problem, our algorithms require a constant-factor blowup in the parameter k.) This local search heuristic was rst proposed several decades ago, and has been shown to exhibit good practical performance in empirical studies. We also extend the above results to obtain constant-factor approximation bounds for the metric versions of capacitated k-median and facility location problems.  ",
            "title": "Analysis of a local search heuristic for facility location problems"
        },
        {
            "group": 90,
            "name": "10.1.1.108.2853",
            "keyword": "",
            "author": "David W. Bulger",
            "abstract": "Grover\u2019s quantum algorithm promises a quadratic acceleration for any problem formulable as a search. For unstructured search problems, its implementation and performance are well understood. The curse of dimensionality and the intractibility of the general global optimisation problem require any identifiable structure or regularity to be incorporated into a solution method. This paper addresses the application of Grover\u2019s algorithm when a local search technique is available, thereby combining the quadratic acceleration with the acceleration seen in the multistart method.",
            "title": "Combining a local search and Grover\u2019s algorithm in black-box global optimisation"
        },
        {
            "group": 91,
            "name": "10.1.1.108.3612",
            "keyword": "",
            "author": "Ram\u00f3n B\u00e9jar, Alba Cabiscol, Felip Many\u00e0",
            "abstract": "Nowadays, the undergraduate curriculum in computer science of most universities includes an introductory course in logic. In this kind of course, the syllabus usually includes the syntax and semantics of propositional and \u2026rst-order logic, as well as some proof systems such as natural deduction, resolution and",
            "title": "First International Congress on Tools for Teaching Logic Local Search Algorithms for SAT in a Course in Logic for Computer Science"
        },
        {
            "group": 92,
            "name": "10.1.1.108.4633",
            "keyword": "A",
            "author": "",
            "abstract": "7. External Examiner (for Dissertations only) 8. Expert Comments on the Work and Facility for the Feedback from the Users 9. Abstract of the Work A Search Engine is very important in any information system; it can help us easy to search available information quickly. In Content Management System, we also need a search engine to find information from itself and from existing resources. The research study describes an overview of federated search method and implementation of prototype Search Engine within the Plone CMS. That can search useful information from external sites and relational databases. Moreover, this research study also mentions about Ajax technology that it is used to build LiveSearch function on the Search Engine. The research study uses resources from the AIT\u2019s websites including webpages and relational database as a case study.",
            "title": "ELECTRONIC DOCUMENTATION FORM FEDERATED SEARCH OVER DISTRIBUTED CONTENT: A CASE STUDY WITH PLONE CMS FOR SEARCHING EXTERNAL SITES AND EXTERNAL DATABASES"
        },
        {
            "group": 93,
            "name": "10.1.1.108.4678",
            "keyword": "",
            "author": "Wen Qi Huang, Yu Li, Bernard Jurkowiak, Chu Min Li, Ru Chu Xu",
            "abstract": "Abstract. We propose a two-level search strategy to solve a two dimensional circle packing problem. At the first level, a good enough packing algorithm called A1.0 uses a simple heuristic to select the next circle to be packed. This algorithm is itself used at the second level to select the next circle to be packed. The resulted packing procedure called A1.5 considerably improves the performance of the algorithm in the first level, as shown by experimental results. We also apply the approach to solve other CSPs and obtain interesting results. 1",
            "title": "A Two-Level Search Strategy for Packing Unequal Circles into a Circle Container"
        },
        {
            "group": 94,
            "name": "10.1.1.108.5371",
            "keyword": "Key words. robot travel, D \u2217, grid graph, girth, planar graph, search heuristic, Mars rover",
            "author": "Apurva Mudgal, Craig Tovey, Sam Greenberg, Sven Koenig",
            "abstract": "Abstract. D \u2217 is a greedy heuristic planning method that is widely used in robotics, including several Nomad class robots and the Mars rover prototype, to reach a destination in unknown terrain. We obtain nearly sharp lower and upper bounds of \u03a9(n log n / log log n) and O(n log n), respectively, on the worst-case total distance traveled by the robot, for the grid graphs on n vertices typically used in robotics applications. For arbitrary graphs we prove an O(n log 2 n) upper bound.",
            "title": "BOUNDS ON THE TRAVEL COST OF A MARS ROVER PROTOTYPE SEARCH HEURISTIC \u2217"
        },
        {
            "group": 95,
            "name": "10.1.1.108.6367",
            "keyword": "",
            "author": "J Gerard Wolff",
            "abstract": "This paper describes a novel approach to grammar induction that has been developed within a framework designed to integrate learning with other aspects of computing, AI, mathematics and logic. This framework, called information compression by multiple alignment, unification and search (ICMAUS), is founded on principles of Minimum Length Encoding pioneered by Solomonoff and others. Most of the paper describes SP70, a computer model of the ICMAUS framework that incorporates processes for unsupervised learning of grammars. An example is presented to show how the model can infer a plausible grammar from appropriate input. Limitations of the current model and how they may be overcome are briefly discussed. ",
            "title": "Unsupervised grammar induction in a framework of information compression by multiple alignment, unification and search "
        },
        {
            "group": 96,
            "name": "10.1.1.108.649",
            "keyword": "",
            "author": "Oren Eli Zamir",
            "abstract": " ",
            "title": "Clustering Web Documents: A Phrase-Based Method for Grouping Search Engine Results"
        },
        {
            "group": 97,
            "name": "10.1.1.108.7634",
            "keyword": "",
            "author": "David J. Bruemmer, Ronald L. Boring, Douglas A. Few, Julie L. Marble, Miles C. Walton",
            "abstract": "Abstract- The quality of human-robot interaction trails other advances in robotics and may prove to be a limiting factor when deploying remote, mobile robots for critical applications. One reason is that most autonomous robot behaviors are not robust and often degrade in unstructured environments. Another reason is that the design of human-robot interaction (HRI) and interfaces fails to follow basic usability principles or be informed by basic concepts of human-computer interaction. To address both these challenges, we have used a development cycle of iterative usability testing and redesign to hone both our interface and the robot behaviors that support it. The present paper presents results from a wide swathe of over 100 novices who used the resulting system to accomplish a real-world search and detection task. The current interface proved to be highly usable by novices, regardless of age or gender. The study demonstrates the utility of effective robot autonomy and examines the benefits of mixed-initiative control. In particular, the study compares the performance achieved when the robot takes initiative to support human driving versus the case where the human takes initiative to support autonomous robot driving. Results indicate that performance is better when the robot is in the driver\u2019s seat. Optimal performance was achieved when the operator focuses on the search and rescue task and provides only intermittent direction to the robot. Keywords: Human-robot interaction, usability evaluation, novice performance, urban search and rescue. 1",
            "title": "i call shotgun!\u201d: An evaluation of mixed-initiative control for novice users of a search and rescue robot"
        },
        {
            "group": 98,
            "name": "10.1.1.108.8144",
            "keyword": "",
            "author": "Stephen V. Chenoweth",
            "abstract": "In high-performance A * searching to solve satisficing problems, there is a critical need to design heuristics which cause low time-complexity. In order for humans or machines to do this effectively, there must be an understanding of the domainindependent properties that such heuristics have. We snow that, contrary to common belief, accuracy is not critical; the key issue is whether or not heuristic values are concentrated closely near a rapidly growing &quot;central function. &quot; As an application, we show that, by &quot;multiplying &quot; heuristics, it is possible to reduce exponential average timecomplexity to polynomial. This is contrary to conclusions drawn from previous studies. Experimental and theoretical examples are given. 1",
            "title": "HIGH-PERFORMANCE A * SEARCH [NG RAPIDLY GROWING HEURISTICS"
        },
        {
            "group": 99,
            "name": "10.1.1.109.1061",
            "keyword": "",
            "author": "Xirong Li, Dong Wang, Jianmin Li, Bo Zhang",
            "abstract": "Though both quantity and quality of semantic concept detection in video are continuously improving, it still remains unclear how to exploit these detected concepts as semantic indices in video search, given a specific query. In this paper, we tackle this problem and propose a video search framework which operates like searching text documents. Noteworthy for its adoption of the well-founded text search principles, this framework first selects a few related concepts for a given query, by employing a tf-idf like scheme, called c-tf-idf, to measure the informativeness of the concepts to this query. These selected concepts form a concept subspace. Then search can be conducted in this concept subspace, either by a Vector Model or a Language Model. Further, two algorithms, i.e., Linear Summation and Random Walk through Concept-Link, are explored to combine the concept search results and other baseline search results in a reranking scheme. This framework is both effective and efficient. Using a lexicon of 311 concepts from the LSCOM concept ontology, experiments conducted on the TRECVID 2006 search data set show that: when used solely, search within the concept subspace achieves the state-of-the-art concept search result; when used to rerank the baseline results, it can improve over the top 20 automatic search runs in TRECVID 2006 on average by approx. 20%, on the most significant one by approx. 50%, all within 180 milliseconds on a normal PC.",
            "title": "Video search in concept subspace: A text-like paradigm"
        },
        {
            "group": 100,
            "name": "10.1.1.109.1428",
            "keyword": "",
            "author": "Mirja Iivonen, Diane H. Sonnenwald",
            "abstract": "We propose a model of the search term selection process based on our empirical study of professional 1.",
            "title": "From translation to navigation of different discourses: a model of search term selection during the pre-online stage of the search process"
        },
        {
            "group": 101,
            "name": "10.1.1.109.4049",
            "keyword": "World Wide Web, Search Engines, Information Retrieval, PageRank, Google",
            "author": "Sergey Brin, Lawrence Page",
            "abstract": "In this paper, we present Google, a prototype of a large-scale search engine which makes heavy use of the structure present in hypertext. Google is designed to crawl and index the Web efficiently and produce much more satisfying search results than existing systems. The prototype with a full text and hyperlink database of at least 24 million pages is available at http://google.stanford.edu/\r\n\r\nTo engineer a search engine is a challenging task. Search engines index tens to hundreds of millions of web pages involving a comparable number of distinct terms. They answer tens of millions of queries every day. Despite the importance of large-scale search engines on the web, very little academic research has been done on them. Furthermore, due to rapid advance in technology and web proliferation, creating a web search engine today is very different from three years ago. This paper provides an in-depth description of our large-scale web search engine -- the first such detailed public description we know of to date.\r\n\r\nApart from the problems of scaling traditional search techniques to data of this magnitude, there are new technical challenges involved with using the additional information present in hypertext to produce better search results. This paper addresses this question of how to build a practical large-scale system which can exploit the additional information present in hypertext. Also we look at the problem of how to effectively deal with uncontrolled hypertext collections where anyone can publish anything they want.",
            "title": "The Anatomy of a Large-Scale Hypertextual Web Search Engine"
        },
        {
            "group": 102,
            "name": "10.1.1.109.5049",
            "keyword": "Key words, mucin, MUC gene, genome-wide search, bioinformatics, in situ",
            "author": "Yin Chen, Yu Hua Zhao, Tejas Baba Kalaslavadi, Edward Hamati, Keith Nehrke, Anh Dao Le, David K. Ann, Reen Wu",
            "abstract": "hybridization Copyright (C) 2003 by the American Thoracic Society. Gel-forming mucins are major contributors to the viscoelastic properties of mucus secretion. Currently, four gel-forming mucin genes have been identified: MUC2, MUC5AC, MUC5B, and MUC6. All these genes have five major cysteine rich domains (four von Willebrand Factor (vWF) C or D domains and one Cystine-knot (CT) domain) as their distinctive features, in contrast to other non-gel-forming type of mucins. The CT domain is believed to be involved in the initial mucin dimer formation and have very succinct relationship between different gel-forming mucins across different species. Because of gene duplication and evolutional modification, it is very likely that other gel forming mucin genes exist. In order to search for new gel-forming mucin candidate genes, a \u201cHidden Markov Model\u201d(HMM) was built from the common features of the CT domains of those gel-forming mucins. By using this model to screen all protein databases as well as the six-frame translated EST and translated human genomic databases, we",
            "title": "Genome-wide search and identification of a novel gel-forming mucin MUC19/Muc19 in glandular tissues"
        },
        {
            "group": 103,
            "name": "10.1.1.109.5074",
            "keyword": "",
            "author": "Valery Sklyarov, Iouliia Skliarova",
            "abstract": "Abstract. The paper suggests architecture of a reconfigurable processor, which can be customized for implementing different search algorithms over discrete matrices. Such algorithms might be used for solving various problems of combinatorial optimization, such as covering, Boolean satisfiability, etc. The proposed architecture contains memory blocks for binary or ternary matrix, general-purpose registers, five stacks, that make possible to carry out recursive search procedures based on decision tree, and a reprogrammable functional unit that allows to perform the required operations over binary and ternary vectors. Two levels of control circuits have been suggested. The first (top) level permits to realize the search algorithm. The second (bottom) level allows to implement operations that are required for the algorithm. The same architecture enables us to implement different search algorithms by reprogramming RAM (ROM) \u2013 based components of control circuits.",
            "title": "Architecture of a Reconfigurable Processor for Implementing Search Algorithms over Discrete Matrices"
        },
        {
            "group": 104,
            "name": "10.1.1.109.6142",
            "keyword": "",
            "author": "Francois Saidi, Olivier Stasse, Kazuhito Yokoi, Fumio Kanehiro",
            "abstract": "Abstract \u2014 This paper presents an object active visual search behavior in a 3D environment performed by a HRP-2 humanoid robot. The search is formalized as an optimization problem in which the goal is to maximize the target detection probability while minimizing the energy/distance and time to achieve the task. Natural constraints on the camera parameter space based on the characteristics of the recognition system are used to reduce the dimension of the problem and to speed up the optimization process to achieve a real time behavior. We present simulation and real experimental results using an HRP-2 robot. I.",
            "title": "Online Object Search with a Humanoid Robot"
        },
        {
            "group": 105,
            "name": "10.1.1.109.6366",
            "keyword": "documents, namely, Knowledge Factor (Kf\u2019, Knowledge Quotient (Kq\u2019, and Context Sensitive Index (CSI). Keywords. Heuristic Search, Knowledge Processing System Integration, Intelligent Knowledge Management, Search Engines",
            "author": "K. Satya, Sai Prakash",
            "abstract": "Abstract. Wading through the innumerable number of pages to find the relevant result is a daunting experience for most of the web searchers. The problem is compounded with that of growing web. Though popular search engines (SE) such as Google and Altavista are employing research groups and adopting the state of the art technology to yield the relevant result set, still relevancy remains as an open issue. In this paper we attempt to overcome this problem by suggesting the knowledge centric approach. We develop a framework that encapsulates the concept of knowledge and extend the logic-based representation of facts to capture intuition and then incorporate the intuitive knowledge into the general knowledgebase. We used connectionist model as a knowledge acquisition tool. This paper also introduces three parameters, Knowledge Factor (Kf), Knowledge Quotient (Kq), and User Relevancy Index (URI) to quantify the relevancy on a per user basis. Every individual has a definite Kq and varying Kf. These two factors identify one\u2019s URI and give a measure of his/her satisfaction. Similarly three corresponding parameters are introduced to categorize",
            "title": "Relevancy in Search Engines: A Knowledge Centric Approach"
        },
        {
            "group": 106,
            "name": "10.1.1.109.6611",
            "keyword": "",
            "author": "Blai Bonet",
            "abstract": "Dynamic Programming provides a convenient and unified framework for studying many state models used in AI but no algorithms for handling large spaces. Heuristic-search methods, on the other hand, can handle large spaces but lack a common foundation. In this work, we combine the benefits of a general dynamic programming formulation with the power of heuristic-search techniques for developing an algorithmic framework, that we call Learning in Depth-First Search, that aims to be both general and effective. The basic LDFS algorithm searches for solutions by combining iterative, bounded depth-first searches, with learning in the sense of Korf\u2019s LRTA * and Barto\u2019s et al. RTDP. In each iteration, if there is a solution with cost not exceeding a lower bound, then the solution is found, else the process restarts with the lower bound and the value function updated. LDFS reduces to IDA * with Transposition Tables over deterministic models, but solves also non-deterministic, probabilistic, and game tree models, over which a slight variation reduces to the stateof-the-art MTD algorithm. Over Max AND/OR graphs, on the other hand, LDFS is a new algorithm which appears to be quite competitive with AO*.",
            "title": "Learning Depth-First Search: A Unified Approach to Heuristic Search in Deterministic and Non-Deterministic Settings, and its application to MDPs"
        },
        {
            "group": 107,
            "name": "10.1.1.109.6942",
            "keyword": "",
            "author": "Demetrios Zeinalipour-yazti, Vana Kalogeraki, Dimitrios Gunopulos",
            "abstract": "Abstract\u2014The emerging Peer-to-Peer (P2P) model has become a very powerful and attractive paradigm for developing Internet-scale systems for sharing resources, including files and documents. The distributed nature of these systems, where nodes are typically located across different networks and domains, inherently hinders the efficient retrieval of information. In this paper, we consider the effects of topologically aware overlay construction techniques on efficient P2P keyword search algorithms. We present the Peer Fusion (pFusion) architecture that aims to efficiently integrate heterogeneous information that is geographically scattered on peers of different networks. Our approach builds on work in unstructured P2P systems and uses only local knowledge. Our empirical results, using the pFusion middleware architecture and data sets from Akamai\u2019s Internet mapping infrastructure (AKAMAI), the Active Measurement Project (NLANR), and the Text REtrieval Conference (TREC) show that the architecture we propose is both efficient and practical. Index Terms\u2014Information retrieval, peer-to-peer, overlay construction algorithms. 1",
            "title": "pFusion: A P2P Architecture for Internet-Scale Content-Based Search and Retrieval"
        },
        {
            "group": 108,
            "name": "10.1.1.109.7062",
            "keyword": "",
            "author": "Mireille Palpant, Christian Artigues, Cristian Oliva",
            "abstract": "In this paper, we present a solution approach based on Chv\u00e1tal\u2019s Resolution Search [2] to solve combinatorial optimization problems. Resolution Search constitutes an alternative to classical enumeration methods and possesses strong connections to nogood recording approaches, and in particular dynamic backtracking, though it is designed to deal with binary linear programming problems. Accordingly, we suggest to hybridize the procedure using constraint programming techniques, in order to apply it to Constraint Satisfaction Problems (CSP). Furthermore, the introduction of such techniques allows some specific improvements that speed up the process and let many outcomes for further research. In order to evaluate the interest of the proposed method, we use it to tackle some particular graph coloring instances, known as the Queens n 2 problem. The experimental results obtained so far prove the validity of the approach and compete with state-of-the-art complete solution methods. 1",
            "title": "MARS: a hybrid scheme based on Resolution Search and Constraint Programming for Constraint Satisfaction Problems."
        },
        {
            "group": 109,
            "name": "10.1.1.11.110",
            "keyword": "",
            "author": "B P\u00e9rez-Rend\u00f3n, G. Garc\u00eda Segura, N. Langer",
            "abstract": "The observed abundances in the Cas A supernova remnant (SNR) are used together with the results of evolutionary calculations of massive stars to construct an evolutionary picture for the Cas A progenitor star. From the structure shown by the remnant, it is believed that the precursor star was a WR with a lifetime of 10 4 years. With this assumption and the chemical abundances produced during the stellar nucleosynthesis we present results which suggest that the precursor of Cas A was a star with a mass between 29\u201330 M on the ZAMS.",
            "title": "A Search for the Cassiopeia a SN Progenitor"
        },
        {
            "group": 110,
            "name": "10.1.1.11.1896",
            "keyword": "",
            "author": "Timo Slawinski,  Angelika Krone, Peter Krause",
            "abstract": "In the field of data-based fuzzy modeling two approaches are predominately applied: Firstly, the optimization of an entire rule base by minimizing the modeling error and secondly to incrementally set up the rule base by individual tested rules. Following the second approach the search space increases exponentially with the number of input variables. On the other hand, due to the limited amount of available data, the search space becomes more and more sparsely populated. Therefore, part of the possible rules are no longer supported by any data set and can be neglected in the search process. The tree-oriented rule search concept, presented in this paper, takes advantage of this fact and leads to a drastically reduced computational effort.",
            "title": "Efficient Design of a Complete Rule Search in Sparsely Populated Search Spaces"
        },
        {
            "group": 111,
            "name": "10.1.1.11.4922",
            "keyword": "",
            "author": "Liam J. Bannon,  Kjeld Schmidt",
            "abstract": "The title of this paper was chosen to highlight the fact that the label CSCW, although widely adopted as the acronym for the field of Computer Supported Cooperative Work, has been applied to computer applications of very different ilk. It is not at all clear what are the unique identifying elements of this research area. This paper provides a framework for approaching the issue of cooperative work and its possible computer support. The core issues are identified and prospects for the field are outlined.",
            "title": "CSCW: Four Characters in Search of a Context"
        },
        {
            "group": 112,
            "name": "10.1.1.11.5627",
            "keyword": "",
            "author": "George E. Randall, George E. R, Hans E. Hartse,  Lee K. Steck",
            "abstract": "We investigate the performance of array beams formed using the observed slowness and azimuth of arrival for large, well located events. For this study, we use event locations from the United States Geological Survey (USGS) Earthquake  Data Reports (EDR). The deviations of the observed azimuths of arrival from the predicted azimuths of arrival  based on a suite of events are used to estimate correction surfaces to be applied for improved azimuth estimation for phase association and event location. We have begun an exploratory effort to study the residual waveforms for seismic array elements. The individual seismic traces from array elements are shifted to a common geographic reference point using delays based on the observed slowness and azimuth of arrival, and then averaged to form the array beam. We then compute the residual seismograms by subtracting the beam from the time shifted traces for each element and study the residual traces for systematic effects. Any systematic effects in the residuals point to deviations from the  assumed ideal array behavior. If we can identify and correct for systematic array deviations, we hope to improve  array detection capability, as well as array estimates of azimuth and slowness.",
            "title": "Attempts to Enhance Array Detection Capability: A Search for Systematic Array Residuals"
        },
        {
            "group": 113,
            "name": "10.1.1.11.6298",
            "keyword": "",
            "author": "Nico Roos, Yongping Ran, Jaap Van Den Herik",
            "abstract": "Many hard practical problems such as Time Tabling and Scheduling  can be formulated as Constraint Satisfaction Problems. For these CSPs, powerful  problem-solving methods are available. However, in practice, the problem  definition may change over time. Each separate change may invoke a new CSP  formulation. The resulting sequence of CSPs is denoted as a Dynamic CSP.",
            "title": "Combining Local Search and Constraint Propagation to find a minimal change solution for a Dynamic CSP"
        },
        {
            "group": 114,
            "name": "10.1.1.11.7241",
            "keyword": "Capacitated minimum spanning tree, metaheuristics, GRASP, local search, neighborhood reduction, short term memory, path-relinking",
            "author": "Mauricio C. de Souza,  Christophe Duhamel, Celso C. Ribeiro",
            "abstract": "We describe a new neighborhood structure for the capacitated minimum spanning tree problem. This neighborhood structure is used by a local search strategy, leading to good trade-offs between solution quality and computation time. We also propose a GRASP with path-relinking heuristic. It uses a randomized version of a savings heuristic in the construction phase and an extension of the above local search strategy, incorporating some short term memory elements of tabu search. Computational results on benchmark problems illustrate the effectiveness of this approach, which is competitive with the best heuristics in the literature in terms of solution quality. The GRASP heuristic using a memory-based local search strategy improved the best known solution for some of the largest benchmark problem.",
            "title": "A GRASP heuristic for the capacitated minimum spanning tree problem using a memory-based local search strategy"
        },
        {
            "group": 115,
            "name": "10.1.1.11.859",
            "keyword": "",
            "author": "Michael Lewis, Katia Sycara, Illah Nourbakhsh",
            "abstract": "We are developing simulations of the National Institute of Standards and Technology (NIST) Reference Test Facility for Autonomous Mobile Robots (Urban Search and Rescue) in order to develop and test our strategies for Robots-Agents-People (RAP) team coordination and control. The NIST USAR Test Facility is a standardized disaster environment consisting of three scenarios of progressive difficulty: Yellow, Orange, and Red arenas. The USAR task focuses on robot behaviors, and physical interaction with standardized but disorderly rubble filled environments. As part of our research effort we are constructing and permanently housing a physical replica of the Orange arena at Carnegie Mellon University. A simulation of the Orange arena was constructed first in order to allow comparisons between simulated and real environments as soon as construction of the physical Orange Arena is completed. We hope to use the simulations to provide a testbed in which to evaluate rapidly prototyped interfaces and control strategies prior to the construction and testing of physical robots. This paper describes our simulation approach based on the use of the Unreal game engine to provide graphics and physics and simplified CAD models textured from digital photographs to model the environment.",
            "title": "Developing a Testbed for Studying Human-Robot Interaction in Urban Search and Rescue"
        },
        {
            "group": 116,
            "name": "10.1.1.11.9154",
            "keyword": "",
            "author": "N. Monmarch\u00e9, G. Venturini, M. Slimane",
            "abstract": "We present in this paper a new model of artificial ants foraging behavior  based on a population of primitive ants (Pachycondyla apicalis) and its application to the general problem of optimization. These ants are characterized  by a relatively simple but efficient strategy of prey search where individuals  hunt alone and try to cover uniformly a given area around their nest. This  is performed by parallel local searches on hunting sites with a sensitivity to  successful sites. Also, the nest is moved periodically. This corresponds in optimization  to an algorithm performing several random parallel searches which  are localized uniformly in a sub-space centered around a point. Moving the  nest corresponds to a restart operator of the parallel searches where the central  point is moved. Furthermore, these ants are able to perform some form of  recruitment called \"tandem-running\" where one leading ant is followed by another  one to a given interesting site. We have applied this algorithmic model,  called API, to combinatorial and numerical optimization problems.",
            "title": "On how the ants Pachycondyla apicalis are suggesting a new search algorithm"
        },
        {
            "group": 117,
            "name": "10.1.1.11.941",
            "keyword": "Adaptive Search Systems 1. ADAPTIVE SEARCH SYSTEMS",
            "author": "Ryen W. White,  Joemon M. Jose, Ian Ruthven",
            "abstract": "In this paper we present an evaluation of a behaviour-based adaptive search interface that predicts the current state of a user's information need based on their interaction. We evaluate the hypotheses that our adaptive system selects additional query words that closely describe user needs and is able to accurately depict the degree of change in these needs. Our evaluation, with real users and different types of information seeking scenario, shows that these hypotheses hold.",
            "title": "Adapting to Evolving Needs: Evaluating a Behaviour-Based Search Interface"
        },
        {
            "group": 118,
            "name": "10.1.1.11.9981",
            "keyword": "Pachycondyla apicalis ants, Foraging behavior, Numerical optimization, Ant algorithms",
            "author": "Nicolas Monmarch\u00e9,  Gilles Venturini,  Mohamed Slimane",
            "abstract": "In this paper we present a new optimization algorithm based on a model of the foraging behavior of a population of primitive ants (Pachycondyla apicalis). These ants are characterized by a relatively simple but efficient strategy for prey search in which individuals hunt alone and try to cover a given area around their nest. The ant colony search behavior consists of a set of parallel local searches on hunting sites with a sensitivity to successful sites. Also, their nest is periodically moved. Accordingly, the proposed algorithm performs parallel random searches in the neighborhood of points called hunting sites. Hunting sites are created in the neighborhood of a point called nest. At constant intervals of time the nest is moved, which corresponds to a restart operator which re-initializes the parallel searches. We have applied this algorithm, called API, to numerical optimization problems with encouraging results. 2000 Elsevier Science B.V.",
            "title": "On how Pachycondyla apicalis ants suggest a new search algorithm"
        },
        {
            "group": 119,
            "name": "10.1.1.110.1094",
            "keyword": "",
            "author": "",
            "abstract": "Abstract \u2013 Many P2P-based storage systems use distributed indexing service for searching documents. There are two security issues when the nodes providing the index service are compromised by adversaries. First, the adversaries may delete the indexes or stop the program of indexing service, making the affected documents disappear in the search infrastructure. Second, the adversaries may leak the locations of the storage nodes hosting certain documents, making those nodes the target of DOS attacks. We propose a protocol called SCUBE which addresses these attacks by using secret-sharing based threshold cryptography and the concept of virtual addresses. Our results show that SCUBE performs appreciably well under different attack scenarios and incurs nominal overhead. A working prototype of SCUBE has also been implemented and tested on the Planetlab testbed. 1",
            "title": "SCUBE: A DoS-Resistant Distributed Search Protocol"
        },
        {
            "group": 120,
            "name": "10.1.1.110.2327",
            "keyword": "Search Engines, Information Retrieval, PageRank, Google",
            "author": "Sergey Brin",
            "abstract": "In this paper, we present Google, a prototype of a large-scale search engine which makes heavy use of the structure present in hypertext. Google is designed to crawl and index the Web efficiently and produce much more satisfying search results than existing systems. The prototype with a full text and hyperlink database of at least 24 million pages is available at",
            "title": "The Anatomy of a Search Engine The Anatomy of a Large-Scale Hypertextual Web Search Engine"
        },
        {
            "group": 121,
            "name": "10.1.1.110.4061",
            "keyword": "crossover, schemata, Geiringer theorem, Markov process, stationary distribution",
            "author": "Boris Mitavskiy, Jonathan Rowe",
            "abstract": "The frequency with which various elements of the search space of a given evolutionary algorithm are sampled is affected by the family of recombination (reproduction) operators. The original Geiringer theorem tells us the limiting frequency of occurrence of a given individual under repeated application of crossover alone for the classical genetic algorithm. Recently, Geiringer\u2019s theorem has been generalized to include the case of linear GP with homologous crossover (which can also be thought of as a variable length GA). In the current paper we prove a general theorem which tells us that under rather mild conditions on a given evolutionary algorithm, call it A, the stationary distribution of a certain Markov chain of populations in the absence of selection is unique and uniform. This theorem not only implies the already existing versions of Geiringer\u2019s theorem, but also provides a recipe of how to obtain similar facts for a rather wide class of evolutionary algorithms. The techniques which are used to prove this theorem involve a classical fact about random walks on a group and may allow us to compute and/or estimate the eigenvalues of the corresponding Markov transition matrix which is directly related to the rate of convergence towards the unique limiting distribution.",
            "title": "An extension of geiringer\u2019s theorem for a wide class of evolutionary search algorithms"
        },
        {
            "group": 122,
            "name": "10.1.1.110.4338",
            "keyword": "",
            "author": "Hercules Dalianis",
            "abstract": "In this paper we have investigated 128 high frequent Swedish compound queries (6.2 per thousand) with no search results among 1.6 million searches carried out at nine public web sites containing all together 100,000 web pages in Swedish. To these compound queries we added a compound splitter as a pre-processor and we found that after decompounding these queries they gave relevant results in 64 percent of the cases instead of zero percent hits. We give also examples on some rules for optimal compound splitting in a search situation. 1",
            "title": "Improving search engine retrieval using a compound splitter for Swedish"
        },
        {
            "group": 123,
            "name": "10.1.1.110.5644",
            "keyword": "",
            "author": "Hai He, Weiyi Meng, Clement Yu, Zonghuan Wu",
            "abstract": "We demonstrate WISE-Integrator \u2013 an automatic search interface extraction and integration tool. The basic research issues behind this tool will also be explained.  ",
            "title": " Wise-integrator: A system for extracting and integrating complex web search interfaces of the deep web"
        },
        {
            "group": 124,
            "name": "10.1.1.110.7101",
            "keyword": "Aloul F.A, Markov I.L, Sakallah K.A, MINCE, A S",
            "author": "Fadi A. Aloul, Igor L. Markov, Karem A. Sakallah",
            "abstract": "Abstract: The increasing popularity of SAT and BDD techniques in formal hardware verification and automated synthesis of logic circuits encourages the search for additional speedups. Since typical SAT and BDD algorithms are exponential in the worst-case, the structure of realworld instances is a natural source of improvements. While SAT and BDD techniques are often presented as mutually exclusive alternatives, our work points out that both can be improved via the use of the same structural properties of instances. Our proposed methods are based on efficient problem partitioning and can be easily applied as pre-processing with arbitrary SAT solvers and BDD packages without modifying the source code of SAT/BDD tools. Finding a better variable ordering is a well recognized problem for both SAT solvers and BDD packages. Currently, the best variable-ordering algorithms are dynamic, in the sense that they are invoked many times in the course of the host algorithm that solves SAT or manipulates BDDs. Examples include the DLCS ordering for SAT solvers and variable sifting during BDD manipulations. In this work we propose a universal variable-ordering algorithm MINCE (MIN Cut Etc.) that pre-processes a given Boolean formula in CNF. MINCE is completely independent from target SAT algorithms and in some cases outperforms both the variable state independent",
            "title": "MINCE: A static global variableordering heuristic for sat search and bdd manipulation"
        },
        {
            "group": 125,
            "name": "10.1.1.110.7223",
            "keyword": "Information Visualization, Evaluation, Comparison visualization",
            "author": "",
            "abstract": "When searching on the web, users often reformulate their queries after viewing the results and viewing some of the pages. After one or two reformulations the user may implicitly realize patterns and relationships between the multiple search results. We believe that these patterns can be used to identify interesting results. We have developed the prototype Search Engine Similarity (SES) tool which explicitly visualizes the similarity between multiple searches. In this paper we describe an experiment to determine whether explicitly visualizing the relationships between multiple searches will let users browse more effectively. Our results show that explicit difference visualizations can enhance the search process for some tasks.",
            "title": "Explicit verses Implicit: An Analysis of a Multiple Search Result Visualization"
        },
        {
            "group": 126,
            "name": "10.1.1.110.7285",
            "keyword": "",
            "author": "Victoria Uren, Enrico Motta",
            "abstract": "Abstract. Formulating complex queries is hard, especially in heterogeneous information environments, where users do not understand all the data structures of multiple complex knowledge bases. We see a gap between semantic search tools that are user friendly, but have restricted functionality, and powerful, formal query languages, which are unsuitable for end users. We explore the complexity of semantic queries through an example. Building on this example, we propose a solution using a component based approach. We propose a layered architecture, with components taking an intermediary role between the end user interface and formal query languages. The kinds of components that would be needed for such a system are outlined, and challenges for the system are discussed, in particular, how to combine semantic searches. 1",
            "title": "Semantic Search Components: a blueprint for effective query language interfaces"
        },
        {
            "group": 127,
            "name": "10.1.1.110.8198",
            "keyword": "EALR",
            "author": "Bearly Born, Wildlife Is Everywhere, Microtrek Scavenger Hunt",
            "abstract": "The correlations for the Project WILD activities are summarized by subject. Use this matrix to find what activity addresses certain benchmarks you are targeting. The numbers in the subject sections of the matrix correspond to benchmark numbers in the Overview of the Essential Academic Learning Requirements provided by the Washington State Commission on Student Learning. For each activity a symbol indicates what subject area standard is addressed and in a few instances whether it provides background information, options or variations, extensions or evaluation that addresses the learning requirement.",
            "title": "26. Animal Poetry 27. Museum Search for Wildlife 28. Let's Go Fly a Kite"
        },
        {
            "group": 128,
            "name": "10.1.1.110.8751",
            "keyword": "",
            "author": "",
            "abstract": "This paper describes the design of an extensible 3-tiered semantic file system, backed by an existing extensible object-relational database. The system is designed to export the standard NFS interface, while providing indexing and query support for user-defined file types using the virtual directory abstraction. To illustrate the feasibility of the proposed architecture, we describe its implementation for one important file type, text. Indexing and query support for text are implemented in the database using a plug-in module, and support for full-text queries, including boolean keyword search and information retrieval rank, are exported by the file system interface using virtual directories. 1",
            "title": "Text Search in an NFS-Proxy: A Case Study in Extensible File Systems"
        },
        {
            "group": 129,
            "name": "10.1.1.111.1182",
            "keyword": "",
            "author": "",
            "abstract": "In this paper, we treat multi-core processor design space exploration as an application-driven machine learning problem. We develop two machine learning-based techniques for efficiently exploring the processor design space. We observe that these techniques result in multi-core processors whose performance is comparable (within 1%) to a processor design that requires an exhaustive exploration of the design space. These techniques often take orders of magnitude (a factor of 3800 at the minimum) less time for coming up with these processors. The benefits are up to 13% over intelligent search techniques that have been adapted to do multi-core design space exploration. We leverage the knowledge gained in this research to develop Magellan \u2013 a framework for accelerating multi-core design space exploration and optimization. Magellan can be used to find the highest throughput processors of a given type for a given area, power, or time budget. It can be used to aid even experienced processor designers that prefer to rely on intuition by allowing fast refinements to an input design. 1",
            "title": "Magellan: A Search and Machine Learning-based Framework for Fast Multi-core Design Space Exploration and Optimization"
        },
        {
            "group": 130,
            "name": "10.1.1.111.119",
            "keyword": "",
            "author": "Srinivas Sista, Charles A. Bouman, Jan P. Allebach",
            "abstract": "Searching an image for the occurrence of a pattern or a template is an essential step in a number of image processing applications. We propose a new multiresolution matching criterion based on the generalized log likelihood ratio. We also developed a multiscale search technique which facilitates finding the best solution by searching a small subset of the entire set of possible template locations. The search technique is designed to keep the amount of computation at each resolution approximately the same. The results obtained on our example images demonstrate the robustness and accuracy of the matching criterion along with a speed-up of over two orders of magnitude by the search technique. 1.",
            "title": "Fast image search using a multiscale stochastic model"
        },
        {
            "group": 131,
            "name": "10.1.1.111.2560",
            "keyword": "",
            "author": "Nicholas A. Christakis, Mph Lauren, M. Mcintyre, James A. Tulsky",
            "abstract": "Despite a recent increase in the attention given to improving end-of-life care, our understanding of what constitutes a good death is surprisingly lacking. The purpose of this study was to gather descriptions of the components of a good death from patients, families, and providers through focus group discussions and in-depth interviews. Seventy-five participants\u2014including physicians, nurses, social workers, chaplains, hospice volunteers, patients, and recently bereaved family members\u2014were recruited from a university medical center, a Veterans Affairs medical center, and a community hospice. Participants identified six major components of a good death: pain and symptom management, clear decision making, preparation for death, completion, contributing to others, and affirmation of the whole person. The six",
            "title": "PERSPECTIVE In Search of a Good Death: Observations of Patients, Families, and Providers"
        },
        {
            "group": 132,
            "name": "10.1.1.111.3821",
            "keyword": "",
            "author": "Preeti Verghese",
            "abstract": "The attentive, serial second stage has been invoked especially to explain conjunction search. In conjunction search, the target differs from the distractors by a unique",
            "title": "Visual Search and Attention: Review A Signal Detection Theory Approach"
        },
        {
            "group": 133,
            "name": "10.1.1.111.6412",
            "keyword": "",
            "author": "Alexandros Ntoulas",
            "abstract": "Incorporation of language techniques in various web search engines has shown both positive and negative effects on retrieval performance. This paper describes an experiment conducted to determine the impact document and query normalization has on retrieval performance of a Greek web search engine. Experiments especially focus on the measurement of Recall and Precision of the obtained results and show whether information retrieval can benefit from normalization techniques. Results show that normalization yields significant improvement concerning recall of the retrieved data, whereas precision strongly depends on the queries issued to the engine. 1",
            "title": "Using a WWW Search Engine to Evaluate Normalization Performance for a Highly Inflectional Language"
        },
        {
            "group": 134,
            "name": "10.1.1.111.7995",
            "keyword": "",
            "author": "Albert Cohen, S\u00e9bastien Donadio, Maria-jesus Garzaran, Christoph Herrmann, David Padua",
            "abstract": "The quality of compiler-optimized code for high-performance applications lags way behind what optimization and domain experts can achieve by hand. This paper explores in-between solutions, besides fully automatic and fully-manual code optimization. This work discusses how generative approaches can help the design and optimization of supercomputing applications. It outlines early results and research directions, using MetaOCaml for the design of a generative tool-box to design portable optimized code. We also identify some limitations the MetaOCaml system. We finally present and advocate for an offshoring approach to bring high-level and safe metaprogramming to imperative languages.",
            "title": "In search of a program generator to implement generic transformations for high-performance computing"
        },
        {
            "group": 135,
            "name": "10.1.1.111.8139",
            "keyword": "Web service federation, web service security, svg image security, medical imaging",
            "author": "Sabah Mohammed, Jinan Fiaidhi, Marshal Hahn",
            "abstract": "Abstract: With more and more medical web services appearing on the web, web service\u2019s discovery mechanism becomes essential. UDDI is an online registry standard to facilitate the discovery of business partners and services. However, most medical imaging applications exist within their own protected domain and were never designed to participate and operate with other applications across the web. However, private UDDI registries in federated organizations should be able to share the service descriptions as well as to access them if they are authorized. The new initiatives on Federated Web Services Identity Management can resolve a range of both technical and political barriers to enable wide-scale participation and interoperation of separate domains into a singular, robust user experience. However, there is no widely acceptable standard for federated web services and most of the available venders frameworks concentrate only on the security issue of the federation leaving the issue of searching and discovering web services largely primitive. Federated web services security and web services searching are uniquely intertwined, mutually reliant on each other and are poised to finally solve a long-running problem in both IT and systems security. Traditional keyword search is insufficient for web services search as the very small text fragments in web services are unsuitable for keyword search and the underlying structure and semantics of the web service are not exploited. Engineering solutions that address the security and accessibility concerns of web services, however, is a challenging task. This article introduces an extension to the traditional UDDI that enables sophisticated types of searching based on a lightweight web services federated security infrastructure.",
            "title": "\u00a9 2005 Science Publications A UDDI Search Engine for SVG Federated Medical Imaging Web Services"
        },
        {
            "group": 136,
            "name": "10.1.1.112.2110",
            "keyword": "",
            "author": "P-. S. M. Hasan, P-. Carllionberger, Digitizer Readout, Event-building For Gretina",
            "abstract": "LHC GCS process tuning- Selection and use of PID and Smith Predictor for the regulations of the LHC experiment gas systems",
            "title": "P-4.011 M.Lonza Design of a Fast Global Orbit Feedback System for the ELETTRA Storage Ring P-4.012 C.Briegel BPM Search Algorithms for Beam Injection and Extraction at Fermilab"
        },
        {
            "group": 137,
            "name": "10.1.1.112.264",
            "keyword": "",
            "author": "Richard Pak, Wendy A. Rogers, Arthur D. Fisk",
            "abstract": "Objective: The present study examined the relationship between two distinct subfactors of spatial ability and performance in an information search task modeled on browsing the Web. Background: Previous studies have found relationships between various measures of spatial ability and performance in a wide variety of computerbased tasks. Method: In the search task 101 participants (18\u201329 years of age) searched for the answer to a question by navigating the system. They completed the experimental task as well as a battery of cognitive ability measures that included two different measures of spatial ability. Results: The results indicate that spatial orientation ability was related to performance with tasks that were high in their navigational requirement (engendered by the use of a novel aid), whereas spatial visualization was unrelated to performance in any task condition. Conclusion: A closer inspection of the cognitive requirements of a task may reveal what interventions could be most useful when designing computer systems or developing training programs. Application: Given the unique differences between the different spatial abilities, the current results suggest the design of navigational aids that place less demand on spatial orientation ability.",
            "title": "Spatial Ability Subfactors and Their Influences on a Computer-Based Information Search Task"
        },
        {
            "group": 138,
            "name": "10.1.1.112.3063",
            "keyword": "",
            "author": "Alexander Markowetz, Yen-yu Chen, Torsten Suel",
            "abstract": "",
            "title": "Design and implementation of a geographic search engine"
        },
        {
            "group": 139,
            "name": "10.1.1.112.4003",
            "keyword": "",
            "author": "Barbara M. Wildemuth, Meng Yang, Gary Geisler, Tom Tolleson, Jon Elsas, Jei Luo, Gary Marchionini",
            "abstract": "Search mechanisms are the interface tools that people can use to search the items in a collection; a common example is a text box for entering search terms. In this pilot study, the Open Video team investigated two mechanisms for providing access to a collection of news videos. The first provided direct access to the subsets of the collection containing particular video features, as identified by other TREC VID participants; the second provided direct access to the subsets of the collection that were identified as semantic clusters, using latent semantic indexing approaches to analyzing the video transcripts. Each access mechanism was depicted in the interface as a series of labeled checkboxes. In the pilot study, four team members completed the TREC VID topic searches and responded to measures of their perceptions of the experience of using each search mechanism. Reasonably high precision was achieved on the user searches across all three systems (0.67-0.74), but none of the systems achieved high recall (0.10-0.11). Mean average precision across three runs (as calculated by NIST) ranged from 0.06-0.09. Searches were completed in approximately 8 minutes across all three systems. User satisfaction with the two experimental systems was mixed. Lessons learned from conducting this pilot study will contribute to the design of a follow-up study investigating the ways in which users of digital video retrieval systems conceptualize search mechanisms that incorporate access to subsets of the collection based on video features or semantic clusters of transcript content. 1",
            "title": "Conceptions of Features and Semantic Clusters as Search Mechanisms: A Pilot Study 1"
        },
        {
            "group": 140,
            "name": "10.1.1.112.4311",
            "keyword": "",
            "author": "Bernd Bohnet",
            "abstract": "One of the most widely explored issues in natural language generation is the generation of referring expressions (gre): given an entity we want to refer to, how do we work out the content of a referring expression that uniquely identifies the intended referent? Over the last 15 years, a number of authors have proposed a wide range of algorithms for addressing different aspects of this problem, but the different approaches taken have made it very difficult to compare and contrast the algorithms provided in any meaningful way. In this paper, we propose a characterisation of the problem of referring expression generation as a search problem; this allows us to recast existing algorithms in a way that makes their similarities and differences clear. 1",
            "title": "Referring Expression Generation as a Search Problem"
        },
        {
            "group": 141,
            "name": "10.1.1.112.6962",
            "keyword": "",
            "author": "Greg Smith, Mary Czerwinski, Brian Meyers, Daniel Robbins, George Robertson, Desney S. Tan",
            "abstract": "Abstract \u2014 The dominant paradigm for searching and browsing large data stores is text-based: presenting a scrollable list of search results in response to textual search term input. While this works well for the Web, there is opportunity for improvement in the domain of personal information stores, which tend to have more heterogeneous data and richer metadata. In this paper, we introduce FacetMap, an interactive, query-driven visualization, generalizable to a wide range of metadata-rich data stores. FacetMap uses a visual metaphor for both input (selection of metadata facets as filters) and output. Results of a user study provide insight into tradeoffs between FacetMap\u2019s graphical approach and the traditional text-oriented approach. Index Terms \u2014 Graphical visualization, interactive information retrieval, faceted metadata 1",
            "title": "Facetmap: A scalable search and browse visualization"
        },
        {
            "group": 142,
            "name": "10.1.1.112.9278",
            "keyword": "",
            "author": "",
            "abstract": "The request of patients for non-metal tooth-like restorations lead to the development of all-ceramic systems. These systems are generally classified in reference to their infrastructure composition. Each system offers various physical and esthetic properties. The most recent all-ceramic system uses a CAD/CAM technology (Computer Aided Design/Computer Aided Machining) to fabricate an infrastructure in zirconia that possesses a superior marginal adaptation and resistance to fracture when compared to the other all-ceramic systems available. Zirconia exists in three configurations: monoclinic, tetragonal and cubic. A stabilizing agent, yttrium oxide (Y 2 O 3), is added to zirconium oxide to allow sintering of a fully tetragonal ceramic known as partially stabilized zirconia. The material used to fabricate the infrastructure, yttrium tetragonal zirconia polycristals (Y-TZP), confers high mechanical resistance to the restoration: 1. Resistance to fracture: the tendency for a crack to spread in zirconia is reduced as the stress created in its leading edge causes a transformation in configuration from tetragonal into a monoclinic phase that is 3 to 5 % more volumous. The monoclinic crystal places the region in compression and prevents the crack from spreading (\u201ctransformation toughening\u201d) 1. 2. 2. The absence of glass and the dense polycrystalline microstructure of the zirconia ceramic provide resistance to hydro-fatigue (degradation of glass by water present in the saliva). Following immergence in water for 1 week, biaxial flexural tests have shown no loss in the strength of zirconia but a reduction in resistance of infiltrated glass ceramics (In Ceram Alumina:-31%) and pressed ceramics [Empress 1 (leucite):-22%,",
            "title": "(Y-TZP) Infrastructure: The New Chapter in the Search for a Metal Framework Replacement"
        },
        {
            "group": 143,
            "name": "10.1.1.112.9288",
            "keyword": "determinerless PP, multiword expression, selection, noun countability",
            "author": "Timothy Baldwin, John Beavers, Leonoor Van Der Beek, Francis Bond, Dan Flickinger, Ivan A. Sag",
            "abstract": "Abstract This paper examines determinerless prepositional phrases in English and Dutch from a theoretical perspective. We classify attested P + N combinations across a number of analytic dimensions, arguing that the observed cases fall into at least three distinct classes. We then survey four different analytic methods that can predict the behaviour of the differing classes and examine various remaining difficult cases that may remain as challenges.",
            "title": "Chapter 1 IN SEARCH OF A SYSTEMATIC TREATMENT OF DETERMINERLESS PPS"
        },
        {
            "group": 144,
            "name": "10.1.1.112.9487",
            "keyword": "Markov Decision Process, probabilistic automata, websearch, local web search, web traffic logs",
            "author": "",
            "abstract": "ABSTRACT In this paper we give a preliminary report on our study of the use ofweb server traffic logs to improve local search. Web server traffic",
            "title": "On Improving Local Website Search Using Web ServerTraffic logs: A Preliminary Report"
        },
        {
            "group": 145,
            "name": "10.1.1.113.469",
            "keyword": "",
            "author": "Linda L. West",
            "abstract": "",
            "title": "Best Practices in Integrating Technology Into Adult ESL Instruction: A Literature Search Prepared for TECH21 By"
        },
        {
            "group": 146,
            "name": "10.1.1.113.6680",
            "keyword": "Salesman Problem (TSP, Quadratic Assignment Problem",
            "author": "Steven Halim, Roland H. C. Yap, et al.",
            "abstract": "NP-hard combinatorial optimization problems are common in real life. Due to their intractability, local search algorithms are often used to solve such problems. Since these algorithms are heuristic-based, it is hard to understand how to improve or tune them. We propose an interactive visualization tool, VIZ, meant for understanding the behavior of local search. VIZ uses animation of abstract search trajectories with other visualizations which are also animated in a VCR-like fashion to graphically playback the algorithm behavior. It combines generic visualizations applicable on arbitrary algorithms with algorithm and problem specific visualizations. We use a variety of techniques such as alpha blending to reduce visual clutter and to smooth animation, highlights and shading, automatically generated index points for playback, and visual comparison of two algorithms. The use of multiple viewpoints can be an effective way of understanding search behavior and highlight algorithm behavior which might otherwise be hidden.",
            "title": "  Viz: A Visual Analysis Suite for Explaining Local Search Behavior"
        },
        {
            "group": 147,
            "name": "10.1.1.113.8230",
            "keyword": "Web Search, Search Context, Search Log Analysis, Community Search Behaviour",
            "author": "Mingfang Wu, Andrew Turpin, Justin Zobel",
            "abstract": "Users \u2019 past search behaviour provides a rich context that an information retrieval system can use to tailor its search results to suit an individual\u2019s or a community\u2019s information needs. In this paper, we present an investigation of the variability in search behaviours for the same queries in a close-knit community. By examining web proxy cache logs over a period of nine months, we extracted a set of 135 queries that had been issued by at least ten users. Our analysis indicates that, overall, users clicked on highly ranked and relevant pages, but they tend to click on different sets of pages. Examination of the query reformulation history revealed that users often have different search intents behind the same query. We identify three major causes for the community\u2019s interaction behaviour differences: the variance of task, the different intents expressed with the query, and the snippet and characteristics of retrieved documents. Based on our observations, we identify opportunities to improve the design of different search and delivery tools to better support community and individual search experience.",
            "title": "Abstract An Investigation on a Community\u2019s Web Search Variability"
        },
        {
            "group": 148,
            "name": "10.1.1.114.1724",
            "keyword": "Key Words, Emergence, evolution, natural selection, synergy 1",
            "author": "Peter A. Corning",
            "abstract": "Despite its current popularity, \u201cemergence\u201d is a concept with a venerable history and an elusive, ambiguous standing in contemporary evolutionary theory. This paper briefly recounts the history of the term and details some of its current usages. Not only are there radically varying interpretations about what emergence means but \u201creductionist \u201d and \u201cholistic \u201d theorists have very different views about the issue of causation. However, these two seemingly polar positions are not irreconcilable. Reductionism, or detailed analysis of the parts and their interactions, is essential for answering the \u201chow \u201d question in evolution--how does a complex living system work? But holism is equally necessary for answering the \u201cwhy \u201d question-- why did a particular arrangement of parts evolve? In order to answer the \u201cwhy \u201d question, a broader, multi-leveled paradigm is required. The reductionist approach to explaining emergent complexity has entailed a search for underlying \u201claws of emergence.\u201d Another alternative is the \u201cSynergism Hypothesis, \u201d which focuses on the \u201ceconomics \u201d  \u2013 the functional effects produced by emergent wholes and their selective consequences. This theory, in a nutshell, proposes that the synergistic (co-operative) effects produced by various combinations of parts have played a major causal role in the evolution of biological complexity. It will also be argued that emergent phenomena represent, in effect, a subset of a much larger universe of combined effects in the natural world; there are many different kinds of synergy, but not all synergies represent emergent phenomena.",
            "title": "The re-emergence of \u201cemergence\u201d: A venerable concept in search of a theory"
        },
        {
            "group": 149,
            "name": "10.1.1.114.2081",
            "keyword": "",
            "author": "Ruud Stegers, Peter Fekkes, Heiner Stuckenschmidt",
            "abstract": "The increasing use of structured information on the web demands new ways of searching and integrating data from different sources. In this paper, we focus on the use of unique representations of data objects in terms of public repositories (in this case MusicBrainz) and the use of recommendation mechanisms as a basis for supporting information access. We have implemented a prototypical system with the corresponding functionality in the area of digital music. We discuss the challenges of providing integrated access to structured web resources and the solutions adopted in the MusiDB system.",
            "title": "MusiDB A Personalized Search Engine for Music"
        },
        {
            "group": 150,
            "name": "10.1.1.114.3874",
            "keyword": "Testability Transfer",
            "author": "Hans G. Kerkhoff",
            "abstract": "Abstract\u2014The well-known approach towards testing mixed-signal cores is functional testing and basically measuring key parameters of the core. However, especially if performance requirements increase, and embedded cores are considered, functional testing becomes technically and economically less attractive. A more cost-effective approach could be accomplished by a combination of reduced functional tests and added structural tests. In addition, it will also improve the debugging facilities of cores. Basic problem remains the large computational effort for analogue structural testing. In this paper, we introduce the concept of Testability Transfer Function for both analogue as well as digital parts in a mixed-signal core. This opens new possibilities for efficient structural testing of embedded mixed-signal cores, thereby adding to the quality of tests.",
            "title": "Test-Signal Search for Mixed-Signal Cores in a System-on-Chip"
        },
        {
            "group": 151,
            "name": "10.1.1.114.5195",
            "keyword": "Controlled, Specialties, Medical, Systematized Nomenclature",
            "author": "M. Fieschi Et Al. (eds, Curtis L. Cole A, Andrew S. Kanter B, Michael Cummens B, Sean Vostinar A, Frank Naeymi-rad B, Curtis L. Cole, Andrew S. Kanter, Michael Cummens, Sean Vostinar, Frank Naeymi-rad",
            "abstract": "Objectives: To design and implement a real world application using a terminology server to assist patients and physicians who use common language search terms to find specialist physicians with a particular clinical expertise. Method: Terminology servers have been developed to help users encoding of information using complicated structured vocabulary during data entry tasks, such as recording clinical information. We describe a methodology using Personal Health Terminology \u2122 and a SNOMED \u00ae CT-based hierarchical concept server. Results: Construction of a pilot mediated-search engine to assist users who use vernacular speech in querying data which is more technical than vernacular. Conclusion: This approach, which combines theoretical and practical requirements, provides a useful example of concept-based searching for physician referrals. Keywords:",
            "title": "Using a Terminology Server and Consumer Search Phrases to Help Patients Find Physicians with Particular Expertise"
        },
        {
            "group": 152,
            "name": "10.1.1.114.5479",
            "keyword": "",
            "author": "Sanjay Agrawal",
            "abstract": "Internet search engines have popularized the keywordbased search paradigm. While traditional database management systems offer powerful query languages, they do not allow keyword-based search. In this paper, we discuss DBXplorer, a system that enables keywordbased search in relational databases. DBXplorer has been implemented using a commercial relational database and web server and allows users to interact via a browser front-end. We outline the challenges and discuss the implementation of our system including results of extensive experimental evaluation. 1.",
            "title": "DBXplorer: A system for keyword-based search over relational databases"
        },
        {
            "group": 153,
            "name": "10.1.1.114.6824",
            "keyword": "",
            "author": "Noel Geoghegan",
            "abstract": "For the last seven years, a research project focused on one North American Grade 2 teacher\u2019s efforts to develop young children\u2019s early mathematical concepts has given rise to a new paradigm for teaching and learning. By creating a classroom environment that promotes (1) reflexive psycho-pedagogical relationships and, (2) a systems-theory approach to learning, the teacher\u2019s pedagogy and children\u2019s engagement with learning have been continually refined through the SEARCH metaphor (Geoghegan, 2002). Being less to do with \u201cdidactic teaching \u201d and more to do with \u201cself-regulated learning, \u201d the research project has sought to highlight children\u2019s capacity to confidently generate creative propositions as one of the significant constituent elements of effective mathematics teaching and learning. Incorporating post-modern and systems-theory perspectives, this paper will discuss and demonstrate how the reflexive nature of self-regulation engages children in creative and productive mathematical thinking from a young age.",
            "title": "RE-SEARCH RELATIONSHIPS: A SYSTEMS APPROACH TO MATHEMATICS EDUCATION USING THE METAPHOR OF A SEARCH AS A PARADIGM FOR CLASSROOM TEACHING AND LEARNING"
        },
        {
            "group": 154,
            "name": "10.1.1.115.2319",
            "keyword": "",
            "author": "Michael Chen, Marti Hearst, Jason Hong, James Lin",
            "abstract": "Although search over World Wide Web pages has recently received much academic and commercial attention, surprisingly little research has been done on how to search the web pages within large, diverse intranets. Intranets contain the information associated with the internal workings of an organization. A standard search engine retrieves web pages that fall within a widely diverse range of information contexts, but presents these results uniformly, in a ranked list. As an alternative, the Cha-Cha system organizes web search results in such a way as to reflect the underlying structure of the intranet. In our approach, an \u201coutline \u201d or \u201ctable of contents \u201d is created by first recording the shortest paths in hyperlinks from root pages to every page within the web intranet. After the user issues a query, these shortest paths are dynamically combined to form a hierarchical outline of the context in which the search results occur. The system is designed to be helpful for users with a wide range of computer skills. Preliminary user study and survey results suggest that some users find the resulting structure more helpful than the standard retrieval results display for intranet search. 1",
            "title": "Cha-Cha: A system for organizing intranet search results"
        },
        {
            "group": 155,
            "name": "10.1.1.115.2606",
            "keyword": "",
            "author": "Michael Wollowski",
            "abstract": "ABSTRACT. We present and discuss a likely future world in which advances in search and the wiring of our environment would provide us with ready access to much information. We outline the current status of search and the goals of the semantic web. We argue that much of the information already in electronic format will likely be made accessible through the web. We present a likely future scenario of a wired world, a world in which entities as simple as a bottle of pills to as complex as the human body are wired to the web. This adds much additional information to the web, information that by-andlarge is currently not gathered in electronic format. We present and discuss three representative cases which highlight the benefits and drawbacks of ready access to information pertaining to individuals. We suggest that the future scenarios are not too far off in the making and suggest that a dialogue be started, attempting to develop enforceable privacy policies.",
            "title": "Living in a Transparent Future: Search in a Wired World"
        },
        {
            "group": 156,
            "name": "10.1.1.115.312",
            "keyword": "",
            "author": "M. Fieschi Et Al. (eds, Yang Gong A, Tao Zhang A, Jamie Rukab A, Kathy Johnson-throop B, Jane Malin B, Jiajie Zhang A",
            "abstract": "In order to design effective and usable search interfaces it is essential to fully understand the characteristics of the users and the tasks they perform. In this paper, we describe how to use a human-centered approach to design a usable search interface. We first conducted user and task analyses of the application domain-- Biomedical Engineers ' log notes at NASA Johnson Space Center. From these analyses, we identified what functions the users want, the tasks they perform, and a coding system for the vocabulary used by the users to log entries in the log notes. We then implemented a prototype of a human-centered search interface by using the results of the user and task analyses and by applying other human-centered principles. Finally, we discussed the implications of human-centered design for general health information systems. Keywords: interface design, information retrieval, user analysis, task analysis",
            "title": "Design and Development of a Search Interface for an Information Gathering Tool"
        },
        {
            "group": 157,
            "name": "10.1.1.115.319",
            "keyword": "",
            "author": "",
            "abstract": "A collection of tutorials produced by the UC Berkeley Teaching Library. It contains basic Internet background, web browser guides, search strategies, and evaluating web content. Search Engine Watch\u2019s Web Searching Tips searchenginewatch.com/facts/index.php A collection of useful searching tips. Search Engine Showdown: The User\u2019s Guide to Web Searching www.searchengineshowdown.com Find the latest news on search engines. Be sure to check out the chart comparing the features of the various search engines. Search Syntax\u2014Google and Yahoo The following syntax examples work in both Google and Yahoo unless otherwise noted. Automatic \u201cand\u201d: Searches for pages containing all of the words you enter A search for pennsylvania genealogy will find pages with both Pennsylvania and genealogy in them OR operator: Searches for pages with either term a or term b in them leading to more search results (OR must be capitalized) A search for lemons OR limes will find pages that have the word lemons in them or pages with the word limes- (minus sign) operator: Google/Yahoo excludes the word after the minus sign in your search A search for lemons\u2013limes will find pages that have the word lemons in them but will not bring back pages that also have the word limes Phrase searching: Placing quotation marks around two or more words will tell Google/Yahoo to search for that exact phrase A search for\u201cchester county\u201dwill find pages with that exact phrase in them",
            "title": "Super-Size Your Searching Skills: Advanced Internet Searching Search Engine Basics Finding Information on the Internet: A Tutorial"
        },
        {
            "group": 158,
            "name": "10.1.1.115.4891",
            "keyword": "",
            "author": "Amr Abdalla",
            "abstract": "The purpose of this paper is to discuss potential principles for interpersonal dispute resolution models within an Islamic context. Such a task requires an Islamic researcher to walk a fine line in order to avoid falling in one of two methodological traps. The first trap is to draw",
            "title": "ABDALLAFIN.DOC 9/16/2002 6:39 AM PRINCIPLES OF ISLAMIC INTERPERSONAL CONFLICT INTERVENTION: A SEARCH WITHIN ISLAM AND WESTERN LITERATURE"
        },
        {
            "group": 159,
            "name": "10.1.1.115.6287",
            "keyword": "",
            "author": "C. Lee Giles, Prasenjit Mitra, Karl Mueller, James Z. Wang, Bingjun Sun, Levent Bolelli, Ying Liu, Isaac Councill, William Brower, Qingzhao Tan, Anuj Jaiswal, James Kubicki, Joel B, Juan Pablo Fern, Ez Ramirez",
            "abstract": "Cyberinfrastructure or e-science has become crucial for scientific progress and open source systems have greatly facilitated design and implementation. In chemistry, the growth of data has been explosive and timely and effective information and data access is critical. We discuss our ChemXSeer (funded by NSF Chemistry) architecture, a portal and search engine for academic researchers in environmental chemistry, which integrates the scientific literature with experimental, analytical and simulation datasets. ChemXSeer consists of information crawled from the web, manual submission of scientific documents and user submitted datasets, as well as scientific documents and metadata provided by major publishers. Information gathered from the web is publicly accessible whereas access to restricted publisher resources will be provided by linking to their respective sites and users can control access to their data. Thus, instead of being a fully open search engine and repository, ChemXSeer will be a hybrid one, limiting access to some resources. ChemXSeer offers some unique aspects of search not yet present in other scientific search services or search engines. We have developed or are developing algorithms for the extraction of tables, figures, and chemical names and formulae from scientific documents enabling users to search on those fields. In particular ChemXSeer will provide the following search features:",
            "title": "ChemXSeer: A Web Search Engine and Repository for e-Chemistry"
        },
        {
            "group": 160,
            "name": "10.1.1.115.7735",
            "keyword": "Document clustering, User interface, Search engine, Visualization",
            "author": "Oren Zamir \u0141",
            "abstract": "Users of Web search engines are often forced to sift through the long ordered list of document \u2018snippets \u2019 returned by the engines. The IR community has explored document clustering as an alternative method of organizing retrieval results, but clustering has yet to be deployed on most major search engines. The NorthernLight search engine organizes its output into \u2018custom folders \u2019 based on pre-computed document labels, but does not reveal how the folders are generated or how well they correspond to users \u201d interests. In this paper, we introduce Grouper, an interface to the results of the HuskySearch meta-search engine, which dynamically groups the search results into clusters labeled by phrases extracted from the snippets. In addition, we report on the first empirical comparison of user Web search behavior on a standard ranked-list presentation versus a clustered presentation. By analyzing HuskySearch logs, we are able to demonstrate substantial differences in the number of documents followed, and in the amount of time and effort expended by users accessing search",
            "title": "ELSEVIER Abstract Grouper: a dynamic clustering interface to Web search results"
        },
        {
            "group": 161,
            "name": "10.1.1.115.8174",
            "keyword": "",
            "author": "",
            "abstract": "Scientific realism holds that scientific theories are approximations of universal truths about reality, whereas scientific instrumentalism posits that scientific theories are intellectual structures that provide adequate predictions of what is observed and useful frameworks for answering questions and solving problems in a given domain. These philosophical perspectives have different strengths and weaknesses and have been regarded as incommensurate: Scientific realism fosters theoretical rigor, verifiability, parsimony, and debate, whereas scientific instrumentalism fosters theoretical innovation, synthesis, generativeness, and scope. The authors review the evolution of scientific realism and instrumentalism in psychology and propose that the categorical distinction between the 2 is overstated as a prescription for scientific practice. The authors propose",
            "title": "Realism, Instrumentalism, and Scientific Symbiosis Psychological Theory as a Search for Truth"
        },
        {
            "group": 162,
            "name": "10.1.1.115.9904",
            "keyword": "",
            "author": "",
            "abstract": "Educational games and simulations, unlike direct forms of instruction, are experiential exercises. That is, student teams may be racing each other to reach a pot of gold (game), sifting through an archeological site and analyzing the artifacts",
            "title": "17. EDUCATIONAL GAMES AND SIMULATIONS: A TECHNOLOGY IN SEARCH OF A (RESEARCH) PARADIGM"
        },
        {
            "group": 163,
            "name": "10.1.1.116.3632",
            "keyword": "",
            "author": "Luiz Andr\u00e9 Barroso, Jeffrey Dean, Urs H\u00f6lzle, Superior Performance, At A Fraction, Of The, Cost Of, A System Built",
            "abstract": "Few Web services require as much computation per request as search engines. On average, a single query on Google reads hundreds of megabytes of data and consumes tens of billions of CPU cycles. Supporting a peak request stream of thousands of queries per second requires an infrastructure comparable in size to that of the largest supercomputer installations. Combining more than 15,000 commodity-class PCs with fault-tolerant software creates a solution that is more cost-effective than a comparable system built out of a smaller number of high-end servers. Here we present the architecture of the Google cluster, and discuss the most important",
            "title": "AMENABLE TO EXTENSIVE PARALLELIZATION, GOOGLE\u2019S WEB SEARCH APPLICATION LETS DIFFERENT QUERIES RUN ON DIFFERENT PROCESSORS AND, BY PARTITIONING THE OVERALL INDEX, ALSO LETS A SINGLE QUERY USE MULTIPLE PROCESSORS. TO HANDLE THIS WORKLOAD, GOOGLE\u2019S ARCHITECT"
        },
        {
            "group": 164,
            "name": "10.1.1.116.3861",
            "keyword": "cognitive modeling, visual search, EPIC, eye",
            "author": "Tim Halverson, Anthony J. Hornof",
            "abstract": "Visual search is an integral component in many human activities. The eye movements produced during such activities can provide valuable information about people\u2019s cognitive processes. This research investigates, with detailed eye movement data analysis and computational cognitive modeling, the perceptual, strategic, and oculomotor processes people use to visually search. A cognitive model is evolved in a principled manner based on eye movement data, past modeling efforts, and recent psychological literature. In the model, re-usable, parsimonious, local strategies interact with perceptual-motor constraints to predict the bulk of the eye movement data, including aspects of the data that appear to require task-specific global strategies in addition to fixationto-fixation local strategies. The analysts evolve a base level model with a random strategy into a robust and reusable model with a flexible strategy that could work with a wide range of visual stimuli.",
            "title": "Towards a Flexible, Reusable Model for Predicting Eye Movements During Visual Search of Text"
        },
        {
            "group": 165,
            "name": "10.1.1.116.5149",
            "keyword": "Interface design, search, browse, category overview, visualization",
            "author": "Junliang Zhang, Gary Marchionini",
            "abstract": "We present in this paper the design and an evaluation of a novel interface called the Relation Browser++ (RB++) for searching and browsing large information collections. RB++ provides visualized category overviews of an information space and allows dynamic filtering and exploration of the result set by tightly coupling the browsing and searching functions. A user study was conducted to compare the effectiveness, efficiency and user satisfaction of completing various types of searching and browsing using the RB++ interface and a traditional formfillin interface for a video library. An exploration set of tasks was also included to examine the effectiveness of and user satisfaction with the RB++ when applied to a large federal statistics website. The comparison study strongly supported that RB++ was more effective, efficient, and satisfying for completing data exploration tasks. Based on the results, efforts to automatically populate the underlying database using machine learning techniques are underway. Preliminary implementations for two large-scale federal statistical websites have been installed on government servers for internal evaluation. Categories and Subject Descriptors:H.5.2 [Information Interfaces and presentation (e.g. HCI)]: User Interface- interaction style, graphical user interfaces (GUI);H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval- query formulation,",
            "title": "Evaluation and evolution of a browse and search interface: Relation Browser"
        },
        {
            "group": 166,
            "name": "10.1.1.116.5191",
            "keyword": "",
            "author": "Stephen Muggleton, Alireza Tamaddoni-nezhad",
            "abstract": "Abstract Most search techniques within ILP require the evaluation of a large number of inconsistent clauses. However, acceptable clauses typically need to be consistent, and are only found at the \u201cfringe \u201d of the search space. A search approach is presented, based on a novel algorithm called QG (Quick Generalization). QG carries out a random-restart stochastic bottom-up search which efficiently generates a consistent clause on the fringe of the refinement graph search without needing to explore the graph in detail. We use a Genetic Algorithm (GA) to evolve and re-combine clauses generated by QG. In this QG/GA setting, QG is used to seed a population of clauses processed by the GA. Experiments with QG/GA indicate that this approach can be more efficient than standard refinement-graph searches, while generating similar or better solutions.",
            "title": "DOI 10.1007/s10994-007-5029-3 QG/GA: a stochastic search for Progol"
        },
        {
            "group": 167,
            "name": "10.1.1.116.5199",
            "keyword": "",
            "author": "Christian S. Collberg",
            "abstract": "Abstract A*goVista is a web-based search engine that assists programmers to find algorithms and implementations that solve specific problems. A*goVista is not keyword based but rather requires users to provide-- in a very simple textual language-- input)output samples that describe the behavior of their needed algorithm. Unfortunately, even this simple language has proven too challenging for casual users. To overcome this problem and make A*goVista more accessible to novice programmers, we are designing and prototyping a visual language for creating A*goVista queries. Since web users do not have the patience to learn fancy query languages (be they textual or visual), our goal is to make this language and its implementation natural enough to require virtually no explanation or user training. A*goVista operates at",
            "title": "A Fuzzy Visual Query Language for a Domain-Specific Web Search Engine"
        },
        {
            "group": 168,
            "name": "10.1.1.116.7805",
            "keyword": "searching, Webometrics, distributions",
            "author": "Suresh K. Bhavnani, Frederick A. Peck",
            "abstract": "Recent studies suggest that users often retrieve incomplete healthcare information because of the complex and skewed distribution of facts across relevant webpages. To understand the causes for such skewed distributions, this paper presents the results of two analyses: (1) A distribution analysis discusses how facts related to healthcare topics are scattered across high-quality healthcare pages. (2) A cluster analysis of the same data suggests that the skewed distribution can be explained by the existence of three page profiles that vary in information density, each of which play in important role in providing comprehensive information of a topic. The above analyses provide clues towards a model of information scatter which describes how the design decisions by individual webpage authors could collectively lead to the scatter of information as observed in the data. The analyses also suggest implications for the design of websites, search algorithms, and search interfaces to help users find comprehensive information about a topic.",
            "title": "Towards a Model of Information Scatter: Implications for Search and Design"
        },
        {
            "group": 169,
            "name": "10.1.1.116.7903",
            "keyword": "Tabu Search, Integer Programming",
            "author": "Junha Hwang, Chang Sung Kang, Kwang Ryel Ryu, Yongho Han, Hyung Rim Choi",
            "abstract": "Methods based on integer programming have been shown to be very effective in solving various crew pairing optimization problems. However, their applicability is limited to problems with linear constraints and objective functions. Also, those methods often require an unacceptable amount of time and/or memory resources given problems of larger scale. Heuristic methods such as tabu search, on the other hand, can handle large-scaled problems without too much difficulty and can be applied to problems having any form of objective functions and constraints. However, tabu search often gets stuck at local optima when faced with complex search spaces. This paper presents a hybrid algorithm of tabu search and integer programming, which nicely combines the advantages of both methods. The hybrid algorithm has been successfully tested on a large-scaled crew pairing optimization problem for a real subway line.",
            "title": "Abstract A HYBRID OF TABU SEARCH AND INTEGER PROGRAMMING FOR SUBWAY CREW PARING OPTIMIZATION"
        },
        {
            "group": 170,
            "name": "10.1.1.116.8002",
            "keyword": "Unicode, UML, CORBA, Information Retrieval (IR, Search engine, Farsi language",
            "author": "M. Azadnia, M. Salehi, A. M. Zareh Bidoki",
            "abstract": "In this paper we have tried to model, design and test a prototype of Farsi/English search engine. The engine has the duty of covering the web media features such as heterogeneity, volatility and huge amount of unstructured worldwide information. These features as well as the rapid advance in technology, challenge the effectiveness of classical Information Retrieval (IR) techniques. Although a growing number of sites with Farsi language support exist, still few research works have been done regarding the computational linguistic approach to this language, particularly in the field of thesaurus construction and stemming. In this paper, we have tried to utilize the past research experiences to design Farsi/English search engine. It seems that Unicode is sufficiently capable of preparing a conclusive environment within this respect specially regarding the issues of indexing and searching web pages. Many common Farsi code-pages are now being used which are to be converted into Unicode, in order to cover most of the existing Farsi web pages. To handle the complexity in analysis and design of the system and generate a visual easy-toscale model Unified Modeling Language (UML) was utilized; and to assure scalability, distributed functionality and reliability, we tried to use some successful industrial solutions: Relational Database in managing the web-page indices and Clustering techniques to balance the high workload on the user interface and index management unit. We\u2019ve chosen Common Object Request Broker Architecture (CORBA) due to distributed object-oriented design of the system and our agent-oriented trends in future. We\u2019ve tried to apply CORBA design ideas to build a scalable and platform-independent framework.",
            "title": "Designing a Distributed search engine for Farsi/English web pages"
        },
        {
            "group": 171,
            "name": "10.1.1.116.8574",
            "keyword": "Postmodern Man in Search of a Soul",
            "author": "Clasina Buffelen Segura, Olga Cooke",
            "abstract": "",
            "title": "Major Subject: Sociology POSTMODERN MAN IN SEARCH OF A SOUL: TOWARDS A (RE)FORMULATION OF THE SOCIOLOGY OF RELIGION"
        },
        {
            "group": 172,
            "name": "10.1.1.117.1341",
            "keyword": "",
            "author": "Shobha Potluri, Anthony K. Yan, James J. Chou, Bruce R. Donald, Chris Bailey-kellogg",
            "abstract": "Symmetric homo-oligomers are protein complexes with similar subunits arranged symmetrically [10]. Figure 1 illustrates the structure of a symmetric homo-oligomer called phospholamban. Phospholamban is a membrane protein that helps regulate the calcium level inside the cell and hence aids in muscle contraction and relaxation [7]; ion conductance studies [5] also suggest that phospholamban might have a separate role as an ion channel. A detailed molecular-level understanding of homo-oligomeric structures provides insights into their functions and, in some cases, how to design appropriate drugs. Nuclear Magnetic Resonance (NMR) spectroscopy underlies many structural studies of homo-oligomers, but poses significant computational challenges in inferring three-dimensional structures from indirect (and often sparse) measurements of geometry. We use two types of information in homo-oligomeric structure determination: distance restraints from nuclear Overhauser effect (NOE) data, and biophysical modeling terms evaluating packing quality. An inter-subunit distance restraint is of the form \ufffdp \u2212 q \u2032  \ufffd  \u2264 d, where p and q \u2032 are atoms in different subunits of the complex,",
            "title": "Symmetric Protein Complexes by a Complete Search of Symmetry Configuration Space Using NMR Distance Restraints"
        },
        {
            "group": 173,
            "name": "10.1.1.117.1908",
            "keyword": "",
            "author": "Peter Boothe",
            "abstract": "Abstract. The evolution of the Internet topology has never been subject to a long-term quantitative analysis, despite the potential importance of the analysis \u2019 results. This paper surveys the current state of the art in all of the fields required, and finds that the time is ripe for exactly such a study to be performed. We close with a proposed timeline for completing this study, a brief description of what has already been done, and a call to action. 1",
            "title": "In Search of a Quantitative History of the Internet"
        },
        {
            "group": 174,
            "name": "10.1.1.117.2023",
            "keyword": "",
            "author": "Robert K. France, Lucy Terry Nowell, Edward A. Fox, Rani A. Saad, Jianxin Zhao",
            "abstract": "Digital libraries must reach out to users from all walks of life, serving information needs at all levels. To do this, they must attain high standards of usability over an extremely broad audience. This paper details the evolution of one important digital library component as it has grown in functionality and usefulness over several years of use by a live, unrestricted community. Central to its evolution have been user studies, analysis of use patterns, and formative usability evaluation. We extrapolate that all three components are necessary in the production of successful digital library systems.",
            "title": "Use and usability in a digital library search system.&quot; CoRR cs.DL/9902013"
        },
        {
            "group": 175,
            "name": "10.1.1.117.2695",
            "keyword": "Key words, \u03c0-calculus, names, meta-logic, proof search",
            "author": "Alwen Tiu, \u00c9cole Polytechnique, Dale Miller",
            "abstract": "We present a meta-logic that contains a new quantifier \u2207 (for encoding \u201cgeneric judgments\u201d) and inference rules for reasoning within fixed points of a given specification. We then specify the operational semantics and bisimulation relations for the finite \u03c0-calculus within this meta-logic. Since we restrict to the finite case, the ability of the meta-logic to reason within fixed points becomes a powerful and complete tool since simple proof search can compute this one fixed point. The \u2207 quantifier helps with the delicate issues surrounding the scope of variables within \u03c0calculus expressions and their executions (proofs). We shall illustrate several merits of the logical specifications we write: they are natural and declarative; they contain no side conditions concerning names of variables while maintaining a completely formal treatment of such variables; differences between late and open bisimulation relations are easy to see declaratively; and proof search involving the application of inference rules, unification, and backtracking can provide complete proof systems for both one-step transitions and for bisimulation.",
            "title": "FGUC 2004 Preliminary Version A Proof Search Specification of the \u03c0-Calculus Abstract"
        },
        {
            "group": 176,
            "name": "10.1.1.117.4407",
            "keyword": "General Terms Algorithms, Design, Experimentation. Keywords Web image search",
            "author": "Feng Jing, Changhu Wang, Yuhuan Yao, Kefeng Deng, Lei Zhang, Wei-ying Ma",
            "abstract": "In this demo, we present IGroup, a Web image search engine that organizes the search results into semantic clusters. Different from all existing Web image search results clustering algorithms that only cluster the top few images using visual or textual features, IGroup first identifies several query-related semantic clusters based on a key phrases extraction algorithm originally proposed for clustering general Web search results. Then, all the resulting images are separated and assigned to corresponding clusters. To make the best use of the clustering results, a new user interface is proposed. Please go to",
            "title": "IGroup: A Web Image Search Engine with Semantic Clustering of Search Results"
        },
        {
            "group": 177,
            "name": "10.1.1.117.5484",
            "keyword": "",
            "author": "",
            "abstract": "In this paper some methods using the Internet as a normative corpus for error checking purposes is presented. These include error detection and removing false alarms from existing grammar checkers. We evaluate these methods on Swedish texts. While not performing as well as state of the art traditional methods, results indicate that these methods are still useful, especially as a complement to other methods. Errors not detected by traditional methods can be detected by very simple means, and increasing the precision of other grammar checkers by removing false alarms also works quite well. 1",
            "title": "The Internet as a Normative Corpus: Grammar Checking with a Search Engine"
        },
        {
            "group": 178,
            "name": "10.1.1.117.7254",
            "keyword": "Abbreviations and Acronyms..........................................................................",
            "author": "Table Of Contents",
            "abstract": "",
            "title": "ORIGINAL: ENGLISH CONCEPTUAL AND DEFINITIONAL APPROACHES TO SUSTAINABLE DEVELOPMENT In Search of a Caribbean Convergence i"
        },
        {
            "group": 179,
            "name": "10.1.1.110.4097",
            "keyword": "",
            "author": "Chenghai Xue, Fei Li, Tao He, Guo-ping Liu, A Li, Xuegong Zhang",
            "abstract": "Classification of real and pseudo microRNA precursors using local structure-sequence features and support vector machine",
            "title": "BMC Bioinformatics BioMed Central Methodology article"
        },
        {
            "group": 180,
            "name": "10.1.1.117.8303",
            "keyword": "1 Interfacing Search Services",
            "author": "Eetu M\u00e4kel\u00e4, Eero Hyv\u00f6nen, Samppa Saarela",
            "abstract": "  View-based search provides a promising paradigm for formulating complex semantic queries and representing results on the Semantic Web. A challenge for the application of the paradigm is the complexity of providing view-based search services through application programming interfaces (API) and web services. This paper presents a solution on how semantic view-based search can be provided efficiently through an API or as web service to external applications. The approach has been implemented as the open source tool Ontogator, that has been applied successfully in several practical semantic portals on the web.",
            "title": "Ontogator -- a semantic view-based search engine service for web applications"
        },
        {
            "group": 181,
            "name": "10.1.1.117.8864",
            "keyword": "",
            "author": "",
            "abstract": "Abstract. \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd",
            "title": "SemSearch: A Search Engine for the Semantic Web"
        },
        {
            "group": 182,
            "name": "10.1.1.118.6138",
            "keyword": "",
            "author": "Leendert Van Maanen, Gert Kootstra",
            "abstract": "What exactly controls our gazing behaviour when we look at visual stimuli? We presume that some objects are more salient then others, which means that they have a more striking appearance against the background. It is known that these salient objects can influence our gazing behaviour, this uncontrolled effect is called bottom-up. The effect competing with bottom-up control is top-down behaviour, which is the shift of attention controlled on basis of the goals of the viewer or other goal-relevant knowledge about the visual field. In this research we investigated the influence of salient objects on shift of attention in a top-down search task. Participants searched for a stimulus with a known feature (orientation) in a field with 2 objects which had the same or different grades of saliency (brightness). Eye-movements were measured with the eyetracker. Furthermore, Participants responded where they found the target or concluded the target was not present. Results suggest an effect of bottom-up, where there are more fixations on the most salient stimulus while this stimulus increases in saliency. In contrast to results of other research (Theeuwes, 1992; Theeuwes, 2004), top-down influence does contribute to the performance for all levels of saliency.",
            "title": "Bottom-up influences on visual attention in a top-down search task Kai van Amsterdam,"
        },
        {
            "group": 183,
            "name": "10.1.1.118.7859",
            "keyword": "",
            "author": "Paul E. Rybski, Amy Larson, Harini Veeraraghavan, Monica Anderson Lapoint, Maria Gini",
            "abstract": "Swarm techniques, where many simple robots are used instead of complex ones for performing a task, promise to reduce the cost of developing robot teams for many application domains. The challenge lies in selecting an appropriate control strategy for the individual units. This work explores the effect of different control strategies of varying complexity and of various environmental factors on performance of a team of robots at a foraging task when using physical robots (the Minnesota Distributed Autonomous Robotic Team). Specifically we study the effect of localization and of simple communication techniques on task completion time using two sets of foraging experiments. We also present results for task performance with varying team sizes and target distribution. As indicated by the results, control strategies with increasing complexity reduce the variance in the performance, but do not always reduce the time to complete the task. 1",
            "title": "Performance evaluation of a multi-robot search & retrieval system: Experiences with MinDART"
        },
        {
            "group": 184,
            "name": "10.1.1.119.1890",
            "keyword": "",
            "author": "Ben Craig, Guillaume Rocheteau, Ben Craig, Guillaume Rocheteau",
            "abstract": "This paper extends recent fi ndings in the search-theoretic literature on monetary exchange regarding the welfare costs of infl ation. We present fi rst some estimates of the welfare cost of infl ation using the \u201cwelfare triangle \u201d methodology of Bailey (1956) and Lucas (2000). We then derive a money demand function from the search-theoretic model of Lagos and Wright (2005) and we estimate it from U.S. data over the period 1900\u20132000. We show that the welfare cost of infl ation predicted by the model accords with the welfare-triangle measure when pricing mechanisms are such that buyers appropriate the social marginal benefi t of their real balances. For other mechanisms, welfare triangles underestimate the true welfare cost of infl ation because of a rent-sharing externality. We also point out other ineffi ciencies associated with noncompetitive pricing, which matter for estimating the cost of infl ation. We then illustrate how endogenous participation decisions can mitigate or exacerbate the cost of infl ation, and we provide calibrated examples in which a deviation from the Friedman rule is optimal. Finally, we discuss distributional effects of infl ation.",
            "title": "FEDERAL RESERVE BANK OF CLEVELAND Infl ation and Welfare: A Search Approach"
        },
        {
            "group": 185,
            "name": "10.1.1.119.4799",
            "keyword": "",
            "author": "Montague Ullman",
            "abstract": "A b st r a c t \u2014 What has not yet come clearly into focus in the current exploration of the mind/body problem is how the unique features of dre a m ing cons c i o u s n ess might contribute to the ong o ing dialogue. Following a brief hist o r ical pe rs pe c t i ve, a th e o ry of dre a m ing as no c t u rnal social vigilance is p res e n t ed that takes into account both the genetic and social impe r a t i ves th a t s h a pe the dream. The unique features of the dream are re v i e w ed in the ligh t of this approach. Org a n i z ed outside the space, time and causality frame of w a k ing th o u ght, the dream takes on a presentational fo rm and dis p lays as m e t a p h o r ical visual imagery the impact of recent feeling res i d u es, their connection to the past, and their imp l ications for current and future behavior. The genetic impe r a t i ve makes its presence felt th ro u gh the in t r in s ic honest y of th ese no c t u rnal confrontations, their concern wi th how genuinely connected we are wi th our past and wi th our way of re la t ing to oth e rs. Thro u gh both its biolo g ical and social determ inants, the ultimate concern of dre a m ing is wi th the unity of the spe c i es and its surv i v a l. In a final section, analo g i es are no t ed between the in t e r p lay of waking and d re a m ing consciousness and some of the basic concepts of quantum mechanics.",
            "title": "Dreaming Consciousness: More Than a Bit Player in the Search for Answers to the Mind/Body Problem"
        },
        {
            "group": 186,
            "name": "10.1.1.119.6124",
            "keyword": ", phone 1 818 354 \u2013 5753",
            "author": "Riley Duren *a, Karen Dragon A, Steve Gunter A, Nick Gautier A, Eric Bachtell B, Dan Peters B, Adam Harvey B, Alan Enos B, Dave Koch C, Bill Borucki C, Charlie Sobeck C, Dave Mayer C, Jon Jenkins D, Rick Thompson E",
            "abstract": "The Kepler mission will launch in 2007 and determine the distribution of earth-size planets (0.5 to 10 earth masses) in the habitable zones (HZs) of solar-like stars. The mission will monitor> 100,000 dwarf stars simultaneously for at least 4 years. Precision differential photometry will be used to detect the periodic signals of transiting planets. Kepler will also support asteroseismology by measuring the pressure-mode (p-mode) oscillations of selected stars. Key mission elements include a spacecraft bus and 0.95meter, wide-field, CCD-based photometer injected into an earth-trailing heliocentric orbit by a 3-stage Delta II launch vehicle as well as a distributed Ground Segment and Follow-up Observing Program. The project is currently preparing for Preliminary Design Review (October 2004) and is proceeding with detailed design and procurement of long-lead components. In order to meet the unprecedented photometric precision requirement and to ensure a statistically significant result, the Kepler mission involves technical challenges in the areas of photometric noise and systematic error reduction, stability, and false-positive rejection. Programmatic and logistical challenges include the collaborative design, modeling, integration, test, and operation of a geographically and functionally distributed project. A very rigorous systems engineering program has evolved to address these challenge. This paper provides an overview of the Kepler systems engineering program, including some examples of our processes and techniques in areas such as",
            "title": "Systems Engineering for the Kepler Mission: A Search for Terrestrial Planets"
        },
        {
            "group": 187,
            "name": "10.1.1.119.6693",
            "keyword": "",
            "author": "Martin Del Vecchio, Shu Jin, Alana Mistretta, Hayden Rol, Hope Tuck",
            "abstract": "Abstract\u2014Debt Collection firms require an efficient and accurate procedure for locating a delinquent debtor, filing a lawsuit, and collecting on a debt at minimal cost. This process is known as \u201cskip-tracing,\u201d with a \u201cskip \u201d being a delinquent debtor actively attempting to escape a debt. In this paper, we study the skip-tracing procedure for a large firm specializing in debt collection. This firm currently contracts an address search service to research and compile a list of possible addresses for each debtor and recommend one address as the most probable. We use a simple maximum likelihood estimation procedure for assessing the \u201cfalse positive \u201d and \u201cfalse negative \u201d probabilities. Having determined the accuracy of the address search service, we study the optimal decision for the firm taking into account the costs and probabilities of all the available alternatives for \u201cskip-tracing\u201d. Our preliminary findings suggest that at high confidence levels, the firm stands to benefit monetarily by forgoing one of the most costly steps in the verification process.",
            "title": "Designing a Search Mechanism for Debt Collection"
        },
        {
            "group": 188,
            "name": "10.1.1.119.7223",
            "keyword": "",
            "author": "Ir\u00e8ne Abi-zeid, Qiang Yang, Luc Lamontagne",
            "abstract": "Abstract. In response to the occurrence of an air incident, controllers at one of the three Canadian Rescue Coordination Centers (RCC) must make a series of critical decisions on the appropriate procedures to follow. These procedures (called incident prosecution) include hypotheses formulation and information gathering, development of a plan for the search and rescue (SAR) missions and in the end, the generation of reports. We present in this paper the results of a project aimed at evaluating the applicability of CBR to help support incident prosecution in the RCC. We have identified three possible applications of CBR: Online help, real time support for situation assessment, and report generation. We present a brief description of the situation assessment agent system that we are implementing as a result of this study. 1",
            "title": "Is CBR applicable to the coordination of search and rescue operations? A feasibility study"
        },
        {
            "group": 189,
            "name": "10.1.1.119.8442",
            "keyword": "Key Words, Multi-criteria analysis, Neighborhood preferences, Search tool software 1",
            "author": "Rupali Kale A, Yichun Xie B",
            "abstract": "A method is presented for multi-criteria analysis using two different families of preference functions to identify non-subsidized rental properties and to assist real estate agents and people seeking housing accommodations. Apartments are screened for user\u2019s selection of apartment characteristics and are further ranked based on regional and neighborhood characteristics. Typically, the existing online apartment search tools only filter apartments matching user input criteria and do not consider any neighborhood factors. The present study identifies and ranks apartments based on the user preferred neighborhood variables. A software application is developed using Visual basic and Arcobjects in ArcGIS 8.3. This application first selects apartments based on typical apartment characteristics as desired by the user. The user then has further options to choose his/her preferences for the neighborhood characteristics for the selected apartments. This technique adds a new dimension to existing search tools to increase the satisfaction level of the user and ranking the selected apartments based on individual preferences. The neighborhood preferences that are considered in the present study are socio-economic status of the area, proximity to",
            "title": "Multi-Criteria Analysis using Preference Function Method for Developing a Rental Property Search Tool in GIS"
        },
        {
            "group": 190,
            "name": "10.1.1.119.9174",
            "keyword": "",
            "author": "David J. Mcnamara",
            "abstract": "Issues in porting an existing C image processing application into Data Parallel C are discussed. This paper shows several examples of Data Parallel C code. Performance of the application on two distributed parallel systems is presented.",
            "title": "Data Parallel C Extensions Applied to Image Processing: A Faster Search for Extraterrestrial Objects"
        },
        {
            "group": 191,
            "name": "10.1.1.119.9323",
            "keyword": "",
            "author": "Ronald A. Rensink",
            "abstract": "A set of visual search experiments tested the proposal that focused attention is needed to detect change. Displays were arrays of rectangles, with the target being the item that continually changed its orientation or contrast polarity. Five aspects of performance were examined: linearity of response, processing time, capacity, selectivity, and memory trace. Detection of change was found to be a self-terminating process requiring a time that increased linearly with the number of items in the display. Capacity for orientation was found to be about five items, a value comparable to estimates of attentional capacity. Observers were able to filter out both static and dynamic variations in irrelevant properties. Analysis also indicated a memory for previously attended locations. These results support the hypothesis that the process needed to detect change is much the same as the attentional process needed to detect complex static patterns. Interestingly, the features of orientation and polarity were found to be handled in somewhat different ways. Taken together, these results not only provide evidence that focused attention is needed to see change, but also show that",
            "title": "Visual search for change: A probe into the nature of attentional processing"
        },
        {
            "group": 192,
            "name": "10.1.1.12.1409",
            "keyword": "",
            "author": "Mark D Dunlop,  Kieran McDonald",
            "abstract": "This paper reports the design and development of the Diceman Query Application. This is the end-user query application for a video indexing and retrieval project based on the Diceman architecture for distributed internet content exchange using MPEG-7 and agent negotiation. The query application was developed to support different search strategies of users accessing large video archives that have been indexed with a complex indexing language. The paper describes the interface, its design, the strategies supported, and initial results from user tests of building complex queries using the query interface (including a discussion of end-users ability to formulate meaningful semantic queries using low-level indexing features). Finally the paper discusses the implications of the interface on the underlying search engine.",
            "title": "Supporting Different Search Strategies in a Video Query Interface"
        },
        {
            "group": 193,
            "name": "10.1.1.12.2055",
            "keyword": "",
            "author": "Peter Marendy, Supervisor Dr. Bruce Litow",
            "abstract": "With the daily addition of in excess of a million documents, the World  Wide Web is expanding at a rapid rate. This expansion presents the users,  often nev to the use of the Web, vith a dilemma. Conventional search  engines utilise text matching methods applied to vast indexes of vords  found on veb pages. This method can produce overvhelming numbers  of pages that match the search query vhich are not necessarily relevant  to the information sought by the user. By utilising the link structure of  the World Wide Web, relevant results can be distilled and extracted to  produce a small set of highly relevant pages.",
            "title": "A Review of World Wide Web searching techniques, focusing on HITS and related algorithms that utilise the link topology of the World Wide Web to provide the basis for a structure based search technology."
        },
        {
            "group": 194,
            "name": "10.1.1.12.3181",
            "keyword": "Key words, Similarity search, Sequence database, Categorization, Indexing, Suffix tree, Time warping distance \u22c6 Recommended by Dr. Nick Koudas",
            "author": "Sanghyun Park,  Wesley W. Chu,  Jeehee Yoon,  Jungim Won",
            "abstract": "This paper proposes an indexing technique for fast retrieval of similar subsequences using the time warping distance. The time warping distance is a more suitable similarity measure than the Euclidean distance in many applications where sequences may be of different lengths and/or different sampling rates. The proposed indexing technique employs a disk-based suffix tree as an index structure and uses lower-bound distance functions to filter out dissimilar subsequences without false dismissals. To make the index structure compact and hence accelerate the query processing, it converts sequences in the continuous domain into sequences in the discrete domain and stores only a subset of the suffixes whose first values are different from those of the immediately preceding suffixes. Extensive experiments with real and synthetic data sequences revealed that the proposed approach significantly outperforms the sequential scan and LB scan approaches and scales well in a large volume of sequence databases.",
            "title": "Similarity Search of Time-Warped Subsequences Via a Suffix Tree"
        },
        {
            "group": 195,
            "name": "10.1.1.12.3438",
            "keyword": "",
            "author": "Zheng Chen, Liu Wenyin, Chunhui Hu, Mingjing Li, Hongjiang Zhang",
            "abstract": "Introduction  iFind (v1.0) is a web-based image retrieval system developed at Microsoft Research China. It provides the functionalities of text based image search, query by image example, and their combination. Images in the database are indexed by their lowlevel (visual) features, high-level (semantic) features (collected from image's environment, e.g., the Web), and optionally, annotations if they are available. The key technology in the system is the integrated semantics and feature based image retrieval and relevance feedback approach and data mining of users' feedback log. When the user provides feedback images, the system can refine the retrieval result based on the user's feedback. In the meantime, the system updates the annotation of feedback images by increasing the linkage to the positive examples' annotation and decreasing the linkage to the negative examples' annotation. The updated annotation can further help to improve image retrieval results of the system in later use. L",
            "title": "iFind: A Web Image Search Engine"
        },
        {
            "group": 196,
            "name": "10.1.1.12.4064",
            "keyword": "",
            "author": "Maxim Lifantsev,  Tzi-Cker Chiueh",
            "abstract": "Yuntis is a fully-functional prototype of a complete web search engine with features comparable to those available in commercial-grade search engines. In particular, Yuntis supports page quality scoring based on global web linkage graph, extensively exploits text associated with links, computes pages' keywords and lists of similar pages of good quality, and provides a very flexible query language. This paper reports our experiences in the three-year development process of Yuntis, by presenting its design issues, software architecture, implementation details, and performance measurements.",
            "title": "Implementation of a Modern Web Search Engine Cluster"
        },
        {
            "group": 197,
            "name": "10.1.1.12.4633",
            "keyword": "",
            "author": "Hercules Dalianis",
            "abstract": "The information in a database is usually accessed using SQL or some other query  language, but if one uses a free text retrieval system the retrieval of text based information  becomes much easier and user friendly, since one can use natural languages techniques such  as automatic spell checking and stemming. The free text retrieval system needs first to  index the database but then it is just to search the database.",
            "title": "Evaluating a Spelling Support in a Search Engine"
        },
        {
            "group": 198,
            "name": "10.1.1.12.5741",
            "keyword": "",
            "author": "Ping Zhang,  Gilbert Maker",
            "abstract": "This paper reports a study on the role of a subject's intention on animation interference. Experiment results show that first, experiment instruction can sometimes eliminate animation interference. Second, the moment animation is on the screen does not differentiate the animation interference if the subjects are not instructed to ignore animation. Third, stay on animation has less impact than animation that is repeated on and off during the task. This research has practical implications for user interface designs, especially web designs, and theoretical implications for the predictive power of classic visual attention theories in computing environments",
            "title": "Effects Of Allocated Attention On Visual Search Tasks: A Web-Based Experiment on Animation Interference"
        },
        {
            "group": 199,
            "name": "10.1.1.12.6066",
            "keyword": "",
            "author": "Josue Kuri, Nicolas Puech, Maurice Gagnaire, Emmanuel Dotaro",
            "abstract": "blem. .  We developed both exact and approximate resolution algorithms for the combinatorial optimization problem. Routing problem: mathematical model G = (V, E, w)  is an edge-weighted undirected graph with vertex set V =  {v  1 , v 2 , . . . , v N  },  edge set E =  {e  1 , e 2 , . . . , e L   and weight function w : E   R  +  . # =  {#  1 , # 2 , . . . , # M   is the set of M SLDs, where # i = (s i , d i , n i , # i , # i ) is a tuple representing the SLD number i; s i , d i   V are the source and destination nodes, n i is the number of requested lightpaths, and # i and # i are the set-up and tear-down dates. (G, #)  is a pair representing an instance of the RWA problem. N =  |V |,  L =  |E|,  K max  are, respectively, the number of vertices and edges in G and the maximum number of possible alternate paths for each demand. Routing problem: mathematical model P k,i , 1   k   K max , 1   i    represents the k   alternate path in G from s i to d i . # #,# = (P # 1 ,1 P # 2 ,2 . . . P #",
            "title": "Routing of Scheduled Lightpath Demands Using a Tabu Search Meta-heuristic"
        },
        {
            "group": 200,
            "name": "10.1.1.12.6160",
            "keyword": "Web-based Services, I.3.8 [Computer Graphics, Applications Keywords, Specialized search engine, 3D model database, shape matching, shape",
            "author": "Patrick Min,  John A. Halderman, Michael Kazhdan, Thomas A. Funkhouser",
            "abstract": "New acquisition and modeling tools make it easier to create 3D models, and affordable and powerful graphics hardware makes it easier to use them. As a result, the number of 3D models available on the web is increasing rapidly. However, it is still not as easy to find 3D models as it is to find, for example, text documents and images. What is needed is a \"3D model search engine,\" a specialized search engine that targets 3D models. We created a prototype 3D model search engine to investigate the design and implementation issues. Our search engine can be partitioned into three main components: (1) acquisition: 3D models have to be collected from the web, (2) analysis: they have to be analyzed for later matching, and (3) query processing and matching: an online system has to match user queries to the collected 3D models. Our site currently indexes over 36,000 models, of which about 31,000 are freely available. In addition to a text search interface, it offers several 3D and 2D shape-based query interfaces. Since it went online one year ago (in November 2001), it has processed over 148,000 searches from 37,800 hosts in 103 different countries. Currently 20--25% of the about 1,000 visitors per week are returning users. This paper reports on our initial experiences designing, building, and running the 3D model search engine.",
            "title": "Early Experiences with a 3D Model Search Engine"
        },
        {
            "group": 201,
            "name": "10.1.1.12.6196",
            "keyword": "",
            "author": "Torsten Suel, Chandan Mathur, Jo-wen Wu, Jiangong Zhang,  Alex Delis, Mehdi Kharrazi, Xiaohui Long, Kulesh Shanmugasundaram",
            "abstract": "this paper appears in [15], and updated information is available at http://cis.poly.edu/westlab/odissea/",
            "title": "ODISSEA: A Peer-to-Peer Architecture for Scalable Web Search and Information Retrieval"
        },
        {
            "group": 202,
            "name": "10.1.1.12.6600",
            "keyword": "",
            "author": "Katy B\u00f6rner",
            "abstract": "Massive amounts of data are available in today's Digital Libraries (DLs). The challenge is to find relevant information quickly and easily, and to use it effectively. A standard way to access DLs is via a text-based query issued by a  single user. Typically, the query results in a potentially very long ordered list of matching documents, that makes it hard for users to find what they are looking for.",
            "title": "iScape: A Collaborative Memory Palace for Digital Library Search Results"
        },
        {
            "group": 203,
            "name": "10.1.1.12.7449",
            "keyword": "",
            "author": "Josue Kuri, Nicolas Puech, Maurice Gagnaire, Emmanuel Dotaro",
            "abstract": "In this paper we investigate the problem of routing a set of lightpath demands for which the set-up and tear-down dates are known. We call this type of requests Foreseeable Lightpath Demands  or FLDs. In a transport network, FLDs correspond, for example, to clients' requests for pre-provisioned bandwidth capacity such as fixed-bandwidth pipes for bulk data transfers during the night, extra VPN bandwidth used during peak office working time, etc. Since in some cases the FLDs are not all simultaneous in time, it is possible to reuse physical resources to realize time-disjoint demands. We propose a routing algorithm that takes into account this property to minimize the number of required WDM channels in the physical links of the network. The gain (in terms of saved WDM channels) provided by the algorithm, when compared to a shortest path routing strategy, depends both on the spatial and temporal structure of the set of traffic demands and on the structure of the physical network. The routing problem is formulated as a spatio-temporal combinatorial optimization problem. A Tabu Search meta-heuristic algorithm is developed to solve this problem. I. ",
            "title": "Routing Foreseeable Lightpath Demands Using a Tabu Search Meta-heuristic"
        },
        {
            "group": 204,
            "name": "10.1.1.12.824",
            "keyword": "Camera motion, Correspondences, 3D reconstruction, Structure metrics, Scatter, Tensor voting",
            "author": "Faysal Boughorbel, Paul Crilly, Andreas Koschan,  Mongi Abidi",
            "abstract": "A novel approach is presented for recovering the motion parameters of a camera from two frames. The proposed method does not require establishing point correspondences between the images, as does most current techniques. Our approach is also more straightforward than the very few non-correspondence motion estimation algorithms. It is based on the estimation of structure for each given set of motion parameters. This resulting structure is then evaluated in an optimization process using saliency metrics, until the best structure and motion parameters are obtained. In this work we have devised and tested two different structure metrics: the first based on scatter and the second using tensor voting. Experimental results show that this method is effective and can be used in video-based scene modeling systems.",
            "title": "Estimating 3D camera motion without correspondences using a search for the best structure"
        },
        {
            "group": 205,
            "name": "10.1.1.12.8464",
            "keyword": "",
            "author": "Cees G.M. Snoek, Marcel Worring",
            "abstract": "Goalgle is a prototype search engine for soccer video. Browsing  and retrieval functionality is provided by means of a web based interface. This interface allows users to jump to video segments from a collection of prerecorded and analyzed soccer matches based on queries on specific players, events, matches, and/or text. In this contribution we discuss the system architecture and functionality of the Goalgle soccer video search engine.",
            "title": "Goalgle: A Soccer Video Search Engine"
        },
        {
            "group": 206,
            "name": "10.1.1.12.8733",
            "keyword": "Logical topology design, WDM, tabu search, network optimization, network planning",
            "author": "Josue Kuri, Nicolas Puech, Maurice Gagnaire",
            "abstract": "We propose a Tabu Search (TS) algorithm to solve the problem of designing a logical topology for packet- switched traffic over a WDM mesh network. The cost of mapping such a logical topology over a physical network is taken into account. The algorithm provides approximate solutions of good quality (i.e., close to the optimal ones) to the corresponding optimization problem and allows us to solve problem instances of large size, which is usually impossible with algorithms solving exactly the Integer Linear Programming (ILP) formulations of the problem. The algorithm makes it possible to evaluate the cost-performance tradeoff between designing a logical topology with small congestion and a large number of (possibly expensive) lightpaths and designing a less expensive topology with higher congestion.",
            "title": "A Tabu Search Algorithm to Solve a Logical Topology Design Problem in WDM Networks Considering Implementation Cost"
        },
        {
            "group": 207,
            "name": "10.1.1.120.2595",
            "keyword": "",
            "author": "Alan Messer, Anugeetha Kunjithapatham, Phuong Nguyen, Priyang Rathod, Mithun Sheshagiri, Doreen Cheng, Simon Gibbs",
            "abstract": "The Internet has become an extremely popular source of entertainment and information. But, despite the growing amount of media content, most Web sites today are designed for access via web browsers on the PC, making it difficult for home consumers to access Internet content on their TVs or other devices that lack keyboards. As a result, the Internet is generally restricted to access on the PC or via cumbersome interfaces on non-PC devices. In this paper, we present unobtrusive and assistive technologies enabling home users to easily find and access Internet content related to the TV program they are watching. Using these technologies, the user is now able to access relevant information and video content on the Internet while watching TV. 1.",
            "title": "SeeNSearch: A Context Directed Search Facilitator for Home Entertainment Devices"
        },
        {
            "group": 208,
            "name": "10.1.1.120.3004",
            "keyword": "",
            "author": "Daniel M. Cable, Timothy A. Judge, Martin Wells For",
            "abstract": "The present study investigated the degree to which pay preferences influenced job search decisions in both hypothetical and actual organizations, and the degree to which preferences for particular compensation attributes depended on job seekers ' dispositional characteristics. Based on prior theory and research, we hypothesized that certain pay systems generally would be preferred by job seekers, that these pay systems would affect applicant attraction to organizations, and that different types of job seekers would be attracted to different types of pay systems. The sample comprised 171 college students who were seeking jobs during the study, and who represented six majors, three degree types, and two degree levels. Experimental policy-capturing results and results obtained about actual companies with which the job seekers would potentially interview supported hypotheses that organizations perceived to offer high pay levels, flexible benefits, individualbased pay, and fixed pay policies were more attractive to job seekers.",
            "title": "Pay preferences and job search decisions: A person-organization fit perspective"
        },
        {
            "group": 209,
            "name": "10.1.1.120.4060",
            "keyword": "",
            "author": "Jay Sethuraman, John N. Tsitsiklis",
            "abstract": "We consider a generalization of the model of stochastic search in an out-forest, introduced and studied by Denardo, Rothblum, and Van der Heyden [1]. We provide a simple proof of the optimality of index-based policies. 1",
            "title": "Stochastic search in a forest revisited \u2217"
        },
        {
            "group": 210,
            "name": "10.1.1.120.6335",
            "keyword": "",
            "author": "On Anna Sfard, Anna Prusak\u2019s \u201ctelling Identities, Mary M. Juzwik, Anna Sfard, Anna Prusak",
            "abstract": "articulate the promise of story or narrative in defining identity as an analytic tool in sociocultural research on learning. The article, as I read it, strives toward a process-rich notion of identity that responds to prior sociocultural articulations of identity as an analytic construct (e.g., Gee, 2001; Holland, Lachiotte, Skinner,  & Cain, 1998). Noting the dangers of treating identity as a product or an essential core that remains static over a lifetime\u2014or that boils down to \u201cis-statements \u201d about \u201cbeing a certain kind of person \u201d (p. 16)\u2014 Sfard and Prusak theorize identity as a relational and dynamic process. That is, identity changes across time (cf. Lemke, 2000) and space (cf. Gee, 2001), and thus is always in motion. These changes depend, at least in part, on social and contextual interactions, rather than on inner or individual processes alone. Theorizing identity as a process, the authors propose narrative, or story, as a definition that can allow the term identity to serve as",
            "title": "In their \u201cTelling Identities: In Search of an Analytic Tool for Investigating Learning as a Culturally Shaped Activity \u201d (Educational"
        },
        {
            "group": 211,
            "name": "10.1.1.120.6514",
            "keyword": "",
            "author": "Marco Chiarandini, Irina Dumitrescu, Thomas St\u00fctzle",
            "abstract": " The Graph Colouring Problem (GCP) is a well known NP-hard problem with many theoretical and practical applications. In this paper we introduce a new local search algorithm based on a very large scale neighbourhood. We provide an extensive numerical comparison between this method and several other local search techniques considering also the embedding of the local search into more complex schemes like Iterated Local Search or Tabu Search. ",
            "title": "Local Search for the Colouring Graph Problem. A Computational Study"
        },
        {
            "group": 212,
            "name": "10.1.1.120.9728",
            "keyword": "",
            "author": "Matt Wilding",
            "abstract": "representing the official policies, either expressed or implied, of",
            "title": "A mechanically-checked correctness proof of a floating-point search program"
        },
        {
            "group": 213,
            "name": "10.1.1.120.9849",
            "keyword": "",
            "author": "Dmitrii E. Makarov, Kevin W. Plaxco, Email Alerting, Dmitrii E. Makarov, Kevin, W. Plaxco",
            "abstract": "The topomer search model: A simple, quantitative theory of",
            "title": "REVIEW The topomer search model: A simple, quantitative theory of"
        },
        {
            "group": 214,
            "name": "10.1.1.121.1970",
            "keyword": "",
            "author": "Hisao Ishibuchi, Tadahiko Murata",
            "abstract": "We have already proposed a multi-objective genetic local search algorithm for finding nondominated solutions of multi-objective optimization problems (Ishibuchi & Murata 1998). In our hybrid algorithm, a local search procedure is applied to each solution generated by genetic operations (i.e., selection, crossover, and mutation). Since our optimization problem involves multiple objectives, the application of the local search is not straightforward. In this paper, we examine various methods for implementing local search procedures in our multi-objective genetic local search algorithm. One method uses a weighted sum of multiple objectives as a scalar fitness function where weight values are randomly updated whenever a pair of parent solutions is selected. Such a fitness function is used in the local search as well as the selection of parent solutions. In a variant of this method, weight values for a solution in the local search are specified according to its location in the objective space. Another method uses an inequality relation between solutions based on multiple objectives when a local search procedure determines whether the current solution is to be replaced with a new solution. The performance of multi-objective genetic local search algorithms with various local search procedures is examined by computer simulations on two-objective flowshop scheduling problems. 1.",
            "title": "Local search procedures in a multi-objective genetic local search algorithm for scheduling problems"
        },
        {
            "group": 215,
            "name": "10.1.1.121.2728",
            "keyword": "Contents",
            "author": "Osku Salerma, Helsingin Yliopisto, University Of Helsinki, Osku Salerma",
            "abstract": "Full Text Search (FTS) is a term used to refer to technologies that allow efficient retrieval of relevant documents matching a given search query. Going through each document in a collection and determining if it matches the search query does not scale to large collection sizes, so more efficient methods are needed. We start by describing the technologies used in FTS implementations, concentrating specifically on inverted index techniques. Then we conduct a survey of six existing FTS implementations, of which three are embedded in database management systems and three are independent systems. Finally, we present our design for how to add FTS index support to the InnoDB database management system. The main difference compared to existing systems is the addition of a memory buffer that caches changes to the index before flushing them to disk, which gives us such benefits as real-time dynamic updates and less fragmentation in on-disk data structures.",
            "title": "Ty\u00f6n nimi \u2014 Title Design of a Full Text Search index for a database management system"
        },
        {
            "group": 216,
            "name": "10.1.1.121.3424",
            "keyword": "",
            "author": "Osma Suominen, Kim Viljanen, Eero Hyv\u00f6nen",
            "abstract": "This paper presents TerveSuomi.fi, a prototype of a national semantic health portal in Finland. TerveSuomi.fi aggregates ontological metadata created by various Finnish health organizations in a distributed environment. The portal provides a faceted search user interface created from the perspective of ordinary citizens and cross-links documents from multiple sources with recommendations based on ontological knowledge. ",
            "title": "Semantic Faceted Search in a Citizens\u2019 Health Portal"
        },
        {
            "group": 217,
            "name": "10.1.1.121.5457",
            "keyword": "",
            "author": "Michael Wetter, Jonathan Wright",
            "abstract": "",
            "title": "Comparison of a generalized pattern search and a genetic algorithm optimization method"
        },
        {
            "group": 218,
            "name": "10.1.1.121.6074",
            "keyword": "",
            "author": "Claudio Gennaro, Matteo Mordacchini, Salvatore Orlando, Fausto Rabitti",
            "abstract": " Similarity search for content-based retrieval (where content can be any combination of text, image, audio/video, etc.) has gained importance in recent years, also because of the advantage of ranking the retrieved results according to their proximity to a query. However, to use similarity search in real world applications, we need to tackle the problem of huge volumes of such mixed multimedia data (e.g., coming from Web sites) and the problem of their distribution on multiple cooperating nodes. This is the situation of the NeP4B project (Networked Peers for Business), where the distributed nodes (i.e., peers) represent aggregations of SME\u2019s with similar activities and the multimedia objects are descriptions/presentations of their products/services extracted from the companies \u2019 Web sites. In this paper we approach this problem by considering a scenario of a network of autonomous peers maintaining a local collection of metric objects (i.e., mixed mode multimedia content). This network forms a distributed Peer\u2013to\u2013Peer (P2P) search engine for similarity search based on the paradigm of Routing Index. Each peer in the network thus maintains both an index of its local resources and a table for every neighbor, summarizing the objects that are reachable from it. The paper presents techniques that aim to make our P2P similarity-based search system viable, trading approximate results for scalable solutions. Results of simulations that use real collections of images are discussed. ",
            "title": "MRoute: A Peer-to-Peer Routing Index for Similarity Search in Metric Spaces "
        },
        {
            "group": 219,
            "name": "10.1.1.121.6473",
            "keyword": "",
            "author": "Wheeler Ruml",
            "abstract": "To my family.",
            "title": "Adaptive Tree Search A thesis"
        },
        {
            "group": 220,
            "name": "10.1.1.121.9953",
            "keyword": "",
            "author": "Francesco Caviglia, Maria Ferraris",
            "abstract": "Abstract The Web is widely used, in educational settings, typically as a repository of contents to be learned. Within this approach, the Web-searching process tends to be perceived merely as an obstacle on the way to the contents. This paper suggests instead that searching the Web requires information problem solving competences which are in themselves key requisites for literacy in a knowledge society and deserve to be fostered as explicit goals in educational settings. Given the complexity of the competences involved, it is suggested that educational intervention focus on practice with information problems which should be thin in content, but rich in opportunities for bringing to the foreground and refining some critical areas of the information problem solving process. 1",
            "title": "The Web as a learning environment Focus on contents vs. focus on the search process"
        },
        {
            "group": 221,
            "name": "10.1.1.122.1148",
            "keyword": "",
            "author": "Steffen H\u00f6lldobler, Eldar Karabaev, Olga Skvortsova",
            "abstract": "We present a heuristic search algorithm for solving first-order Markov Decision Processes (FOMDPs). Our approach combines first-order state abstraction that avoids evaluating states individually, and heuristic search that avoids evaluating all states. Firstly, in contrast to existing systems, which start with propositionalizing the FOMDP and then perform state abstraction on its propositionalized version we apply state abstraction directly on the FOMDP avoiding propositionalization. This kind of abstraction is referred to as first-order state abstraction. Secondly, guided by an admissible heuristic, the search is restricted to those states that are reachable from the initial state. We demonstrate the usefulness of the above techniques for solving FOMDPs with a system, referred to as FluCaP (formerly, FCPlanner), that entered the probabilistic track of the 2004 International Planning Competition (IPC\u20192004) and demonstrated an advantage over other planners on the problems represented in first-order terms. 1.",
            "title": "Engineering Note FluCaP: A Heuristic Search Planner for First-Order MDPs"
        },
        {
            "group": 222,
            "name": "10.1.1.122.209",
            "keyword": "",
            "author": "Jeff M. Phillips, C. S. Draper Laboratories",
            "abstract": "Abstract \u2014 Motion planning for systems with constraints on controls or the need for relatively straight paths for real-time actions presents challenges for modern planners. This paper presents an approach which addresses these types of systems by building on existing motion planning approaches. Guided Expansive Spaces Trees are introduced to search for a low cost and relatively straight path in a space with motion constraints. Path Gradient Descent, which builds on the idea of Elastic Strips, finds the locally optimal path for an existing path. These techniques are tested on simulations of rendezvous and docking of the space shuttle to the International Space Station and of a",
            "title": "Guided expansive spaces trees: A search strategy for motion- and cost-constrained state spaces"
        },
        {
            "group": 223,
            "name": "10.1.1.122.4726",
            "keyword": "",
            "author": "Swamp M, Sahadeb Jana, Debashis Saha",
            "abstract": "'Abstract-This Thb paper proposes an efficient dynamic wavelength assignment heuristic search technique for optical networks The static wavelength assignment for optical network is known to be NP-hard problem in literature. This is true for dynamic wavelength assignment Thus the problem can be formulated as combinatorial optimization problem. So to solve this problem an efficient heuristic search technique can be used. In the proposed study, we have assumed that all nodes of an optical network are having converter of limited wavelength conversion capshilily. In this work we have used best fit search technique. and tried to study time wquirement and call blocking probability for setting up a lightpath between a pair of nodes with optimum number of wavelength conversion. (Absfrac9 Xeyworh- Besf First Search; optimal; average wavehnglh ufilizufion per lin; roulepafh",
            "title": "Proceedings of ICCT2003 A Heuristic Search for Dynamic Lightpath Establishment in WDM Optical Networks with Limited Wavelength Conversion Capability"
        },
        {
            "group": 224,
            "name": "10.1.1.122.6420",
            "keyword": "",
            "author": "",
            "abstract": "to sift through the long ordered list of document \u201csnippets\u201d returned by the engines. The IR community has explored document clustering as an alternative method of organizing retrieval results, but clustering has yet to be deployed on the major search engines. The paper articulates the unique requirements of Web document clustering and reports on the first evaluation of clustering methods in this domain. A key requirement is that the methods create their clusters based on the short snippets returned by Web search engines. Surprisingly, we find that clusters based on snippets are almost as good as clusters created using the full text of Web documents. To satisfy the stringent requirements of the Web domain, we introduce an incremental, linear time (in the document collection size) algorithm called Suffix Tree Clustering (STC), which creates clusters based on phrases shared between documents. We show that STC is faster than standard clustering methods in this domain, and argue that Web document clustering via STC is both feasible and potentially beneficial. 1",
            "title": "Web Document Clustering: A Feasibility Demonstration Abstract Users of Web search engines are often forced"
        },
        {
            "group": 225,
            "name": "10.1.1.122.7191",
            "keyword": "Index Terms\u2014Clustering methods, Data clustering, Data mining, Search methods, Search trees C",
            "author": "I. Introduction",
            "abstract": "Abstract\u2014A new data structure called \u201cclustering tree \u201d is presented in this paper. With this new data structure, a new clustering algorithm producing a set of clusters with guaranteed similarity is described. We also show that the same clustering tree can be used efficiently as a d-dimensional search tree.",
            "title": "Two Birds With One Stone: A Similarity- Guaranteed Clustering Algorithm and Its Search Tree"
        },
        {
            "group": 226,
            "name": "10.1.1.122.9729",
            "keyword": "C.2.4 [Computer-Communication Networks, Distributed Systems General Terms Algorithms, Design, Experimentation Keywords Search",
            "author": "Jyh-how Huang",
            "abstract": "This paper describes the design, implementation and evaluation of a search and rescue system called CenWits. CenWits uses several small, commonly-available RF-based sensors, and a small number of storage and processing devices. It is designed for search and rescue of people in emergency situations in wilderness areas. A key feature of CenWits is that it does not require a continuously connected sensor network for its operation. It is designed for an intermittently connected network that provides only occasional connectivity. It makes a judicious use of the combined storage capability of sensors to filter, organize and store important information, combined battery power of sensors to ensure that the system remains operational for longer time periods, and intermittent network connectivity to propagate information to a processing center. A prototype of CenWits has been implemented using Berkeley Mica2 motes. The paper describes this implementation and reports on the performance measured from it.",
            "title": "Cenwits: A sensor-based loosely coupled search and rescue system using witnesses"
        },
        {
            "group": 227,
            "name": "10.1.1.123.2651",
            "keyword": "",
            "author": "Pablo Moscato",
            "abstract": "Abstract Although it is not a newcomer in the combinatorial optimization literature, Local Search is an emerging paradigm for combinatorial search, which has been recently shown to be very effective for a large number of scheduling problems. A number of metaheuristics based on local search have been also proposed to address with success a variety of scheduling problems. In this tutorial, we survey the basic local search techniques proposed in the literature and implemented in many industrial scheduling systems: Simulated Annealing, Tabu Search, and various forms of Hill Climbing. We also illustrate some of the most promising improvements and variations of such basic techniques which are currently investigated. Finally, we propose the combination of local search with other solution paradigms, such as genetic algorithms and constructive heuristics. Throughout the tutorial we illustrate three case studies of successful applications of these techniques to real life problems: school timetabling, frequency assignment in mobile radio systems, and sport scheduling.",
            "title": "Local Search Techniques for Scheduling Problems-- A Tutorial--"
        },
        {
            "group": 228,
            "name": "10.1.1.123.3534",
            "keyword": "",
            "author": "Mark H. M. Win, Jos W. H. M. Uiterwijk, H. Jaap Van Den Herik",
            "abstract": "Abstract. The paper introduces a new proof-number (PN) search algorithm, called PDS-PN. It is a two-level search, which performs at the first level a depth-first Proof-number and Disproof-number Search (PDS), and at the second level a best-first PN search. First, we thoroughly investigate four established algorithms in the domain of LOA endgame positions: PN, PN 2, PDS and \u03b1\u03b2 search. It turns out that PN 2 and PDS are best in solving hard problems when measured by the number of solutions and the solution time. However, each of those two has a practical disadvantage: PN 2 is restricted by the working memory, and PDS is relatively slow in searching. Then we formulate our new algorithm by selectively using the power of each one, viz. the two-level nature and the depth-first traversal respectively. Experiments reveal that PDS-PN is competitive with PDS in terms of speed and with PN 2 since it is not restricted in working memory. 1",
            "title": "PDS-PN: A New Proof-Number Search Algorithm Application to Lines of Action"
        },
        {
            "group": 229,
            "name": "10.1.1.123.3579",
            "keyword": "Pickup and Delivery Problem with Time Windows, Fixed size fleet, Tabu search heuristic. In the Pickup and Delivery Problem with Time Windows and a Fixed Size",
            "author": "Fabien Malca, Fr\u00e9d\u00e9ric Semet",
            "abstract": "Fleet (m-PDPTW), a transportation carrier with a fixed size fleet of m vehicles receives a set of n requests. Each request consists of picking up a load, with a certain size, from some origin and to deliver it to a destination, in order to respect the time windows associated with the pickup location and the delivery location. Since the heterogenous fleet is finite, with finite capacity vehicles, some requests may be not assigned to a vehicle route without generating some delay on the time windows or exceeding the vehicle capacity. Then such requests cannot be accepted and are rejected. The aim is then to maximize the number of requests assigned to vehicles routes among the n requests, and next to minimize the total travel cost. Such a description scheme seems to be useful in the context of dynamic routing problems. The purpose of this paper is to provide a fast algorithm designed for the static case, before embedding it in a dynamic context in future work. 1 Notations and problem description We begin this section by providing notations, then we define the problem studied.",
            "title": "A Tabu Search Heuristic for the Pickup and Delivery Problem with Time Windows and a Fixed Size Fleet"
        },
        {
            "group": 230,
            "name": "10.1.1.123.4673",
            "keyword": "",
            "author": "Yaniv Eytani",
            "abstract": "A Random test generator generates executable tests together with their expected results. In the form of a noise-maker, it seeds the program with conditional scheduling primitives (such as yield()) that may cause context switches. As a result different interleavings are potentially produced in different executions of the program. Determining a-priori the set of seeded locations required for a bug to manifest itself is rarely possible. This work proposes to reformulate random test generation of concurrent Java programs as a search problem. Hence, it allows applying a set of well known search techniques from the domain of AI to the input space of the test generator. By iteratively refining the input parameters fed to the test generator, the search process creates testing scenarios (i.e. interleavings) that maximizes predefined objective functions. We develop geneticFinder, a noise-maker that uses a genetic algorithm as a search method. We demonstrate our approach by maximizing two objective functions: the high manifestation rate of concurrent bugs and the exporting of a high degree of debugging information to the user. Experimental results show our approach is effective. 1",
            "title": "Concurrent Java test generation as a search problem"
        },
        {
            "group": 231,
            "name": "10.1.1.123.4977",
            "keyword": "",
            "author": "Bijit Hore, Ravi Ch, Ra Jammalamadaka, Sharad Mehrotra",
            "abstract": "k-anonymity is a popular measure of privacy for data publishing: It measures the risk of identity-disclosure of individuals whose personal information are released in the form of published data for statistical analysis and data mining purposes(e.g. census data). Higher values of k denote higher level of privacy (smaller risk of disclosure). Existing techniques to achieve k-anonymity use a variety of \u201cgeneralization \u201d and \u201csuppression \u201d of cell values for multi-attribute data. At the same time, the released data needs to be as \u201cinformation-rich \u201d as possible to maximize its utility. Information loss becomes an even greater concern as more stringent privacy constraints are imposed [4]. The resulting optimization problems have proven to be computationally intensive for data sets with large attribute-domains. In this paper, we develop a systematic enumeration based branchand-bound technique that explores a much richer space of solutions than any previous method in literature. We further enhance the basic algorithm to incorporate heuristics that potentially accelerate the search process significantly. 1",
            "title": "Flexible anonymization for privacy preserving data publishing: A systematic search based approach"
        },
        {
            "group": 232,
            "name": "10.1.1.123.5250",
            "keyword": "Search Engine, Buckets, BSP, Textual Databases, Supersteps",
            "author": "V. Gil Costa, A. M. Printista",
            "abstract": "Most information in science, engineering and business has been recorded in form of text. This information can be found online in the World-Wide-Web. One of the major tools to support information access are the search engines which usually use information retrieval techniques to rank Web pages based on a simple query and an index structure like the inverted lists. The retrieval models are the basis for the algorithms that score and rank the Web pages. The focus of this presentation is to show some inverted lists alternatives, based on buckets, for an information retrieval system. The main interest is how query performance is effected by the index organization on a cluster of PCs. The server design is effected on top of the parallel computing model Bulk",
            "title": "Buckets Inverted Lists for a Search Engine with BSP"
        },
        {
            "group": 233,
            "name": "10.1.1.123.6232",
            "keyword": "",
            "author": "Antti Leino",
            "abstract": "The existence of patterns as one of the factors in the toponomastic process has been known for more than a quarter of a century. However, while some onomasticians have suggested that such patterns can play an important role even when the names in question can be adequately explained by other means, such hypotheses have been rather difficult to prove. The present study is an attempt to address the issue: the goals were, first, to find regularities in the naming of Finnish lakes; second, to assess whether such regularities imply the presence of naming patterns; and third, to see if a quantitative study could give new insights about the properties of such patterns. This was done by applying methods developed in the computer science field of data mining to an electronic corpus consisting of all Finnish lake names found on the 1:20 000 Basic Map. These revealed several groups of names that appear next to each other significantly more often than could be expected, even after accounting for regional variation in the distributions of the names. Some of the groups can be explained by referring to e.g. cultural history, but in a large number of groups the names have a semantic relationship which suggests that there is a large number of relatively widespread patterns in naming Finnish lakes. However, these patterns are very specific and it is difficult to see a systematically productive general pattern. Some of the phenomena involved can be described using Construction Grammar, but it is evident that the theoretical framework needs some adjustments.",
            "title": "In Search of Naming Patterns: A Survey of Finnish Lake Names"
        },
        {
            "group": 234,
            "name": "10.1.1.123.6260",
            "keyword": "",
            "author": "Mathilde Bouvel, Vladimir Grebinski, Gregory Kucherov",
            "abstract": "Abstract. The goal of this paper is to present a brief survey of a collection of methods and results from the area of combinatorial search [1,8] focusing on graph reconstruction using queries of different type. The study is motivated by applications to genome sequencing.",
            "title": "Combinatorial search on graphs motivated by bioinformatics applications: A brief survey"
        },
        {
            "group": 235,
            "name": "10.1.1.123.6894",
            "keyword": "",
            "author": "Vinay Aggarwal, Anja Feldmann, Deutsche Telekom, Laboratories Tu Berlin",
            "abstract": "Summary. More than half of Internet traffic today is contributed by peer-to-peer (P2P) systems. P2P systems build their overlay topology largely agnostic of the Internet underlay, which often leads to traffic management challenges for Internet Service Providers (ISP) and potentially inefficient neighborhood selection for P2P nodes. To overcome this, we propose to use an oracle hosted by the ISPs, so that ISPs and P2P users can cooperate for improved performance. The oracle can be queried by P2P nodes while choosing neighbors for content search, and it will rank the possible neighbors of the querying node according to a locality indication, like the AS-hop distance. The ISP gains by keeping traffic within its Autonomous System (AS, and the P2P node can experience improved performance like lesser delay and better bandwidth. In this paper, we evaluate the benefits of our scheme by performing experiments in a real Testlab consisting of routers, switches and computers running actual instances of P2P applications. We show how we configure representative AS topologies for P2P networks using VLANs and trunking ports, and present experimental results with content search phase of a P2P network using different file sharing and search query distributions. 1",
            "title": "ISP-aided Biased Query Search for P2P systems in a Testlab"
        },
        {
            "group": 236,
            "name": "10.1.1.123.6989",
            "keyword": "",
            "author": "Marcus Lingenfelter",
            "abstract": "a seven-decade experiment in liberal education. Journal of general education 34 (2), 120-134. Schuman, D. (1981). &quot;Education and solipsism. &quot; CoEvolution Quarterly (Spring), 132-139. Sfard, A. (1998). On two metaphors for learning and the dangers of choosing just one. Educational Researcher, 27 (2), 4-13. Smallwood, S. (2002). Listening for the voice of the desert. Chronicle of Higher Education. Available at",
            "title": "Presidential Search Consultants in Higher Education: A Review of the Literature"
        },
        {
            "group": 237,
            "name": "10.1.1.123.7858",
            "keyword": "",
            "author": "Luc P. Devroye",
            "abstract": "A new class of random search algorithms for minimum in which in the search for a new best estistochastic optimization is presented. The designer has mate, onl y the very recent h1story of the search 1s tathe option to employ a learning memory in order to ken into account. This algor1thm thus operates with a reduce the cost of the optimization process measured short memory.However,over th ~ last five years two in terms of the number of observations. The asympto- factors in the design of optimlzation systems have tical properties of the procedure are discussed,and changed. First, the computers have become very fast new probability theoretical techniques are used in the and can handle very large active memories. On the f f rn nce other hand,the cost of taking measurements (i.e. col-proo 0 conve ~e. lecting data,evaluating a performance, etc.) has gone I. Introduction up considerably because of the increased cost of man-Let Q be an unknown real-valued function on a power. This has made the cost of the storage and proset B ~ Rm where m ~ 1. In many applications, one is in- cessing of data decrease relatively to the cost of obterested in finding a w in B for which Q(w) is nearly taining the data. This trend has been recognized by minimal. Because of the absence of any information several authors (e.g.[18]).So,one wants to develop",
            "title": "ON RANDOM SEARCH WITH A LEARNING MEMORY i'il;'i,if ~'l.!"
        },
        {
            "group": 238,
            "name": "10.1.1.123.8116",
            "keyword": "",
            "author": "Michael J. Cafarella, Oren Etzioni",
            "abstract": "Many modern natural language-processing applications utilize search engines to locate large numbers of Web documents or to compute statistics over the Web corpus. Yet Web search engines are designed and optimized for simple human queries\u2014they are not well suited to support such applications. As a result, these applications are forced to issue millions of successive queries resulting in unnecessary search engine load and in slow applications with limited scalability. In response, we have designed the Bindings Engine (BE), which supports queries containing typed variables and string-processing functions (Cafarella and Etzioni, 2005). For example, in response to the query \u201cpowerful \u2329noun\u232a \u201d BE will return all the nouns in its index that immediately follow the word \u201cpowerful\u201d,",
            "title": "BE: A Search Engine for NLP Research"
        },
        {
            "group": 239,
            "name": "10.1.1.123.8419",
            "keyword": "",
            "author": "Steve J. Simon",
            "abstract": "\u201c...change rather than stability as a way of organizational life may offer a more appropriate conceptual lens with which to think about change in contemporary organizations.\u201d (Orlikowski, 1996,p. 65) Organizational change is ubiquitous and continuous. It permeates organizational processes and life. We cannot avoid or ignore it. Many organizations invest significant sums of resources into external consulting. Some organizations (but very few) even embrace change and attempt to integrate it into their strategic planning. However, anyone involved in change or change research is aware that there is no guarantee that investment in change consultancy pays dividends. In the MIS academic arena, the most prevalent research topic associated with change over the past decade has focused on a change methodology, namely, business process reengineering (BPR). In the management academic arena, the focus has been on change management as a research construct. We believe that both are important, but that a synergistic approach is more appropriate between the two disciplines. MIS research on change tends to be oriented toward applied research, while management research tends to be oriented more toward conceptual research. Quality research, regardless of orientation, must",
            "title": "Synopsis Editorial Preface Change Research: The Search for a Theoretical Construct"
        },
        {
            "group": 240,
            "name": "10.1.1.124.1741",
            "keyword": "",
            "author": "Arpith Jacob, Joseph Lancaster, Jeremy Buhler, Roger D. Chamberlain, Arpith Jacob, Joseph Lancaster, Jeremy Buhler, Roger D, Arpith C. Jacob, Joseph M. Lancaster, Jeremy D. Buhler, Roger D. Chamberlain",
            "abstract": "Comparison between biosequences and probabilistic models is an increasingly important part of modern DNA and protein sequence analysis. The large and growing number of such models in today\u2019s databases demands computational approaches to searching these databases faster, while maintaining high sensitivity to biologically meaningful similarities. This work 1 describes an FPGA-based accelerator for comparing proteins to Hidden Markov Models of the type used to represent protein motifs in the popular HM-MER motif finder. Our engine combines a systolic array design with enhancements to pipeline the complex Viterbi calculation that forms the core of the comparison, and to support coarse-grained parallelism and streaming of multiple sequences within one FPGA. Performance estimates based on a functioning VHDL realisation of our design show a 190 \u00d7 speedup over the same computation in optimised software on a modern general-purpose CPU. 1.",
            "title": "R.D. Chamberlain is a principle in BECS Technology, Inc. Preliminary results in accelerating profile HMM search on FPGAs"
        },
        {
            "group": 241,
            "name": "10.1.1.124.3029",
            "keyword": "",
            "author": "N. L. Homeier, R. D. Blum, A. Pasquali, P. S. Conti, A. Damineli",
            "abstract": "Abstract. We present follow-up spectroscopy of emission line candidates detected on near-infrared narrow band images in the inner Galaxy (Homeier et al. 2003). The filters are optimized for the detection of Wolf-Rayet stars and other objects which exhibit emission\u2013lines in the 2 \u00b5m region. Approximately three square degrees along the Galactic plane have been analyzed in seven narrow\u2013filters (four emission\u2013lines and three continuum). We have discovered 4 new Wolf-Rayet stars and present coordinates, finding charts, and K-band spectra.",
            "title": "Astronomy Astrophysics Results from a near infrared search for emission-line stars in the Inner Galaxy: Spectra of new Wolf-Rayet stars \u22c6"
        },
        {
            "group": 242,
            "name": "10.1.1.124.3534",
            "keyword": "Search Engines, Information Retrieval, PageRank, Google",
            "author": "Sergey Brin",
            "abstract": "In this paper, we present Google, a prototype of a large-scale search engine which makes heavy use of the structure present in hypertext. Google is designed to crawl and index the Web efficiently and produce much more satisfying search results than existing systems. The prototype with a full text and hyperlink database of at least 24 million pages is available at",
            "title": "The Anatomy of a Search Engine Page 1 of 19 The Anatomy of a Large-Scale Hypertextual Web Search Engine"
        },
        {
            "group": 243,
            "name": "10.1.1.124.4702",
            "keyword": "",
            "author": "Robert Yaffee",
            "abstract": "Panel data analysis is an increasingly popular form of longitudinal data analysis among social and behavioral science researchers. A panel is a cross-section or group of people who are surveyed periodically over a given time span. In this article, we will consider a small sample of panel data analytic applications in the social sciences. Then we will address the data structure for panel analysis. Principal models of panel analysis will be summarized, along with some of their relative advantages and disadvantages. We will discuss a test to determine whether to use fixed or random effects models. After a synopsis of methods of estimations tailored to different situations, we will conclude with a brief discussion of popular software capable of performing panel analysis. Some Applications of Panel Analysis Panel data analysis is a method of studying a particular subject within multiple sites, periodically observed over a defined time frame. Within the social sciences, panel analysis has enabled researchers to undertake longitudinal analyses in a wide variety of fields. In economics, panel data analysis is used to study the behavior of firms and wages of people over time. In political science, it is used to study political behavior of parties and organizations over time. It is used in psychology, sociology, and health research to study characteristics of groups of people followed over time. In educational research, researchers study classes of students or graduates over time. With repeated observations of enough cross-sections, panel analysis permits the researcher to study the dynamics of change with short time series. The combination of time series with cross-sections can enhance the quality and quantity of data in ways that would be impossible using only one of these two dimensions (Gujarati, 638). Panel analysis can provide a rich and powerful study of a set of people, if one",
            "title": "A Primer for Panel Data Analysis Search This Site Browse the table of contents, or select an option from this menu: A Primer for Panel Data Analysis"
        },
        {
            "group": 244,
            "name": "10.1.1.124.5234",
            "keyword": "",
            "author": "",
            "abstract": "In this paper, various AI programming techniques will be considered in determining which is the most suitable for game playing in a specific domain. The domain is a style of game which involves creating an agent which engages in competition with other agents. In this style of game, a human player will implement a strategy for an agent which will operate within the guidelines of the particular game. There is no luck or probability involved in the games rule system. All advantage is gained through the ability of an agents strategy to choose actions during the competition based on the information available to it. The goal of the computer is to do something analogous to what the human player is doing. This paper will discuss some techniques which can be used to create a competitive agent in this domain. Particular areas of interest include analysis of techniques in terms of their effectiveness, as well as their ability to simulate a human within this domain. Two techniques that will be considered include tree searching for finding solutions and optimal solutions, as well as a learning based evolutionary model. 1.",
            "title": "Comparing Search Techniques and Genetic Programming in the Application of Agent Based Game Playing: A Problem Analysis"
        },
        {
            "group": 245,
            "name": "10.1.1.124.8409",
            "keyword": "",
            "author": "Andrew Laurence Tuson",
            "abstract": "In recent years, research into \u2018neighbourhood search \u2019 optimisation techniques such as simulated annealing, tabu search, and evolutionary algorithms has increased apace, resulting in a number of useful heuristic solution procedures for real-world and research combinatorial and function optimisation problems. Unfortunately, their selection and design remains a somewhat ad hoc procedure and very much an art. Needless to say, this shortcoming presents real difficulties for the future development and deployment of these methods. This thesis presents work aimed at resolving this issue of principled optimiser design. Driven by the needs of both the end-user and designer, and their knowledge of the problem domain and the search dynamics of these techniques, a semi-formal, structured, design methodology that makes full use of the available knowledge will be proposed, justified, and evaluated. This methodology is centred around a Knowledge Based System (KBS) view of neighbourhood search with a number of well-defined knowledge sources that relate to specific hypotheses about the problem domain. This viewpoint is complemented by a number of design heuristics that suggest a structured series of hillclimbing experiments which allow these results to be",
            "title": "No Optimisation Without Representation: A Knowledge-Based View of Evolution-ary/Neighbourhood Search Optimisation (in preparation"
        },
        {
            "group": 246,
            "name": "10.1.1.124.9011",
            "keyword": "honey bee colony, neighborhood search",
            "author": "Chin Soon, Chong Malcolm, Yoke Hean Low, Sivakumar Kheng, Leng Gay",
            "abstract": "This paper describes a population-based approach that uses a honey bees foraging model to solve job shop scheduling problems. The algorithm applies an efficient neighborhood structure to search for feasible solutions and iteratively improve on prior solutions. The initial solutions are generated using a set of priority dispatching rules. Experimental results comparing the proposed honey bee colony approach with existing approaches such as ant colony, tabu search and shifting bottleneck procedure on a set of job shop problems are presented. The results indicate the performance of the proposed approach is comparable to other efficient scheduling approaches. 1",
            "title": "USING A BEE COLONY ALGORITHM FOR NEIGHBORHOOD SEARCH IN JOB SHOP SCHEDULING PROBLEMS"
        },
        {
            "group": 247,
            "name": "10.1.1.125.2389",
            "keyword": "Query by Humming, Entertainment, Music, Audio",
            "author": "Bryan Pardo",
            "abstract": "Systems able to find a song based on a sung, hummed, or whistled melody are called Query-By-Humming (QBH) systems. We propose an approach to improve search performance of a QBH system based on data collected from an online social music game, Karaoke Callout. Users of Karaoke Callout generate training data for the search engine, allowing both ongoing personalization of query processing as well as vetting of database keys. Personalization of search engine user models takes place through using sung examples generated in the course of play to optimize parameters of user models.",
            "title": "D.: Teaching a music search engine through play"
        },
        {
            "group": 248,
            "name": "10.1.1.125.6117",
            "keyword": "",
            "author": "Leo Yuen, Matthew Chang, Ying Kit Lai, Chung Keung Poon",
            "abstract": "General purpose Web search engines are becoming ineffective due to the rapid growth and changes in the contents of the World Wide Web. Meta-search engines help a bit by having a better coverage of the WWW. However, users are still overwhelmed by the large amount of irrelevant results returned by a search. A promising approach to tackle the problem is personalized search. Thus the problem of capturing users \u2019 personal information need and re-organizing the results has attracted a lot of attention. In this paper, we present a meta-search engine that extracts users \u2019 preference implicitly and provides immediate response by re-ranking the results. Re-ranking is done by using the Naive Bayesian classifier and the resemblance measure. Moreover, we show that the users \u2019 preference can be succinctly represented by a few keywords. 1",
            "title": "Excalibur: A Personalized Meta Search Engine"
        },
        {
            "group": 249,
            "name": "10.1.1.125.6173",
            "keyword": "",
            "author": "David Bruemmer, Douglas Few, Heather Hunting, Miles Walton, Curtis Nielsen",
            "abstract": "Abstract \u2013 This paper discusses the use of four different camera perspectives within a real-time virtual 3-D interface as it is used to accomplish a remote robotic exploration and mapping task. The 3-D interface is used as the basis for a Cognitive Collaborative Workspace (CCW) that supports shared understanding of the task and environment. Multiple humans and robots can add iconographic entities such as waypoints, areas of interest, start and end locations, humans, doors, and landmines into the CCW. These tools can be used as a basis for tasking and monitoring and also communicate intentions and percepts. The experiment discussed in this paper evaluates how different perspectives within the 3-D display affect the performance of human-robot teams on a map-building and exploration task. Results show that perspective does play an important role in providing situation awareness. Specifically, task efficiency in terms of time to complete task and joystick usage is significantly diminished when the endocentric (i.e. 1 st person) perspective is used. I.",
            "title": "Virtual camera perspectives within a 3-d interface for robotic search and rescue"
        },
        {
            "group": 250,
            "name": "10.1.1.125.9665",
            "keyword": "",
            "author": "Abraham Bernstein, Esther Kaufmann, Christian Kaiser, Christoph Kiefer",
            "abstract": "The Semantic Web presents the vision of a distributed, dynamically growing knowledge base founded on formal logic. Common users, however, seem to have problems even with the simplest Boolean expression [1]. So how can we help users to query a web of logic that they do not seem to understand? We address",
            "title": "Ginseng A Guided Input Natural Language Search Engine for Querying Ontologies. Jena User Conference 2006"
        },
        {
            "group": 251,
            "name": "10.1.1.126.1815",
            "keyword": "",
            "author": "Hisayoshi Sugiyama, Tetsuo Tsujioka, Masashi Murata",
            "abstract": "This paper investigates QoS routing in an ad hoc network applied to a multi-robot network system named the \u201cvictim detection system \u201d proposed for detecting victims in urban disaster areas. For the purpose to secure the survivability of victims, a modified frame structure is examined in this paper based on the already proposed method: synchronized QoS routing. This modified scheme improves the network performance of victim detection system including rate of successful communication, call setup time and transmission breakage interval. These improvements are confirmed by computer simulations. 1.",
            "title": "QoS Routing in a Multi-Robot Network System for Urban Search and Rescue"
        },
        {
            "group": 252,
            "name": "10.1.1.126.2020",
            "keyword": "text, content evolution, search engine, Web mining",
            "author": "Ricardo Baeza-yates",
            "abstract": "This paper presents an extensive study about the evolution of textual content on the Web, which shows how some new pages are created from scratch while others are created using already existing content. We show that a significant fraction of the Web is a byproduct of the latter case. We introduce the concept of Web genealogical tree, in which every page in a Web snapshot is classified into a component. We study in detail these components, characterizing the copies and identifying the relation between a source of content and a search engine, by comparing page relevance measures, documents returned by real queries performed in the past, and click-through data. We observe that sources of copies are more frequently returned by queries and more clicked than other documents.",
            "title": "ABSTRACT Genealogical Trees on the Web: A Search Engine User Perspective"
        },
        {
            "group": 253,
            "name": "10.1.1.126.2080",
            "keyword": "",
            "author": "Lada Adamic, Eytan Adar",
            "abstract": "We address the question of how participants in a small world experiment are able to find short paths in a social network using only local information about their immediate contacts. We simulate such experiments on a network of actual email contacts within an organization as well as on a student social networking website. On the email network we find that small world search strategies using a contact\u2019s position in physical space or in an organizational hierarchy relative to the target can effectively be used to locate most individuals. However, we find that in the online student network, where the data is incomplete and hierarchical structures are not well defined, local search strategies are less effective. We compare our findings to recent theoretical hypotheses about underlying social structure that would enable these simple search strategies to succeed and discuss the implications to social software design. Key words: social networks, small world experiment, online communities, email analysis",
            "title": "Abstract How to search a social network"
        },
        {
            "group": 254,
            "name": "10.1.1.126.2916",
            "keyword": "",
            "author": "Sergey Brin",
            "abstract": null,
            "title": "The anatomy of a large-scale hyper textual Web search engine"
        },
        {
            "group": 255,
            "name": "10.1.1.126.3269",
            "keyword": "Algorithms, Experimentation. Keywords PageRank, Markov Decision Process, probabilistic automata, web search, local web search, web traffic logs",
            "author": "Qing Cui, Alex Dekhtyar",
            "abstract": "In this paper we give a preliminary report on our study of the use of web server traffic logs to improve local search. Web server traffic logs are, typically, private to individual websites and as such \u2013 are unavailable to traditional web search engines conducting searches across multiple web sites. However, they can be used to augment search performed by a local search engine, restricted to a single site. Web server traffic logs, which we will refer to as simply logs throughout this paper, contain information on traffic patterns on a web site. By using this information, instead of pure link counts in the computation of PageRank, we can obtain a new local measure of web site importance, based on frequency of visits to a page, rather than simply on the amount of links. In this paper we describe the architecture of a search engine we have built for the Eastern Kentucky University (EKU) website and some preliminary experiments we have conducted with it.",
            "title": "On improving local website search using web server traffic logs: a preliminary report"
        },
        {
            "group": 256,
            "name": "10.1.1.126.4515",
            "keyword": "",
            "author": "Lynne C. Howarth, Thea Miller",
            "abstract": "Abstract: As research described herein suggests, designing a cross-language information retrieval (CLIR) prototype that supports natural language queries in any language, and presents search results in visual category clusters, represents another step towards providing equitable access to the world community by anyone with an Internet connection and an information need. R\u00e9sum\u00e9: Comme la pr\u00e9sente recherche le sugg\u00e8re, la conception d\u2019un prototype de recherche d\u2019information multilingue (RIML) qui permet d\u2019exploiter les requ\u00eates en langage naturel dans n\u2019importe langage, et pr\u00e9sente les r\u00e9sultats de recherche sur les grappes de cat\u00e9gories visuelles. Ceci constitue une autre \u00e9tape pour offrir l\u2019acc\u00e8s \u00e9quitable \u00e0 la communaut\u00e9 internationale pour tous ceux qui poss\u00e8dent une connexion Internet et un besoin informationnel. 1. Introduction and Background to the Research Since 1986, when the Standard Generalized Mark-up Language (SGML) became an international standard (ISO 8879:1986), there has been steady activity to develop and refine SGML/XML/HTML-based metadata standards for specialised information domains. At the same time, so-called \u201clegacy \u201d metadata schemes, such as Machine-",
            "title": "Designing a Language-independent Search Prototype for Accessing Multilingual Resource from Metadata-enabled Repositories"
        },
        {
            "group": 257,
            "name": "10.1.1.126.6211",
            "keyword": "",
            "author": "",
            "abstract": "to the English language and about humans) on the following medical subject heading (MeSH) terms: callus + fracture, callus + radiology, fracture, ununited. Also, leading orthopedic texts were reviewed. BACKGROUND Follow-up radiographs are important to assess proper alignment and adequate healing of a fracture. The formation of a callus is one characteristic used to follow these features, but the timing and size of its appearance is variable. Therefore, when to expect to see a callus on radiographs requires a general understanding of the fracture healing process and the many variables that can affect callus formation. The callus, or immature bone, results from a precise chronological process. 1-3 Many factors can alter the sequence of events that result in the delay or even absence of callus formation. 1,4-7 The fracture healing process begins immediately after the fracture with the inflammatory phase. 1(pp186-199),2,7-9 In this phase, damage to the surrounding blood vessels and tissue lead to the formation of a hematoma. Inflammatory mediators are released causing inflammatory cells to migrate to the region. 1(pp186-199),10 These cells are involved in producing the framework in which the callus forms. This stage lasts 5 to 7 days, 2,11 with some overlap into the next phase. 1(pp186-199),10 The next stage, the reparative phase, is when the callus develops. This stage lasts from 4 to 40 days, composing about 40 % of the healing process time with overlap into the final phase. 1(pp186-199),10,11 The hematoma formed in the initial phase serves as a structure in which the callus forms into mature bone. Through the action of growth factors and other proteins, granulation tissue is converted to radiolucent cartilaginous callus. Eventually, this is mineralized by the deposition of calcium salts. 1,2,3,8,10 Once the calcification occurs, the callus becomes evident radiographically. This woven bone, or periosteal callus, creates an irregular radiographic appearance 1 that is fluffy, amorphous, and biologically plastic. 1(pp70-86) If not",
            "title": "Follow-up Radiographs to Detect Callus Formation After Fractures QUESTION When should one see a callus on a follow-up radiograph of a fracture? SOLUTION SEARCH STRATEGY"
        },
        {
            "group": 258,
            "name": "10.1.1.126.7066",
            "keyword": "",
            "author": "Nora Lustig, Carlos Jarque Head Of Inegi, Mar\u00eda Teresa Jim\u00e9nez, Narciso Arevalo",
            "abstract": "Income Expenditure Survey and patient advice on its use. In particular, she would like to thank",
            "title": "The Search for a Heterdox Paradigm \u201d in The Latin American Development Debate:"
        },
        {
            "group": 259,
            "name": "10.1.1.126.852",
            "keyword": "",
            "author": "Miguel Costa, M\u00e1rio J. Silva",
            "abstract": "Web search engines compete to offer the fastest responses with highest relevance. However, as Web collections grow, it becomes more difficult to achieve this purpose. As most users tend to see only the first two pages of results, it is unnecessary to compute the ranking of each one of the millions of documents that usually match any given query. Only those that have a level of importance that makes them candidates to the top ranked results have to be considered. This work presents and compares algorithms tested in our Web search engine to speed up the search of these candidates. We have been able to reduce by 93 % the number of documents considered for ranking calculation, using a pruning algorithm over a Web collection index sorted by URL weights. 1.",
            "title": "Optimizing Ranking Calculation in Web Search Engines: a Case Study"
        },
        {
            "group": 260,
            "name": "10.1.1.126.97",
            "keyword": "development, flight control systems",
            "author": "Algirdas Aviiienis, Michael R. Lyu, Werner Schutz",
            "abstract": "Multi-version software systems achieve fault tolerance through somare redundancy and diversity. In order to investigate this approach, this joint UCLAIHoneywell research project investigated multi-version sojhvare systems, employing six different programming languages to create six versions of sopare for an automatic landing program. The rationale, preparation. execution, and evaluation of this investigation are reported.",
            "title": "IN SEARCH OF EFFECTIVE DIVERSITY: A SIX-LANGUAGE STUDY OF FAULT-TOLERANT FLIGHT CONTROL SOFTWARE t"
        },
        {
            "group": 261,
            "name": "10.1.1.127.1226",
            "keyword": "",
            "author": "Christopher A. Voigt, D. Benjamin Gordon, Stephen L. Mayo",
            "abstract": "",
            "title": "Trading accuracy for speed: a quantitative comparison of search algorithms in protein sequence design"
        },
        {
            "group": 262,
            "name": "10.1.1.127.4241",
            "keyword": "",
            "author": "Vicente Campos , Fred Glover , Manuel Laguna , Rafael Mart\u00ed ",
            "abstract": "Scatter search is a population-based method that has recently been shown to yield promising outcomes for solving combinatorial and nonlinear optimization problems. Based on formulations originally proposed in the 1960s for combining decision rules and problem constraints, such as the surrogate constraint method, scatter search uses strategies for combining solution vectors that have proved effective in a variety of problem settings. In this paper, we present a scatter search implementation designed to find high quality solutions for the NP-hard linear ordering problem, which has a significant number of applications in practice. The LOP, for example, is equivalent to the so-called triangulation problem for input-output tables in economics. Our implementation goes beyond a simple exercise on applying scatter search, by incorporating innovative mechanisms to combine solutions and to create a balance between quality and diversification in the reference set. We also use a tracking process that generates solution statistics disclosing the nature of combinations and the ranks of antecedent solutions that produced the best final solutions. Our extensive computational experiments with more than 300 instances establishes the effectiveness of our procedure in relation to those previously identified to be best.",
            "title": "An Experimental Evaluation of a Scatter Search for the Linear Ordering Problem"
        },
        {
            "group": 263,
            "name": "10.1.1.127.4828",
            "keyword": "Key words, derivative-free optimization, Gaussian Process, expected improvement, oracle, local convergence",
            "author": "Genetha A. Gray, Monica Martinez-canales, Herbert K. H. Lee, Matt Taddy, Robert B. Gramacy",
            "abstract": "We consider a derivative-free method from the pattern search class of algorithms for the solution of simulationbased optimization problems. Because simulations often require significant computational time and resources, we are striving to reduce the number of runs needed by the optimization method. Moreover, since pattern searches are local methods, we are investigating ways of introducing robustness and some global properties. To accomplish these goals, we are using ideas from the design of computer experiments literature and using random functions to model the deterministic computer output function. We treat the output of the simulations as realizations of a Gaussian Process (GP). Then, the uncertainty about future computer evaluations can be quantified by finding the predictive distribution for new input locations conditional on the points that have already been evaluated. These ideas have been adapted to complex computer simulations in an R code referred to as tgp. This work combines the search properties of a pattern search with the statistical properties of the GP to create a new hybrid algorithm. In this paper, we will describe the optimization algorithm, the GP algorithm, and the resulting hybrid method, and we will present some numerical results.",
            "title": "Enhancing Parallel Pattern Search Optimization with a Gaussian Process Oracle"
        },
        {
            "group": 264,
            "name": "10.1.1.127.494",
            "keyword": "",
            "author": "",
            "abstract": "The late eighteenth and early nineteenth centuries saw what is known today as the Highland Clearances, which was in effect the forced migration of a large proportion of the population of the Scottish Highlands due to intensified sheep farming in the name of a more effective economic land use (Devine, 1999, pp.176-78). For the Gaelic speech community this meant \u2018the removal of its heartland \u2019 (MacKinnon, 1974, p.47). MacKinnon argues that \u2018effectively this was to reorientate the linguistic geography of Scotland in reducing the Gaelic areas to the very fringes of northern and western coastal areas and to the Hebrides \u2019 (1974, p.47). Yet, it was not economic exploitation alone which influenced the existence of the Gaelic population in a most profound way. There was also an active interference with language use through the eradication of Gaelic from the sphere of education as manifested in a series of Education Acts from 1872 onwards. Such education policy ensured the integration of the Gaelic speech community into English-language Britain (MacKinnon, 1974, pp.54-74). Gaelic",
            "title": "eSharp Issue 6:1 Identity and Marginality Gaelic Scotland \u2013 A Postcolonial Site? In Search of a Meaningful Theoretical Framework to Assess the Dynamics of Contemporary Scottish Gaelic Verse"
        },
        {
            "group": 265,
            "name": "10.1.1.127.6300",
            "keyword": "",
            "author": "Shobha Potluri, Anthony K. Yan, James J. Chou, Bruce R. Donald, Chris Bailey-kellogg",
            "abstract": "In these Supplementary Materials, we give the mathematical derivation for the bounding regions of Gq, which are used in the subsection entitled Bounding which is inside the Methods section of the main paper. We have organized these Supplementary Materials as follows. The geometric structure of Gq is described in Section S2. From this geometric structure, we derive properties of the convex hull of Gq in Section S3.",
            "title": "Supplementary Materials for Structure Determination of Symmetric Homo-oligomers by a Complete Search of Symmetry Configuration Space Using NMR Restraints and van der Waals Packing"
        },
        {
            "group": 266,
            "name": "10.1.1.127.643",
            "keyword": "",
            "author": "Tim Finin, Yun Peng, R. Scott, Cost Joel, Sachs Anupam Joshi, Pavan Reddivari, Rong Pan, Vishal Doshi, Li Ding",
            "abstract": "Swoogle is a crawler-based indexing and retrieval system for the Semantic Web documents \u2013 i.e., RDF or OWL documents. It analyzes the documents it discovered to compute useful metadata properties and relationships between them. The documents are also indexed by using an information retrieval system which can use either character N-Gram or URIs as terms to find documents matching a user\u2019s query or to compute the similarity among a set of documents. One of the interesting properties computed for each Semantic Web document is its rank \u2013 a measure of the document\u2019s importance on the Semantic Web. 1.",
            "title": "Swoogle: A search and metadata engine for the semantic web"
        },
        {
            "group": 267,
            "name": "10.1.1.127.7625",
            "keyword": "",
            "author": "Of Dr. Robert Ell, Bertrum H. Macdonald",
            "abstract": "136 MacLaren Street, Ottawa. Fire swept through the three-storey brick home of John and Olga Outram, claiming their lives in its wake. ' That event, tragic as it was, also set in motion the widespread dispersal of a massive estate (an estimated 26 tons of books and artifacts were stored in the hou~e). ~ Three decades later in my quest to discover only a portion of the contents of the Outram house, I have found it necessary to spend hundreds of hours, following countless leads, to document what was an entirely uncatalogued collection. The MacLaren Street address had been the home of Olga Outram's father, Dr. Robert Bell, a medical doctor and one of Canada's outstanding geological explorers during, the last half of the Victorian era. It is the story of Bell and his personal library that I will trace here. Many individuals read and collect books and periodicals; but professionals, such as medical practitioners, whose careers depend on the availability of information in the form of books, periodicals, and reports, have been more likely than general readers to acquire a personal, if modest, library.3 Determining the publications that were held in a private collection is a rewarding endeavor, even though the effort is pro-",
            "title": "Methods and Issues/Problbmatiques et mbthodes A Search for Gold: Reconstructing a Private Library-The Case"
        },
        {
            "group": 268,
            "name": "10.1.1.127.8693",
            "keyword": "",
            "author": "Richard A. Ward",
            "abstract": "A new class of membranes that leak protein has been developed for hemodialysis. These membranes provide greater clearances of low molecular weight proteins and small protein-bound solutes than do conventional high-flux dialysis membranes but at the cost of some albumin loss into the dialysate. Protein-leaking membranes have been used in a small number of clinical trials. The results of these trials suggest that protein-leaking membranes improve anemia correction, decrease plasma total homocysteine concentrations, and reduce plasma concentrations of glycosylated and oxidized proteins. However, it is not clear yet that routine use of protein-leaking membranes is warranted. Specific uremic toxins that are removed by protein-leaking membranes but not conventional high-flux membranes have not been identified. It is also unclear whether protein-leaking membranes offer benefits beyond those obtained with conventional high-flux membranes used in convective therapies, such as hemofiltration and hemodiafiltration. Finally, the amount of albumin loss that can be tolerated by hemodialysis patients in a long-term therapy has yet to be determined. Protein-leaking membranes offer a new approach to improving outcomes in hemodialysis, but whether their benefits will outweigh their disadvantages will require more basic and clinical research. J Am Soc Nephrol 16: 2421\u20132430, 2005. doi: 10.1681/ASN.2005010070 Uremia is characterized by retention of solutes over a wide molecular weight range (1), and new solutes are",
            "title": "Disease of the Month Protein-Leaking Membranes for Hemodialysis: A New Class of Membranes in Search of an Application?"
        },
        {
            "group": 269,
            "name": "10.1.1.127.942",
            "keyword": "",
            "author": "D. Chris Rayner, Katherine Davison, Vadim Bulitko, Kenneth Anderson, Jieshan Lu",
            "abstract": "Learning real-time search, which interleaves planning and acting, allows agents to learn from multiple trials and respond quickly. Such algorithms require no prior knowledge of the environment and can be deployed without pre-processing. We introduce Prioritized-LRTA * (P-LRTA*), a learning real-time search algorithm based on Prioritized Sweeping. P-LRTA * focuses learning on important areas of the search space, where the importance of a state is determined by the magnitude of the updates made to neighboring states. Empirical tests on path-planning in commercial game maps show a substantial learning speed-up over state-of-the-art real-time search algorithms. 1",
            "title": "Real-time heuristic search with a priority queue"
        },
        {
            "group": 270,
            "name": "10.1.1.127.960",
            "keyword": "",
            "author": "Joa\u00e4o P. Marques-silva, Karem A. Sakallah",
            "abstract": "Abstract\u00d0This paper introduces GRASP (Generic seaRch Algorithm for the Satisfiability Problem), a new search algorithm for Propositional Satisfiability (SAT). GRASP incorporates several search-pruning techniques that proved to be quite powerful on a wide variety of SAT problems. Some of these techniques are specific to SAT, whereas others are similar in spirit to approaches in other fields of Artificial Intelligence. GRASP is premised on the inevitability of conflicts during the search and its most distinguishing feature is the augmentation of basic backtracking search with a powerful conflict analysis procedure. Analyzing conflicts to determine their causes enables GRASP to backtrack nonchronologically to earlier levels in the search tree, potentially pruning large portions of the search space. In addition, by \u00aarecording\u00ba the causes of conflicts, GRASP can recognize and preempt the occurrence of similar conflicts later on in the search. Finally, straightforward bookkeeping of the causality chains leading up to conflicts allows GRASP to identify assignments that are necessary for a solution to be found. Experimental results obtained from a large number of benchmarks indicate that application of the proposed conflict analysis techniques to SAT algorithms can be extremely effective for a large number of representative classes of SAT instances. Index Terms\u00d0Satisfiability, search algorithms, conflict diagnosis, conflict-directed nonchronological backtracking, conflict-based equivalence, failure-driven assertions, unique implication points. 1",
            "title": "GRASP: A Search Algorithm for Propositional Satisfiability"
        },
        {
            "group": 271,
            "name": "10.1.1.128.1493",
            "keyword": "",
            "author": "Ele Ferrannini",
            "abstract": "The other day I saw Mrs. R. G., admitted for shortness of breath and fatigue. \u201cA lady of 59, \u201d recited the young intern, \u201chas had type 2 diabetes for 15 yr, treated with metformin plus glibenclamide, and hypertension, well-controlled on an angiotensin-converting enzyme inhibitor-thiazide combination. Her body mass index is 30.5 kg/m 2, serum triglycerides are 2.2 mmol/liter and high-density lipoprotein cholesterol is 0.99 mmol/liter. \u201d Then, with a triumphant glance at me, \u201cmetabolic syndrome, \u201d she stated. A clear message, I thought: the metabolic syndrome is here to stay. A captivating concept, a catchy name, the right blend of mystery (\u201csyndrome\u201d) and novelty, a reputation of global applicability, in consonance with other global epidemics (obesity and diabetes): all ingredients of success. How did it happen? The Beginning",
            "title": "0021-972X/07/$15.00/0 The Journal of Clinical Endocrinology & Metabolism 92(2):396\u2013398 Printed in U.S.A. Copyright \u00a9 2007 by The Endocrine Society doi: 10.1210/jc.2006-0944 CONTROVERSY IN CLINICAL ENDOCRINOLOGY Metabolic Syndrome: A Solution in Search of "
        },
        {
            "group": 272,
            "name": "10.1.1.128.1496",
            "keyword": "",
            "author": "Sinnakkrishnan Perumal, Ambuj Mahanti",
            "abstract": "While executing a process, many decisions are taken at its various decision points for selecting paths. There is a need for understanding and analyzing on various paths that emanate from various decision points to ensure that right decision is taken at these moments. For this purpose, this paper presents the notion of hyperpaths in the context of workflows, its properties, and an algorithm to generate various hyperpaths from a node of a workflow graph. The algorithm is presented with detailed workouts using examples. The paper also details various similarities between hyperpaths and related concepts like instance subgraphs, instance flows, etc., and briefs on various algorithms available in literature for such concepts. Finally, the paper presents various applications of hyperpaths such as process mining, business process re-engineering, etc. Hyperpaths can be used in service-oriented computing model for resource management, business activity monitoring (BAM), dynamic orchestration, and mission-critical service oriented systems.",
            "title": "Formal Foundation of Workflow Hyperpaths and a Graph Search Algorithm for Workflow Hyperpath Generation"
        },
        {
            "group": 273,
            "name": "10.1.1.128.2771",
            "keyword": "",
            "author": "Kashif Ali, Howard M. Heys",
            "abstract": "Abstract: In this paper, we investigate the application of an algorithm to find the best linear approximation of a basic Substitution-Permutation Network block cipher. The results imply that, while it is well known that the S-box used for the Advanced Encryption Standard has good nonlinear properties, it is straightforward to randomly select other S-boxes which are able to provide a similar level of security, as indicated by the exact bias of the best linear approximation found by the algorithm, rather than a simple upper bound on the maximum bias.",
            "title": "Results from a Search for the Best Linear Approximation of a Block Cipher"
        },
        {
            "group": 274,
            "name": "10.1.1.128.4332",
            "keyword": "",
            "author": "Kye-hyeon Kim, Seungjin Choi",
            "abstract": "Neighbor search is a fundamental task in machine learning, especially in classification and retrieval. Efficient nearest neighbor search methods have been widely studied, with their emphasis on data structures but most of them did not consider the underlying global geometry of a data set. Recent graph-based semi-supervised learning methods capture the global geometry, but suffer from scalability and parameter tuning problems. In this paper we present a (nearest) neighbor search method where the underlying global geometry is incorporated and the parameter tuning is not required. To this end, we introduce deterministic walks as a deterministic counterpart of Markov random walks, leading us to use the minimax distance as a global dissimilarity measure. Then we develop a message passing algorithm for efficient minimax distance calculation, which scales linearly in both time and space. Empirical study reveals the useful behavior of the method in image retrieval and semi-supervised learning. 1.",
            "title": "Neighbor Search with Global Geometry: A Minimax Message Passing Algorithm"
        },
        {
            "group": 275,
            "name": "10.1.1.102.5711",
            "keyword": "Category, SD F.0",
            "author": "J Gerard Wolff",
            "abstract": "  This paper argues that the operations of a `Universal Turing Machine' (UTM) and equivalent mechanisms such as the `Post Canonical System' (PCS) -- which are widely accepted as definitions of the concept of `computing' -- may be interpreted as information compression by multiple alignment, unification and search (ICMAUS). The motivation for this interpretation is that it suggests ways in which the UTM/PCS model may be augmented in a proposed new computing system designed to exploit the ICMAUS principles as fully as possible. The provision of a relatively sophisticated search mechanism in the proposed `SP' system appears to open the door to the integration and simplification of a range of functions including unsupervised inductive learning, best-match pattern recognition and information retrieval, probabilistic reasoning, planning and problem solving, and others. Detailed consideration of how the ICMAUS principles may be applied to these functions is outside the scope of this article but relevant sources are cited in this article.",
            "title": "'Computing' as information compression by multiple alignment, unification and search"
        },
        {
            "group": 276,
            "name": "10.1.1.128.705",
            "keyword": "",
            "author": "David J. Montana, Bolt Beranek, Newman Inc",
            "abstract": "We use a Generalized Hough transform (GHT) to detect and track instances of a class of sonar signals. This class consists of a four-dimensional set of curves and hence requires a four-dimensional transform space for the GHT. Many of the signals we need to detect are very weak. Such signals yield peaks in the transform space which are both very narrow and not too far above the random background variations. Finding such peaks is difficult. Exhaustive search over a predetermined discretization of the transform space will yield a nearly optimal point for a sufficiently fine discretization. However, even with an intelligently chosen discretization, exhaustive search requires searching over (and hence evaluating) many points in the transform space. We have therefore developed a genetic algorithm to more efficiently search the transform space. Designing the genetic algorithm to work properly has required experimentation with a number of its parameters. The most important of these are (i) the representation, (ii) the population size, and (iii) the number of runs.",
            "title": "Genetic Search of a Generalized Hough Transform Space"
        },
        {
            "group": 277,
            "name": "10.1.1.128.7670",
            "keyword": "",
            "author": "M. Fieschi Et Al. (eds, Robert Moskovitch, Alon Hessing, Yval Shahar, Robert Moskovitch, Alon Hessing, Yval Shahar",
            "abstract": "A major problem in the effective use of clinical guidelines is fast and accurate access at the point of care. Thus, we are developing a digital electronic guideline library (DeGeL) and a set of tools for incremental conversion of free-text guidelines into increasingly machine-comprehensible representations, which support automated application. Even if guidelines are represented in electronic fashion, care providers need to be able to quickly retrieve the guidelines that best fit the clinical situation at hand. We describe Vaidurya, a search and retrieval engine that exploits the hybrid nature of guideline representation in the De-GeL architecture. Vaidurya can use not only free-text keywords, but also multiple semantic indices along which the guidelines are classified, and the mark up of guidelines in DeGeL, using the semantic roles of one or more guideline-representation languages. Preliminary evaluation of Vaidurya in a standard information task and a large guideline repository is encouraging; formal evaluation is under way. Keywords: Information Retrieval, clinical practice guidelines, context-sensitive search.",
            "title": "Vaidurya \u2013 A Concept-Based, Context-Sensitive Search Engine For Clinical Guidelines"
        },
        {
            "group": 278,
            "name": "10.1.1.128.8672",
            "keyword": "",
            "author": "Teppo Felin  , Nicolai J. Foss  ",
            "abstract": "Organizations are made up of individuals, and there is no organization without individuals. There is nothing quite as elementary; yet this elementary truth seems to have been lost in the increasing focus on structure, routines, capabilities, culture, institutions and various other collective conceptualizations in much of recent strategic organization research. It is not overstating the matter too much to say that \u2018organization \u2019 has generally entered the field of strategy in the form of various aggregate concepts. This editorial essay is born out of a frustration on our part for the present lack of focus on individuals in much of strategic organization and the taken-forgranted status of \u2018organization\u2019. Specifically, the underlying argument of this essay is that individuals matter and that micro-foundations are needed for explanation in strategic organization. In fact, to fully explicate organizational anything \u2013 whether identity, learning, knowledge or capabilities \u2013 one must fundamentally begin with and understand the individuals that compose the whole, specifically their underlying nature, choices, abilities, propensities, heterogeneity, purposes, expectations and motivations. While using the term \u2018organizational\u2019 may serve as helpful shorthand for discussion purposes and for reduced-form empirical analysis, truly explaining (beyond correlations) the organization (e.g. existence, decline, capability or performance), or any collective for that matter, requires starting with the individual as the central actor. Our particular focus in this essay is on the organizational capabilities-based literature in strategic management. This focus serves as a specific example of a more general problem of lack of attention to individuals in strategic organization. (Wider implications could be explicated given more space.) As brief support for the fact that our discussion does have wider ramifications, we note that Selznick has also quite poignantly raised the need for micro-foundations on the",
            "title": " Strategic organization: a field in search of micro-foundations  "
        },
        {
            "group": 279,
            "name": "10.1.1.128.946",
            "keyword": "",
            "author": "Matthew G. Snover, Gaja E. Jarosz, Michael R. Brent",
            "abstract": "This paper describes a system for the unsupervised learning of morphological suffixes and stems from word lists. The system is composed of a generative probability model and a novel search algorithm. By extracting and examining morphologically rich subsets of an input lexicon, the search identifies highly productive paradigms. Quantitative results are shown by measuring the accuracy of the morphological relations identified. Experiments in English and Polish, as well as comparisons with other recent unsupervised morphology learning algorithms demonstrate the effectiveness of this technique. 1",
            "title": "2002. Unsupervised learning of morphology using a novel directed search algorithm: Taking the first step"
        },
        {
            "group": 280,
            "name": "10.1.1.128.9584",
            "keyword": "Static Balancing",
            "author": "Suri Pushpa, Prasad Vinod",
            "abstract": "Binary search tree is a best-suited data structure for data storage and retrieval when entire tree could be accommodated in the primary memory. However, this is true only when the tree is height-balanced. Lesser the height faster the search will be. Despite of the wide popularity of Binary search trees there has been a major concern to maintain the tree in proper shape. In worst case, a binary search tree may reduce to a linear link list, thereby reducing search to be sequential. Unfortunately, structure of the tree depends on nature of input. If input keys are not in random order the tree will become higher and higher on one side. In addition to that, the tree may become unbalanced after a series of operations like insertions and deletions. To maintain the tree in optimal shape many algorithms have been presented over the years. Most of the algorithms are static in nature as they take a whole binary search tree as input to create a balanced version of the tree. In this paper, few techniques have been discussed and analyzed in terms of time and space requirement. Key words:",
            "title": "Binary Search Tree Balancing Methods: A Critical Study"
        },
        {
            "group": 281,
            "name": "10.1.1.128.9719",
            "keyword": "",
            "author": "Vijay John",
            "abstract": "This paper deals with a relatively unexplored aspect (searching for romanized transliterations of terms) of a popular language (namely, Mandarin Chinese). Although search engines are able to suggest alternate spellings, they do not yet look for all possible transliterations of the same word. This paper describes a new approach to enhance search engine performance on terms originally from Mandarin Chinese. The algorithm improves searches by extracting parts of search terms using a right-to-left search method. This algorithm, Xi\u0103ozh\u012d, is currently implemented for Mandarin Chinese search terms written in P\u012bny\u012bn. The program includes a list of transliteration replacement sets, within which the elements are possible transliterations of the same sound. Even though the implementation is specific to Mandarin Chinese, Xi\u0103ozh\u012d may be extended to other languages using a different list of sets. This includes less-studied languages, such as Tibetan, Romani, and Malayalam. 2",
            "title": "1 2 / VIJAY JOHN A Method for Enhancing Search Using Transliteration of Mandarin Chinese"
        },
        {
            "group": 282,
            "name": "10.1.1.129.1446",
            "keyword": "",
            "author": "Amy Felty",
            "abstract": "",
            "title": "The Calculus of Constructions as a Framework for Proof Search with Set Variable Instantiation"
        },
        {
            "group": 283,
            "name": "10.1.1.129.4090",
            "keyword": "",
            "author": "Carlos Amaral, Dominique Laurent, Andr\u00e9 Martins, Afonso Mendes, Cl\u00e1udia Pinto, Priberam Inform\u00e1tica",
            "abstract": "We present the semantic multilingual question answering engine of the TRUST project, describing its overall architecture, its common multilingual resources, as well as the specific resources, tools and processing mechanisms implemented for the development of the Portuguese language module. 1 Introduction 2 Language resources This paper describes the Portuguese language module developed by Priberam for TRUST 1, Text Retrieval Using Semantic Technologies, an EU co-financed project 2, whose aim was the development of a semantic and",
            "title": "Design and Implementation of a Semantic Search Engine for Portuguese"
        },
        {
            "group": 284,
            "name": "10.1.1.129.4495",
            "keyword": "",
            "author": "Matei Ripeanu, Adriana Iamnitchi, Ian Foster, Anne Rogers",
            "abstract": "Group communication primitives have broad utility as building blocks for distributed applications. The challenge is to create and maintain the distributed structures that support these primitives while accounting for volatile end-nodes and variable network characteristics. Most solutions proposed to date rely on complex algorithms or global information, thus limiting the scale of deployments and acceptance outside the academic realm. This article introduces a low-complexity, self-organizing solution for maintaining multicast trees, that we refer to as UMM (Unstructured Multi-source Multicast). UMM uses traditional distributed systems techniques: layering, soft-state, and passive data collection to adapt to the dynamics of the physical network and maintain data dissemination trees. The result is a simple, adaptive system with lower overheads than more complex alternatives. We have implemented UMM and evaluated it on up to 1024-node emulated ModelNet networks and on the PlanetLab testbed.. Extensive experimental evaluations and quantitative comparisons with alternative solutions demonstrate UMM\u2019s low overhead, efficient network usage, and ability to quickly adapt to network changes and to recover from failures. 1.",
            "title": "In Search of Simplicity: A Self-Organizing Group Communication Overlay"
        },
        {
            "group": 285,
            "name": "10.1.1.129.4647",
            "keyword": "",
            "author": "Herwig Unger, Markus Wulff",
            "abstract": "The paper considers the data search problem in distributed P2P networks. Since no central search engines are available, other effective methods must be developed to avoid a complete search of all nodes each time. We investigate mechanisms and introduce the main structure and functionality of such a decentralized cooperative search engine. It is working on the basis of so called ants. This search engine reduces the search time for information, which are needed by more than one node in a peer-to-peer network community. Therefore, the ants are able to switch in a special manner between different behavior strategies to search, concentrate and return the respective information. The various strategies are derived from ant colonies and were simulated in a small world community environment.",
            "title": "Towards a Decentralized Search Engine for P2P-Network Communities"
        },
        {
            "group": 286,
            "name": "10.1.1.129.8074",
            "keyword": "",
            "author": "Ivelin Georgiev, Ryan H. Lilien, Bruce R. Donald",
            "abstract": null,
            "title": "The Minimized Dead-End Elimination Criterion and Its Application to Protein Redesign in a Hybrid Scoring and Search Algorithm for Computing Partition Functions over Molecular Ensembles"
        },
        {
            "group": 287,
            "name": "10.1.1.129.9134",
            "keyword": "",
            "author": "Jason A. D. Atkin, Edmund K. Burke, John S. Greenwood, Dale Reeson",
            "abstract": "",
            "title": " A hybrid tabu search evaluation of holding point entrance allocation methods for departures at London Heathrow airport"
        },
        {
            "group": 288,
            "name": "10.1.1.129.9218",
            "keyword": "",
            "author": "Guang-Ho Cha , Chin-Wan Chung",
            "abstract": " With the proliferation of multimedia data, there is an increasing need to support the indexing and retrieval of high-dimensional image data. In this paper, we propose a new dynamic index structure called the GC-tree (or the grid cell tree) for efficient similarity search in image databases. The GC-tree is based on a special subspace partitioning strategy which is optimized for a clustered high-dimensional image dataset. The basic ideas are three-fold: (1) we adaptively partition the data space based on a density function that identifies dense and sparse regions in a data space; (2) we concentrate the partition on the dense regions, and the objects in the sparse regions of a certain partition level are treated as if they lie within a single region; (3) we dynamically construct an index structure that corresponds to the space partition hierarchy. The resultant index structure adapts well to the strongly clustered distribution of high-dimensional image datasets. To demonstrate the practical effectiveness of the GC-tree, we experimentally compared the GC-tree with the IQ-tree, the LPC-file, the VA-file, and the linear scan. The result of our experiments shows that the GC-tree outperforms all other methods. ",
            "title": "The GC-tree: a high-dimensional index structure for similarity search in image databases"
        },
        {
            "group": 289,
            "name": "10.1.1.129.9829",
            "keyword": "",
            "author": "Hyowon Lee, Alan F. Smeaton",
            "abstract": "Abstract. The proliferation of CCTV surveillance systems creates a problem of how to effectively navigate and search the resulting video archive, in a variety of security scenarios. We are concerned here with a situation where a searcher must locate all occurrences of a given person or object within a specified timeframe and with constraints on which camera(s) footage is valid to search. Conventional approaches based on browsing time/camera based combinations are inadequate. We advocate using automatically detected video objects as a basis for search, linking and browsing. In this paper we present a system under development based on users interacting with detected video objects. We outline the suite of technologies needed to achieve such a system and for each we describe where we are in terms of realizing those technologies. We also present a system interface to this system, designed with user needs and user tasks in mind. 1.",
            "title": "User-Interface to a CCTV Video Search System"
        },
        {
            "group": 290,
            "name": "10.1.1.13.2343",
            "keyword": "",
            "author": "D. A. Caughey, Antony Jameson, Antony Jameson",
            "abstract": "New versions of implicit algorithms are proposedf or the e#cient solution of the Euler equations of compressible flow. The methods are based on a preconditioned, Lower-Upper (LU) implementation of a nonlinear, Symmetric Gauss-Seidel (SGS) algorithmf  or use as a smoothing algorithm in a multigrid method. The methods have been implemented f or flows in quasi-one-dimensional ducts andf or two dimensional flows past airf oils on boundaryconf  orming \"O\"-type gridsf or a varietyof Symmetric LImited Positive (SLIP) spatial approximations, including the scalar dissipation and Convective Upwind Split Pressure (CUSP) schemes. The method is demonstrated to be significantlyf aster than earlier explicit or implicit methodsf or this class of problems, allowing solution of these problems to the level of truncation error in three to five multigrid cycles. 1 ",
            "title": "How Many Steps are Required to Solve the Euler Equations of Steady, Compressible Flow: In Search of a Fast Solution Algorithm"
        },
        {
            "group": 291,
            "name": "10.1.1.13.2724",
            "keyword": "",
            "author": "Hugo Liu, Henry Lieberman, Ted Selker",
            "abstract": "A novice search engine user may find searching the web for information difficult and frustrating because she may naturally express search goals rather than the topic keywords search engines need. In this paper, we present GOOSE (goal-oriented search engine), an adaptive search engine interface that uses natural language processing to parse a user's search goal, and uses \"common sense\" reasoning to translate this goal into an effective query. For a source of common sense knowledge, we use Open Mind, a knowledge base of approximately 400,000 simple facts such as \"If a pet is sick, take it to the veterinarian \" garnered from a Web-wide network of contributors. While we cannot be assured of the robustness of the common sense inference, in a substantial number of cases, GOOSE is more likely to satisfy the user's original search goals than simple keywords or conventional query expansion.",
            "title": "GOOSE: A Goal-Oriented Search Engine with Commonsense"
        },
        {
            "group": 292,
            "name": "10.1.1.13.3411",
            "keyword": "",
            "author": "Richard A. Hagen, Abdul Sattar, Scott Goodwin",
            "abstract": "Nonmonotonic reasoning has been a field of vigorous study for a quarter of a century with practical implementations emerging during the last 15 years. Improving the efficiency of these systems is an important step in them gaining acceptance beyond the research sphere. The use of lemmas - small results that can be reused later in a proof or derivation - might be one way of improving performance. We have extended an implementation of the THEORIST nonmonotonic reasoning system with four sorts of lemmas: goods, nogoods, derived literals and potential crucial literals. In this paper, we report the results of experiments designed to test whether these lemmas provide general performance boosts.",
            "title": "Improving Search in a Hypothetical Reasoning System"
        },
        {
            "group": 293,
            "name": "10.1.1.13.4020",
            "keyword": "Contents",
            "author": "Amr Z. Kronfol, Amr Z. Kronfol",
            "abstract": "This paper introduces FASD, a fault-tolerant, adaptive, scalable, and distributed search layer designed to augment existing peer-to-peer applications. The FASD layer operates as a network of identical nodes that collectively pool their storage space to cache \"metadata keys\" and cooperatively route queries to the nodes most likely to satisfy them. A \"metadata key\" is a list of weighted terms that describe the information content of a document in the underlying network. Although completely decentralized, FASD's approach is able to e#ciently match the recall and precision of a centralized search engine. Simulation results indicate that latency and bandwidth consumption scale logarithmically with the size of a FASD network.",
            "title": "FASD: A Fault-tolerant, Adaptive, Scalable, Distributed Search Engine"
        },
        {
            "group": 294,
            "name": "10.1.1.13.4877",
            "keyword": "",
            "author": "Annie Chen Yun, Yun Ki Lee, Andrew Y. Yao, Amir Michail",
            "abstract": "We have built a tool, CVSSearch [1], that searches for fragments of source code by using CVS comments. (CVS is a version control system that is widely used in the open source community [3].) Our search tool takes advantage of the fact that a CVS comment typically describes the lines of code involved in the commit and this description will typically hold for many future versions. This paper provides a preliminary evaluation of this technique by 74 students at the University of New South Wales. Among our findings, CVS comments do provide a valuable source of information for code search that complements --- but does not replace --- tools that simply search the source code itself (e.g., grep).",
            "title": "Code Search based on CVS Comments: A Preliminary Evaluation"
        },
        {
            "group": 295,
            "name": "10.1.1.13.4980",
            "keyword": "",
            "author": "Mauricio G. C. Resende,  Renato F. Werneck",
            "abstract": "We present a new implementation of a widely used swap-based local search procedure for the p-median problem. It produces the same output as the best implementation described in the literature and has the same worst-case complexity, but, through the use of extra memory, it can be significantly faster in practice: speedups of up to three orders of magnitude were observed.",
            "title": "On the Implementation of a Swap-Based Local Search Procedure for the p-Median Problem"
        },
        {
            "group": 296,
            "name": "10.1.1.13.6500",
            "keyword": "",
            "author": "Stefan Bleuler, Marco Laumanns, Lothar Thiele, Eckart Zitzler",
            "abstract": "This paper  int  roduces  at ext  based int rface  (PISA)t hat  allows t  separat ty  algorit  hm-specific  part  of an op t mizer  fromt  he  applicat  ionspecific  part  . These  part  s are  implement  ed as  independent  programs forming  freelycombinable modules.",
            "title": "PISA - A Platform and Programming Language Independent Interface for Search Algorithms"
        },
        {
            "group": 297,
            "name": "10.1.1.13.6840",
            "keyword": "",
            "author": "Rinat Khoussainov,  Nicholas Kushmerick",
            "abstract": "Optimal behaviour in stochastic games is a key  challenge in multi-agent environments. The difficulty  stems from the fact that the utilities of  local agent actions depend on the uncertain actions  of other agents (opponents). We consider  an instance of this problem in heterogeneous  Web search environments, in which topicspecific  search engines provide search services,  and metasearchers distribute user's queries to  only the most suitable search engines. Previous  research has explored performance in such  environments from the user's perspective (e.g.,  improved quality of search results). Our focus  is instead on performance from the search service  provider's point of view (e.g., income from  queries processed vs. resources used to answer  them). We analyse a scenario in which topicspecific  search engines compete for user queries  by choosing which documents (topics) to index.",
            "title": "Distributed Web Search as a Stochastic Game"
        },
        {
            "group": 298,
            "name": "10.1.1.13.7588",
            "keyword": "Natural search, Optimized search strategies, Robotics, Search for explosive mines",
            "author": "Erol Gelenbe , Nestor Schmajuk , John Staddon , John Reif ",
            "abstract": "This paper is a survey of research on autonomous search strategies which originate in engineering and biology. Our motivation is to identify methods of search in an essentially two-dimensional Euclidean space, which can be applied to the area of detaining. Such search strategies are based on spatio-temporal distributions. These distributions may be known in advance, because of prior intelligence or through the use of remote sensing, or they may be the result of on-line gathering of information as the search progresses, or of both. We first review the literature on search and coordination which emanates from the field of robotics, we then summarize significant research in the field of animal search, and also discuss relevant results in robotics which are inspired by animal behavior.  ",
            "title": "Autonomous Search by  Robots and Animals: A Survey"
        },
        {
            "group": 299,
            "name": "10.1.1.13.8674",
            "keyword": "",
            "author": "Henrich R. Greve, Takako Fujiwara-greve",
            "abstract": "It is in workers' interest to leave their jobs if better work can be found, but imperfect information on outside opportunities impedes their job search. We describe two theories on workers' search using the organizational size as a proxy for work characteristics, and derive hypotheses on how the organizational size distribution in a labor market affects job separations. We test the hypotheses with NLSY 79 data on job separations, finding that diversity in organizational sizes affects worker mobility. Workers are more likely to move within counties with many organizations larger than their current or many organizations of different sizes, and are more likely to leave counties lacking these characteristics.",
            "title": "Job Search with Organizational Size as a Signal"
        }
    ],
    "links": [
        {
            "source": 59,
            "target": 101,
            "value": 0.466403
        },
        {
            "source": 71,
            "target": 259,
            "value": 0.389163
        },
        {
            "source": 101,
            "target": 154,
            "value": 0.472789
        },
        {
            "source": 101,
            "target": 196,
            "value": 0.374468
        },
        {
            "source": 101,
            "target": 248,
            "value": 0.399254
        },
        {
            "source": 101,
            "target": 255,
            "value": 0.5
        }
    ]
}